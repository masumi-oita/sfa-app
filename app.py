# -*- coding: utf-8 -*-
"""
SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - OS v1.4.10 (v1.4.9è¸è¥² + æ–°è¦ç´å“ãƒˆãƒ¬ãƒ³ãƒ‰è¿½åŠ )

ã€v1.4.9 è¸è¥²ã€‘
- YoYï¼šVIEW_UNIFIED ã‹ã‚‰å‹•çš„é›†è¨ˆã«çµ±ä¸€ï¼ˆYJåŒä¸€ã§å•†å“åãŒ2è¡Œå•é¡Œã‚’æŠ‘æ­¢ï¼‰
- YoYï¼šç¬¬ä¸€éšå±¤ã‚’ã€Œã‚¯ãƒªãƒƒã‚¯é¸æŠã€å¯¾å¿œï¼ˆãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿ã§ã‚‚é¸æŠä¿æŒï¼‰
- ã‚¹ã‚³ãƒ¼ãƒ—ï¼šå¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ—åˆ—å€™è£œã‚’ VIEW_UNIFIED ã®ã‚¹ã‚­ãƒ¼ãƒã‹ã‚‰è‡ªå‹•åˆ¤å®š
- Group Display: officialå…ˆé ­ + rawä½µè¨˜
- æ–°æ©Ÿèƒ½ï¼šå¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ— / å¾—æ„å…ˆå˜ä½“ã®åˆ‡æ›¿ ï¼† å•†å“è¦å› ãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ï¼ˆå…¨ä»¶è¡¨ç¤ºï¼‰
- æ–°æ©Ÿèƒ½ï¼šé †ä½ã‚¢ã‚¤ã‚³ãƒ³ã®è¿½åŠ ã¨ã€ä¸è¦ãªYJã‚³ãƒ¼ãƒ‰åˆ—ã®éè¡¨ç¤º
- ä¿®æ­£ï¼šWHEREäºŒé‡ã‚¨ãƒ©ãƒ¼è§£æ¶ˆ ï¼† é¸æŠçŠ¶æ…‹ã®æ¶ˆå¤±ãƒã‚°è§£æ¶ˆ ï¼† è¡¨ç¤ºé †åºã®æœ€é©åŒ–
- ä¿®æ­£ï¼šRecoï¼ˆVIEW_RECOMMENDï¼‰ã® customer_code ãŒ INT64 ã®ãŸã‚ã€STRINGã‚­ãƒ¼ï¼ˆVIEW_UNIFIEDï¼‰ã¨ç…§åˆã§ãã‚‹ã‚ˆã† CAST å¯¾å¿œ
- ColMapï¼ˆåˆ—åå¸åï¼‰å°å…¥ï¼šjan/jan_codeã€pack_unit/package_unit ç­‰ã®å·®ç•°ã‚’è‡ªå‹•è§£æ±º
- å…¨SQLã§ colmap ã‚’è²«é€šï¼šåˆ—åæºã‚Œèµ·å› ã® "Unrecognized name" ã‚’æ ¹çµ¶
- å¿…é ˆåˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€èµ·å‹•ç›´å¾Œã«ã€Œä¸è¶³åˆ—ä¸€è¦§ã€ã‚’æ˜ç¤ºã—ã¦åœæ­¢ï¼ˆæ²ˆé»™ã—ãªã„ï¼‰

ã€v1.4.10 â˜…è¿½åŠ ï¼ˆä»Šå›ï¼‰ã€‘
- â˜… æ–°è¦ç´å“ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆå¾—æ„å…ˆ / ã‚°ãƒ«ãƒ¼ãƒ— / å•†å“ï¼‰ã‚’è¿½åŠ 
  - ç›´è¿‘Næ—¥ vs ãã®å‰Næ—¥ã®æ¯”è¼ƒã§ã€Œå¢—ãˆã¦ã„ã‚‹ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¡¨ç¤º
  - è¿½åŠ ã®å¢—åˆ†ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ»æˆé•·æ›´æ–°SQLã¯ä½œã‚‰ãªã„ï¼ˆç¾è¡ŒVIEWæ›´æ–°ã‚’æœ€å¤§æ´»ç”¨ï¼‰
  - ã‚°ãƒ«ãƒ¼ãƒ—åˆ‡ã‚Šå£ã¯ VIEW_UNIFIED ã® group_expr ã‚’å‚ç…§ï¼ˆç„¡ã‘ã‚Œã°éè¡¨ç¤ºï¼‰
"""

from __future__ import annotations

from dataclasses import dataclass
import re
from typing import Any, Dict, Optional, Tuple

import pandas as pd
import streamlit as st
from google.cloud import bigquery
from google.oauth2 import service_account
from pandas.api.types import is_numeric_dtype


# -----------------------------
# 1. Configuration (è¨­å®š)
# -----------------------------
APP_TITLE = "SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"
DEFAULT_LOCATION = "asia-northeast1"
PROJECT_DEFAULT = "salesdb-479915"
DATASET_DEFAULT = "sales_data"

VIEW_UNIFIED = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_unified_grouped"
VIEW_ROLE_CLEAN = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.dim_staff_role_clean"
VIEW_NEW_DELIVERY = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_new_deliveries_realized_daily_fact_all_months"
VIEW_RECOMMEND = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_recommendation_engine"
VIEW_ADOPTION = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_customer_adoption_status"

CUSTOMER_GROUP_COLUMN_CANDIDATES = (
    "customer_group_display",
    "customer_group_official",
    "customer_group_raw",
    "sales_group_name",
)


# -----------------------------
# 2. Helpers (è¡¨ç¤ºç”¨)
# -----------------------------
def set_page() -> None:
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)
    st.caption("OS v1.4.10ï½œv1.4.9è¸è¥² + æ–°è¦ç´å“ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆå¾—æ„å…ˆ/ã‚°ãƒ«ãƒ¼ãƒ—/å•†å“ï¼‰")


def create_default_column_config(df: pd.DataFrame) -> Dict[str, st.column_config.Column]:
    config: Dict[str, st.column_config.Column] = {}
    for col in df.columns:
        if any(k in col for k in ["å£²ä¸Š", "ç²—åˆ©", "é‡‘é¡", "å·®é¡", "å®Ÿç¸¾", "äºˆæ¸¬", "GAP"]):
            config[col] = st.column_config.NumberColumn(col, format="Â¥%d")
        elif any(k in col for k in ["ç‡", "æ¯”", "ãƒšãƒ¼ã‚¹"]):
            config[col] = st.column_config.NumberColumn(col, format="%.1f%%")
        elif "æ—¥" in col or pd.api.types.is_datetime64_any_dtype(df[col]):
            config[col] = st.column_config.DateColumn(col, format="YYYY-MM-DD")
        elif is_numeric_dtype(df[col]):
            config[col] = st.column_config.NumberColumn(col, format="%d")
        else:
            config[col] = st.column_config.TextColumn(col)
    return config


def get_safe_float(row: pd.Series, key: str) -> float:
    val = row.get(key)
    return float(val) if not pd.isna(val) else 0.0


def normalize_product_display_name(name: Any) -> str:
    if pd.isna(name):
        return ""
    text = str(name).strip()
    text = re.sub(r"[/ï¼].*$", "", text)
    return text.strip()


# -----------------------------
# 3. BigQuery Connection & Auth
# -----------------------------
@st.cache_resource
def setup_bigquery_client() -> bigquery.Client:
    bq = st.secrets["bigquery"]
    sa_info = dict(bq["service_account"])
    scopes = [
        "https://www.googleapis.com/auth/bigquery",
        "https://www.googleapis.com/auth/drive",
        "https://www.googleapis.com/auth/spreadsheets",
    ]
    creds = service_account.Credentials.from_service_account_info(sa_info, scopes=scopes)
    return bigquery.Client(
        project=PROJECT_DEFAULT,
        credentials=creds,
        location=DEFAULT_LOCATION,
    )


def _normalize_param(value: Any) -> Tuple[str, Optional[Any]]:
    if isinstance(value, tuple) and len(value) == 2:
        p_type, p_value = value
        return str(p_type).upper(), p_value

    if value is None:
        return "STRING", None
    if isinstance(value, bool):
        return "BOOL", value
    if isinstance(value, int):
        return "INT64", value
    if isinstance(value, float):
        return "FLOAT64", value
    if isinstance(value, pd.Timestamp):
        return "TIMESTAMP", value.to_pydatetime()

    return "STRING", str(value)


def query_df_safe(
    client: bigquery.Client,
    sql: str,
    params: Optional[Dict[str, Any]] = None,
    label: str = "",
    timeout_sec: int = 60,
) -> pd.DataFrame:
    use_bqstorage = st.session_state.get("use_bqstorage", True)
    try:
        job_config = bigquery.QueryJobConfig()
        if params:
            query_params = []
            for key, raw_value in params.items():
                p_type, p_value = _normalize_param(raw_value)
                query_params.append(bigquery.ScalarQueryParameter(key, p_type, p_value))
            job_config.query_parameters = query_params

        job = client.query(sql, job_config=job_config)
        job.result(timeout=timeout_sec)
        return job.to_dataframe(create_bqstorage_client=use_bqstorage)
    except Exception as e:
        st.error(f"ã‚¯ã‚¨ãƒªã‚¨ãƒ©ãƒ¼ ({label}):\n{e}")
        return pd.DataFrame()


@dataclass(frozen=True)
class RoleInfo:
    is_authenticated: bool = False
    login_email: str = ""
    staff_name: str = "ã‚²ã‚¹ãƒˆ"
    role_key: str = "GUEST"
    role_admin_view: bool = False
    phone: str = "-"


@dataclass(frozen=True)
class ScopeFilter:
    predicates: tuple[str, ...] = ()
    params: Dict[str, Any] | None = None

    def where_clause(self) -> str:
        if not self.predicates:
            return ""
        return " AND ".join(self.predicates)


def _compose_where(*parts: str) -> str:
    clauses = [p.strip() for p in parts if p and p.strip()]
    if not clauses:
        return ""
    return "WHERE " + " AND ".join(clauses)


def _split_table_fqn(table_fqn: str) -> Tuple[str, str, str]:
    parts = table_fqn.split(".")
    if len(parts) != 3:
        raise ValueError(f"Invalid table FQN: {table_fqn}")
    return parts[0], parts[1], parts[2]


@st.cache_data(ttl=3600)
def role_table_has_login_code(_client: bigquery.Client) -> bool:
    project_id, dataset_id, table_name = _split_table_fqn(VIEW_ROLE_CLEAN)
    sql = f"""
        SELECT 1
        FROM `{project_id}.{dataset_id}.INFORMATION_SCHEMA.COLUMNS`
        WHERE table_name = @table_name
          AND column_name = 'login_code'
        LIMIT 1
    """
    df = query_df_safe(_client, sql, {"table_name": table_name}, "Role Schema Check")
    return not df.empty


@st.cache_data(ttl=3600)
def get_unified_columns(_client: bigquery.Client) -> set[str]:
    project_id, dataset_id, table_name = _split_table_fqn(VIEW_UNIFIED)
    sql = f"""
        SELECT column_name
        FROM `{project_id}.{dataset_id}.INFORMATION_SCHEMA.COLUMNS`
        WHERE table_name = @table_name
    """
    df = query_df_safe(_client, sql, {"table_name": table_name}, "Unified Schema Check")
    if df.empty or "column_name" not in df.columns:
        return set()
    return {str(c).lower() for c in df["column_name"].dropna().tolist()}


def get_available_customer_group_columns(_client: bigquery.Client) -> list[str]:
    columns = get_unified_columns(_client)
    return [col for col in CUSTOMER_GROUP_COLUMN_CANDIDATES if col in columns]


@st.cache_data(ttl=3600)
def get_customer_group_column_profiles(_client: bigquery.Client) -> pd.DataFrame:
    available_cols = get_available_customer_group_columns(_client)
    if not available_cols:
        return pd.DataFrame()

    union_parts = []
    for col in available_cols:
        union_parts.append(
            f"""
            SELECT
              '{col}' AS column_name,
              COUNT(*) AS total_rows,
              COUNTIF(COALESCE(NULLIF(CAST({col} AS STRING), ''), '') != '') AS non_null_rows,
              COUNT(DISTINCT NULLIF(CAST({col} AS STRING), '')) AS distinct_groups
            FROM `{VIEW_UNIFIED}`
            """
        )

    sql = "\nUNION ALL\n".join(union_parts) + "\nORDER BY non_null_rows DESC, distinct_groups DESC"
    return query_df_safe(_client, sql, label="Customer Group Column Profile")


def resolve_customer_group_sql_expr(_client: bigquery.Client) -> Tuple[Optional[str], Optional[str]]:
    cols = get_unified_columns(_client)

    has_display = "customer_group_display" in cols
    has_official = "customer_group_official" in cols
    has_raw = "customer_group_raw" in cols
    has_old = "sales_group_name" in cols

    if has_display:
        expr = "COALESCE(NULLIF(CAST(customer_group_display AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.customer_group_display"

    if has_official and has_raw:
        official = "NULLIF(CAST(customer_group_official AS STRING), '')"
        raw = "NULLIF(CAST(customer_group_raw AS STRING), '')"
        expr = f"""
          COALESCE(
            CASE
              WHEN {official} IS NOT NULL AND {raw} IS NOT NULL AND {official} != {raw}
                THEN CONCAT({official}, 'ï¼ˆ', {raw}, 'ï¼‰')
              WHEN {official} IS NOT NULL THEN {official}
              WHEN {raw} IS NOT NULL THEN {raw}
              ELSE NULL
            END,
            'æœªè¨­å®š'
          )
        """
        return " ".join(expr.split()), f"{VIEW_UNIFIED}.customer_group_official + customer_group_raw"

    if has_official:
        expr = "COALESCE(NULLIF(CAST(customer_group_official AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.customer_group_official"

    if has_raw:
        expr = "COALESCE(NULLIF(CAST(customer_group_raw AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.customer_group_raw"

    if has_old:
        expr = "COALESCE(NULLIF(CAST(sales_group_name AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.sales_group_name"

    return None, None


# -----------------------------
# â˜… v1.4.9 ColMapï¼ˆåˆ—åå¸åï¼‰
# -----------------------------
@st.cache_data(ttl=3600)
def resolve_unified_colmap(_client: bigquery.Client) -> Dict[str, str]:
    """
    VIEW_UNIFIED ã®åˆ—åæºã‚Œã‚’å¸åã—ã¦ã€SQLã‹ã‚‰å‚ç…§ã™ã‚‹ã€Œè«–ç†ã‚­ãƒ¼â†’ç‰©ç†åˆ—åã€ã‚’è¿”ã™ã€‚
    â€» BigQueryã¯æœªã‚¯ã‚ªãƒ¼ãƒˆè­˜åˆ¥å­ã¯å¤§æ–‡å­—å°æ–‡å­—éåŒºåˆ¥ãªã®ã§ã€lowerã§è¿”ã™ã€‚
    """
    cols = get_unified_columns(_client)

    def pick(*cands: str) -> Optional[str]:
        for c in cands:
            if c.lower() in cols:
                return c.lower()
        return None

    colmap: Dict[str, Optional[str]] = {
        # ä¸»è¦ã‚­ãƒ¼
        "customer_code": pick("customer_code", "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", "å¾—æ„å…ˆCD"),
        "customer_name": pick("customer_name", "å¾—æ„å…ˆå"),
        "login_email": pick("login_email", "email", "æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«", "æ‹…å½“ãƒ¡ãƒ¼ãƒ«", "login"),
        # æ—¥ä»˜ãƒ»å¹´åº¦ãƒ»é‡‘é¡
        "sales_date": pick("sales_date", "è²©å£²æ—¥", "date"),
        "fiscal_year": pick("fiscal_year", "å¹´åº¦", "fy"),
        "sales_amount": pick("sales_amount", "å£²ä¸Š", "åˆè¨ˆä¾¡æ ¼", "sales"),
        "gross_profit": pick("gross_profit", "ç²—åˆ©", "gp"),
        # å•†å“ç³»
        "product_name": pick("product_name", "å•†å“å", "å•†å“åç§°", "item_name", "å•†å“åç§°"),
        "yj_code": pick("yj_code", "yjcode", "yj", "YJCode"),
        "jan_code": pick("jan_code", "jan", "JAN"),
        "package_unit": pick("package_unit", "pack_unit", "åŒ…è£…å˜ä½", "åŒ…è£…"),
    }

    # Optionalï¼ˆç„¡ãã¦ã‚‚æ­¢ã‚ãªã„ï¼‰
    opt = {
        "staff_name": pick("staff_name", "æ‹…å½“è€…å", "æ‹…å½“ç¤¾å“¡å", "æ‹…å½“ç¤¾å“¡æ°", "æ‹…å½“"),
    }

    # å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯ï¼ˆã“ã“ãŒç„¡ã„ã¨ã‚¢ãƒ—ãƒªãŒæˆç«‹ã—ãªã„ï¼‰
    required = ["customer_code", "customer_name", "sales_date", "fiscal_year", "sales_amount", "gross_profit", "product_name"]
    missing = [k for k in required if not colmap.get(k)]
    if missing:
        colmap["_missing_required"] = ",".join(missing)

    # opt merge
    colmap.update({k: v for k, v in opt.items() if v})
    # Optional ã‚‚ None ã¯æ¨ã¦ã‚‹
    return {k: v for k, v in colmap.items() if v is not None}


def c(colmap: Dict[str, str], key: str) -> str:
    """SQLå†…ã§ä½¿ã†åˆ—åè§£æ±ºã€‚å¿…é ˆåˆ—ãŒç„¡ã„å ´åˆã‚‚ã“ã“ã§ã¯è½ã¨ã•ãªã„ï¼ˆèµ·å‹•å‰ã«æ­¢ã‚ã‚‹ï¼‰ã€‚"""
    return colmap.get(key, key)


def render_scope_filters(client: bigquery.Client, role: RoleInfo) -> ScopeFilter:
    st.markdown("### ğŸ” åˆ†æã‚¹ã‚³ãƒ¼ãƒ—è¨­å®š")
    predicates: list[str] = []
    params: Dict[str, Any] = {}

    with st.expander("è©³ç´°çµã‚Šè¾¼ã¿ï¼ˆå¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ—ãƒ»å¾—æ„å…ˆåï¼‰", expanded=False):
        c1, c2 = st.columns(2)

        group_expr, group_src = resolve_customer_group_sql_expr(client)
        if group_expr:
            role_where = ""
            role_params: Dict[str, Any] = {}
            if not role.role_admin_view:
                role_where = "WHERE login_email = @login_email"
                role_params["login_email"] = role.login_email

            sql_group = f"""
                SELECT DISTINCT {group_expr} AS group_name
                FROM `{VIEW_UNIFIED}`
                {role_where}
                ORDER BY group_name
                LIMIT 500
            """
            df_group = query_df_safe(client, sql_group, role_params, "Scope Group Options")
            group_opts = ["æŒ‡å®šãªã—"] + (df_group["group_name"].tolist() if not df_group.empty else [])
            selected_group = c1.selectbox("å¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ—", options=group_opts)
            if selected_group != "æŒ‡å®šãªã—":
                predicates.append(f"{group_expr} = @scope_group")
                params["scope_group"] = selected_group

            if group_src:
                c1.caption(f"æŠ½å‡ºå…ƒ: `{group_src}`")
        else:
            c1.caption("ã‚°ãƒ«ãƒ¼ãƒ—åˆ—ãªã—ï¼ˆVIEW_UNIFIEDã«è©²å½“åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼‰")

        keyword = c2.text_input("å¾—æ„å…ˆåï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", placeholder="ä¾‹ï¼šå¤è³€ç—…é™¢")
        if keyword.strip():
            predicates.append("customer_name LIKE @scope_customer_name")
            params["scope_customer_name"] = f"%{keyword.strip()}%"

    return ScopeFilter(predicates=tuple(predicates), params=params)


def resolve_role(client: bigquery.Client, login_email: str, login_code: str) -> RoleInfo:
    if not login_email or not login_code:
        return RoleInfo()

    has_login_code = role_table_has_login_code(client)

    if has_login_code:
        sql = f"""
            SELECT login_email, role_tier
            FROM `{VIEW_ROLE_CLEAN}`
            WHERE login_email = @login_email
              AND CAST(login_code AS STRING) = @login_code
            LIMIT 1
        """
        params: Dict[str, Any] = {"login_email": login_email, "login_code": login_code}
    else:
        sql = f"""
            SELECT login_email, role_tier
            FROM `{VIEW_ROLE_CLEAN}`
            WHERE login_email = @login_email
            LIMIT 1
        """
        params = {"login_email": login_email}

    df = query_df_safe(client, sql, params, "Auth Check")
    if df.empty:
        return RoleInfo(login_email=login_email)

    row = df.iloc[0]
    raw_role = str(row["role_tier"]).strip().upper()
    is_admin = any(x in raw_role for x in ["ADMIN", "MANAGER", "HQ"])

    return RoleInfo(
        is_authenticated=True,
        login_email=login_email,
        staff_name=login_email.split("@")[0],
        role_key="HQ_ADMIN" if is_admin else "SALES",
        role_admin_view=is_admin,
        phone="-",
    )


# -----------------------------
# 4. UI Sections (å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³)
# -----------------------------
def render_summary_metrics(row: pd.Series) -> None:
    s_cur = get_safe_float(row, "sales_amount_fytd")
    s_py_ytd = get_safe_float(row, "sales_amount_py_ytd")
    s_py_total = get_safe_float(row, "sales_amount_py_total")

    s_fc = s_cur * (s_py_total / s_py_ytd) if s_py_ytd > 0 else s_cur

    gp_cur = get_safe_float(row, "gross_profit_fytd")
    gp_py_ytd = get_safe_float(row, "gross_profit_py_ytd")
    gp_py_total = get_safe_float(row, "gross_profit_py_total")
    gp_fc = gp_cur * (gp_py_total / gp_py_ytd) if gp_py_ytd > 0 else gp_cur

    st.caption(
        "â€» ã€ä»ŠæœŸäºˆæ¸¬ã€‘ã¯AIäºˆæ¸¬ã§ã¯ãªãã€ã€Œä»ŠæœŸå®Ÿç¸¾ Ã— (æ˜¨å¹´åº¦ç€åœ° Ã· å‰å¹´åŒæœŸ)ã€"
        "ã«ã‚ˆã‚‹å­£ç¯€å¤‰å‹•ã‚’åŠ å‘³ã—ãŸæ¨ç§»ãƒšãƒ¼ã‚¹ï¼ˆç€åœ°è¦‹è¾¼ï¼‰ã§ã™ã€‚"
    )

    st.markdown("##### â–  å£²ä¸Š")
    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("â‘  ä»ŠæœŸç´¯è¨ˆ", f"Â¥{s_cur:,.0f}")
    c2.metric("â‘¡ å‰å¹´åŒæœŸ", f"Â¥{s_py_ytd:,.0f}", delta=f"{int(s_cur - s_py_ytd):,}" if s_py_ytd > 0 else None)
    c3.metric("â‘¢ æ˜¨å¹´åº¦ç€åœ°", f"Â¥{s_py_total:,.0f}")
    c4.metric("â‘£ ä»ŠæœŸäºˆæ¸¬", f"Â¥{s_fc:,.0f}")
    c5.metric("â‘¤ ç€åœ°GAP", f"Â¥{s_fc - s_py_total:,.0f}", delta=f"{int(s_fc - s_py_total):,}")

    st.markdown("##### â–  ç²—åˆ©")
    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("â‘  ä»ŠæœŸç´¯è¨ˆ", f"Â¥{gp_cur:,.0f}")
    c2.metric("â‘¡ å‰å¹´åŒæœŸ", f"Â¥{gp_py_ytd:,.0f}", delta=f"{int(gp_cur - gp_py_ytd):,}" if gp_py_ytd > 0 else None)
    c3.metric("â‘¢ æ˜¨å¹´åº¦ç€åœ°", f"Â¥{gp_py_total:,.0f}")
    c4.metric("â‘£ ä»ŠæœŸäºˆæ¸¬", f"Â¥{gp_fc:,.0f}")
    c5.metric("â‘¤ ç€åœ°GAP", f"Â¥{gp_fc - gp_py_total:,.0f}", delta=f"{int(gp_fc - gp_py_total):,}")


def render_fytd_org_section(client: bigquery.Client, colmap: Dict[str, str]) -> None:
    st.subheader("ğŸ¢ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå…¨ç¤¾ã‚µãƒãƒªãƒ¼")

    if "org_data_loaded" not in st.session_state:
        st.session_state.org_data_loaded = False

    if st.button("å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_org_load"):
        st.session_state.org_data_loaded = True

    if st.session_state.get("org_data_loaded"):
        sql = f"""
            WITH today_info AS (
              SELECT
                CURRENT_DATE('Asia/Tokyo') AS today,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today,
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                    - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
            )
            SELECT
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_fytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_fytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_py_ytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_py_ytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_py_total,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_py_total
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN today_info
        """
        df_org = query_df_safe(client, sql, None, "Org Summary")
        if not df_org.empty:
            render_summary_metrics(df_org.iloc[0])


def render_fytd_me_section(client: bigquery.Client, login_email: str, colmap: Dict[str, str]) -> None:
    st.subheader("ğŸ‘¤ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå€‹äººã‚µãƒãƒªãƒ¼")
    if st.button("è‡ªåˆ†ã®æˆç¸¾ã‚’èª­ã¿è¾¼ã‚€", key="btn_me_load"):
        sql = f"""
            WITH today_info AS (
              SELECT
                CURRENT_DATE('Asia/Tokyo') AS today,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today,
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                    - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
            )
            SELECT
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_fytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_fytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_py_ytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_py_ytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_py_total,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_py_total
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN today_info
            WHERE {c(colmap,'login_email')} = @login_email
        """
        df_me = query_df_safe(client, sql, {"login_email": login_email}, "Me Summary")
        if not df_me.empty:
            render_summary_metrics(df_me.iloc[0])


def render_group_underperformance_section(
    client: bigquery.Client,
    role: RoleInfo,
    scope: ScopeFilter,
    colmap: Dict[str, str],
) -> None:
    st.subheader("ğŸ¢ å¾—æ„å…ˆãƒ»ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ï¼† è¦å› åˆ†æ")

    if "group_perf_mode" not in st.session_state:
        st.session_state.group_perf_mode = "ãƒ¯ãƒ¼ã‚¹ãƒˆ"

    c1, c2 = st.columns(2)
    view_choice = c1.radio("ğŸ“Š åˆ†æã®å˜ä½", ["ğŸ¢ ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥", "ğŸ¥ å¾—æ„å…ˆå˜ä½“"], horizontal=True)
    mode_choice = c2.radio("ğŸ† ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŸºæº–", ["ğŸ“‰ ä¸‹è½å¹…ãƒ¯ãƒ¼ã‚¹ãƒˆ", "ğŸ“ˆ ä¸Šæ˜‡å¹…ãƒ™ã‚¹ãƒˆ"], horizontal=True)

    perf_view = "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" if "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" in view_choice else "å¾—æ„å…ˆåˆ¥"
    perf_mode = "ãƒ¯ãƒ¼ã‚¹ãƒˆ" if "ãƒ¯ãƒ¼ã‚¹ãƒˆ" in mode_choice else "ãƒ™ã‚¹ãƒˆ"
    sort_order = "ASC" if perf_mode == "ãƒ¯ãƒ¼ã‚¹ãƒˆ" else "DESC"

    group_expr, group_src = resolve_customer_group_sql_expr(client)
    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" and not group_expr:
        st.info("ã‚°ãƒ«ãƒ¼ãƒ—åˆ†æã«åˆ©ç”¨ã§ãã‚‹åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆVIEW_UNIFIEDã«ã‚°ãƒ«ãƒ¼ãƒ—åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚")
        return

    role_filter = "" if role.role_admin_view else f"{c(colmap,'login_email')} = @login_email"
    scope_filter_clause = scope.where_clause().replace("customer_name", c(colmap, "customer_name"))
    filter_sql = _compose_where(role_filter, scope_filter_clause)

    params: Dict[str, Any] = dict(scope.params or {})
    if not role.role_admin_view:
        params["login_email"] = role.login_email

    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥":
        sql_parent = f"""
            WITH fy AS (
              SELECT
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                 - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
            )
            SELECT
              {group_expr} AS `åç§°`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS `ä»ŠæœŸå£²ä¸Š`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'sales_amount')} ELSE 0 END) AS `å‰å¹´åŒæœŸå£²ä¸Š`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'gross_profit')} ELSE 0 END) AS `ä»ŠæœŸç²—åˆ©`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'gross_profit')} ELSE 0 END) AS `å‰å¹´åŒæœŸç²—åˆ©`
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN fy
            {filter_sql}
            GROUP BY `åç§°`
            HAVING `å‰å¹´åŒæœŸå£²ä¸Š` > 0 OR `ä»ŠæœŸå£²ä¸Š` > 0
            ORDER BY (`ä»ŠæœŸå£²ä¸Š` - `å‰å¹´åŒæœŸå£²ä¸Š`) {sort_order}
            LIMIT 50
        """
    else:
        sql_parent = f"""
            WITH fy AS (
              SELECT
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                 - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
            )
            SELECT
              {c(colmap,'customer_code')} AS `ã‚³ãƒ¼ãƒ‰`,
              ANY_VALUE({c(colmap,'customer_name')}) AS `åç§°`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS `ä»ŠæœŸå£²ä¸Š`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'sales_amount')} ELSE 0 END) AS `å‰å¹´åŒæœŸå£²ä¸Š`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'gross_profit')} ELSE 0 END) AS `ä»ŠæœŸç²—åˆ©`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'gross_profit')} ELSE 0 END) AS `å‰å¹´åŒæœŸç²—åˆ©`
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN fy
            {filter_sql}
            GROUP BY `ã‚³ãƒ¼ãƒ‰`
            HAVING `å‰å¹´åŒæœŸå£²ä¸Š` > 0 OR `ä»ŠæœŸå£²ä¸Š` > 0
            ORDER BY (`ä»ŠæœŸå£²ä¸Š` - `å‰å¹´åŒæœŸå£²ä¸Š`) {sort_order}
            LIMIT 50
        """

    df_parent = query_df_safe(client, sql_parent, params, f"Parent Perf {perf_view}")
    if df_parent.empty:
        st.info("è¡¨ç¤ºã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df_parent["å£²ä¸Šå·®é¡"] = df_parent["ä»ŠæœŸå£²ä¸Š"] - df_parent["å‰å¹´åŒæœŸå£²ä¸Š"]
    df_parent["å£²ä¸Šæˆé•·ç‡"] = df_parent.apply(
        lambda r: ((r["ä»ŠæœŸå£²ä¸Š"] / r["å‰å¹´åŒæœŸå£²ä¸Š"] - 1) * 100) if r["å‰å¹´åŒæœŸå£²ä¸Š"] else 0,
        axis=1,
    )
    df_parent["ç²—åˆ©å·®é¡"] = df_parent["ä»ŠæœŸç²—åˆ©"] - df_parent["å‰å¹´åŒæœŸç²—åˆ©"]

    def get_parent_rank_icon(rank: int, mode: str) -> str:
        if mode == "ãƒ™ã‚¹ãƒˆ":
            if rank == 1:
                return "ğŸ¥‡ 1ä½"
            if rank == 2:
                return "ğŸ¥ˆ 2ä½"
            if rank == 3:
                return "ğŸ¥‰ 3ä½"
            return f"ğŸŒŸ {rank}ä½"
        else:
            if rank == 1:
                return "ğŸš¨ 1ä½"
            if rank == 2:
                return "âš ï¸ 2ä½"
            if rank == 3:
                return "âš¡ 3ä½"
            return f"ğŸ“‰ {rank}ä½"

    df_parent.insert(0, "é †ä½", [get_parent_rank_icon(i + 1, perf_mode) for i in range(len(df_parent))])

    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" and group_src:
        st.caption(f"æŠ½å‡ºå…ƒã‚°ãƒ«ãƒ¼ãƒ—åˆ—: `{group_src}`")

    event = st.dataframe(
        df_parent.style.format(
            {
                "ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}",
                "å‰å¹´åŒæœŸå£²ä¸Š": "Â¥{:,.0f}",
                "ä»ŠæœŸç²—åˆ©": "Â¥{:,.0f}",
                "å‰å¹´åŒæœŸç²—åˆ©": "Â¥{:,.0f}",
                "å£²ä¸Šå·®é¡": "Â¥{:,.0f}",
                "å£²ä¸Šæˆé•·ç‡": "{:.1f}%",
                "ç²—åˆ©å·®é¡": "Â¥{:,.0f}",
            }
        ),
        use_container_width=True,
        hide_index=True,
        selection_mode="single-row",
        on_select="rerun",
        key=f"grid_parent_{perf_view}_{perf_mode}",
    )

    selected_parent_id = None
    selected_parent_name = None

    try:
        sel_rows = []
        if hasattr(event, "selection") and hasattr(event.selection, "rows"):
            sel_rows = event.selection.rows
        elif isinstance(event, dict) and "selection" in event:
            sel_rows = event["selection"].get("rows", [])

        if sel_rows:
            idx = sel_rows[0]
            if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥":
                selected_parent_id = str(df_parent.iloc[idx]["åç§°"])
                selected_parent_name = selected_parent_id
            else:
                selected_parent_id = str(df_parent.iloc[idx]["ã‚³ãƒ¼ãƒ‰"])
                selected_parent_name = str(df_parent.iloc[idx]["åç§°"])
    except Exception:
        pass

    if selected_parent_id:
        st.markdown(f"#### ğŸ” ã€{selected_parent_name}ã€‘è¦å› åˆ†æï¼ˆå•†å“ãƒ™ãƒ¼ã‚¹ {perf_mode}ãƒ»å…¨ä»¶ä¸€è¦§ï¼‰")

        drill_params = dict(params)

        if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥":
            drill_filter_sql = _compose_where(
                role_filter,
                scope_filter_clause,
                f"{group_expr} = @parent_id",
            )
        else:
            drill_filter_sql = _compose_where(
                role_filter,
                scope_filter_clause,
                f"{c(colmap,'customer_code')} = @parent_id",
            )

        drill_params["parent_id"] = selected_parent_id

        sql_drill = f"""
            WITH fy AS (
              SELECT (
                EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END
              ) AS current_fy,
              DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
            ),
            base_raw AS (
              SELECT
                COALESCE(
                  NULLIF(NULLIF(TRIM(CAST({c(colmap,'yj_code')} AS STRING)), ''), '0'),
                  NULLIF(NULLIF(TRIM(CAST({c(colmap,'jan_code')} AS STRING)), ''), '0'),
                  TRIM(CAST({c(colmap,'product_name')} AS STRING))
                ) AS yj_key,
                REGEXP_REPLACE(CAST({c(colmap,'product_name')} AS STRING), r"[/ï¼].*$", "") AS product_base,
                SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS ty_sales,
                SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'sales_amount')} ELSE 0 END) AS py_sales
              FROM `{VIEW_UNIFIED}`
              CROSS JOIN fy
              {drill_filter_sql}
              GROUP BY yj_key, product_base
            ),
            base AS (
              SELECT
                yj_key AS yj_code,
                ARRAY_AGG(product_base ORDER BY ty_sales DESC LIMIT 1)[OFFSET(0)] AS product_name,
                SUM(ty_sales) AS ty_sales,
                SUM(py_sales) AS py_sales
              FROM base_raw
              GROUP BY yj_code
            )
            SELECT
              yj_code,
              product_name,
              ty_sales AS sales_amount,
              py_sales AS py_sales_amount,
              (ty_sales - py_sales) AS sales_diff_yoy
            FROM base
            WHERE ty_sales > 0 OR py_sales > 0
            ORDER BY sales_diff_yoy {sort_order}
        """
        df_drill = query_df_safe(client, sql_drill, drill_params, "Parent Drilldown")

        if not df_drill.empty:
            df_drill["product_name"] = df_drill["product_name"].apply(normalize_product_display_name)
            df_drill = df_drill.fillna(0)

            df_drill.insert(0, "è¦å› é †ä½", [get_parent_rank_icon(i + 1, perf_mode) for i in range(len(df_drill))])

            st.dataframe(
                df_drill[["è¦å› é †ä½", "product_name", "sales_amount", "py_sales_amount", "sales_diff_yoy"]].rename(
                    columns={
                        "product_name": "ä»£è¡¨å•†å“å(æˆåˆ†)",
                        "sales_amount": "ä»ŠæœŸå£²ä¸Š",
                        "py_sales_amount": "å‰å¹´åŒæœŸå£²ä¸Š",
                        "sales_diff_yoy": "å‰å¹´æ¯”å·®é¡",
                    }
                ).style.format(
                    {"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´åŒæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´æ¯”å·®é¡": "Â¥{:,.0f}"}
                ),
                use_container_width=True,
                hide_index=True,
            )
        else:
            st.info("è¦å› ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")


def render_yoy_section(client: bigquery.Client, login_email: str, is_admin: bool, scope: ScopeFilter, colmap: Dict[str, str]) -> None:
    st.subheader("ğŸ“Š å¹´é–“ YoY ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆæˆåˆ†ãƒ»YJå„ªå…ˆï½œYJ=0/nullã¯JANã‚­ãƒ¼ã§è¿½è·¡ï¼‰")

    if "yoy_mode" not in st.session_state:
        st.session_state.yoy_mode = "ãƒ¯ãƒ¼ã‚¹ãƒˆ"
    if "yoy_df" not in st.session_state:
        st.session_state.yoy_df = pd.DataFrame()
    if "selected_yoy_key" not in st.session_state:
        st.session_state.selected_yoy_key = "å…¨æˆåˆ†ã‚’è¡¨ç¤º"

    c1, c2, c3 = st.columns(3)

    def load_yoy(mode_name: str) -> None:
        st.session_state.yoy_mode = mode_name

        role_filter = "" if is_admin else f"{c(colmap,'login_email')} = @login_email"
        scope_where = scope.where_clause().replace("customer_name", c(colmap, "customer_name"))
        where_sql = _compose_where(role_filter, scope_where)

        params: Dict[str, Any] = dict(scope.params or {})
        if not is_admin:
            params["login_email"] = login_email

        if mode_name == "ãƒ¯ãƒ¼ã‚¹ãƒˆ":
            diff_filter = "py_sales > 0 AND (ty_sales - py_sales) < 0"
            order_by = "sales_diff_yoy ASC"
        elif mode_name == "ãƒ™ã‚¹ãƒˆ":
            diff_filter = "py_sales > 0 AND (ty_sales - py_sales) > 0"
            order_by = "sales_diff_yoy DESC"
        else:
            diff_filter = "py_sales = 0 AND ty_sales > 0"
            order_by = "ty_sales DESC"

        sql = f"""
            WITH fy AS (
              SELECT
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                 - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
            ),
            base_raw AS (
              SELECT
                COALESCE(
                  NULLIF(NULLIF(TRIM(CAST({c(colmap,'yj_code')} AS STRING)), ''), '0'),
                  NULLIF(NULLIF(TRIM(CAST({c(colmap,'jan_code')} AS STRING)), ''), '0'),
                  REGEXP_REPLACE(CAST({c(colmap,'product_name')} AS STRING), r"[/ï¼].*$", "")
                ) AS yj_key,
                REGEXP_REPLACE(CAST({c(colmap,'product_name')} AS STRING), r"[/ï¼].*$", "") AS product_base,
                SUM(CASE WHEN {c(colmap,'fiscal_year')} = fy.current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS ty_sales,
                SUM(CASE WHEN {c(colmap,'fiscal_year')} = fy.current_fy - 1 THEN {c(colmap,'sales_amount')} ELSE 0 END) AS py_sales
              FROM `{VIEW_UNIFIED}`
              CROSS JOIN fy
              {where_sql}
              GROUP BY yj_key, product_base
            ),
            base AS (
              SELECT
                yj_key,
                ARRAY_AGG(product_base ORDER BY ty_sales DESC LIMIT 1)[OFFSET(0)] AS product_name,
                SUM(ty_sales) AS ty_sales,
                SUM(py_sales) AS py_sales
              FROM base_raw
              GROUP BY yj_key
            )
            SELECT
              yj_key,
              product_name,
              ty_sales,
              py_sales,
              (ty_sales - py_sales) AS sales_diff_yoy
            FROM base
            WHERE {diff_filter}
            ORDER BY {order_by}
            LIMIT 100
        """
        st.session_state.yoy_df = query_df_safe(client, sql, params, f"YoY Load {mode_name}")

    with c1:
        if st.button("ğŸ“‰ ä¸‹è½å¹…ãƒ¯ãƒ¼ã‚¹ãƒˆ", use_container_width=True):
            load_yoy("ãƒ¯ãƒ¼ã‚¹ãƒˆ")
    with c2:
        if st.button("ğŸ“ˆ ä¸Šæ˜‡å¹…ãƒ™ã‚¹ãƒˆ", use_container_width=True):
            load_yoy("ãƒ™ã‚¹ãƒˆ")
    with c3:
        if st.button("ğŸ†• æ–°è¦/æ¯”è¼ƒä¸èƒ½", use_container_width=True):
            load_yoy("æ–°è¦")

    if st.session_state.yoy_df.empty:
        st.info("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã‚€ã«ã¯ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
        return

    df_rank = st.session_state.yoy_df.copy()
    df_rank["product_name"] = df_rank["product_name"].apply(normalize_product_display_name)

    st.markdown(f"#### ğŸ† ç¬¬ä¸€éšå±¤ï¼šæˆåˆ†ã‚­ãƒ¼ï¼ˆYJå„ªå…ˆï¼‰{st.session_state.yoy_mode} ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    event = st.dataframe(
        df_rank[["product_name", "ty_sales", "py_sales", "sales_diff_yoy"]].rename(
            columns={
                "product_name": "ä»£è¡¨å•†å“å(æˆåˆ†)",
                "ty_sales": "ä»ŠæœŸå£²ä¸Š",
                "py_sales": "å‰æœŸå£²ä¸Š",
                "sales_diff_yoy": "å‰å¹´æ¯”å·®é¡",
            }
        ).style.format({"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´æ¯”å·®é¡": "Â¥{:,.0f}"}),
        use_container_width=True,
        hide_index=True,
        selection_mode="single-row",
        on_select="rerun",
        key=f"grid_yoy_{st.session_state.yoy_mode}",
    )

    try:
        sel_rows = event.selection.rows if hasattr(event, "selection") else []
        if sel_rows:
            st.session_state.selected_yoy_key = str(df_rank.iloc[sel_rows[0]]["yj_key"])
    except Exception:
        pass

    st.divider()

    st.header("ğŸ” ç¬¬äºŒéšå±¤ï¼šè©³ç´°åˆ†æï¼ˆã‚¹ã‚³ãƒ¼ãƒ—å†…ï¼‰")

    key_opts = ["å…¨æˆåˆ†ã‚’è¡¨ç¤º"] + list(df_rank["yj_key"].astype(str).unique())
    display_map = {"å…¨æˆåˆ†ã‚’è¡¨ç¤º": "ğŸš© ã‚¹ã‚³ãƒ¼ãƒ—å†…ã®å…¨æˆåˆ†ã‚’åˆè¨ˆã—ã¦è¡¨ç¤º"}
    for _, r in df_rank.iterrows():
        k = str(r["yj_key"])
        display_map[k] = f"{normalize_product_display_name(r['product_name'])}ï¼ˆå·®é¡: Â¥{r['sales_diff_yoy']:,.0f}ï¼‰"

    idx = 0
    if st.session_state.selected_yoy_key in key_opts:
        idx = key_opts.index(st.session_state.selected_yoy_key)

    selected_key = st.selectbox(
        "è©³ç´°ã‚’è¦‹ãŸã„æˆåˆ†ã‚­ãƒ¼ã‚’é¸æŠï¼ˆ[å…¨æˆåˆ†ã‚’è¡¨ç¤º]ã§å…¨é‡ï¼‰",
        options=key_opts,
        index=idx,
        format_func=lambda x: display_map.get(x, x),
    )
    st.session_state.selected_yoy_key = selected_key

    role_filter = "" if is_admin else f"{c(colmap,'login_email')} = @login_email"
    scope_where = scope.where_clause().replace("customer_name", c(colmap, "customer_name"))

    params: Dict[str, Any] = dict(scope.params or {})
    if not is_admin:
        params["login_email"] = login_email

    key_filter = ""
    if selected_key != "å…¨æˆåˆ†ã‚’è¡¨ç¤º":
        key_expr = f"""
          COALESCE(
            NULLIF(NULLIF(TRIM(CAST({c(colmap,'yj_code')} AS STRING)), ''), '0'),
            NULLIF(NULLIF(TRIM(CAST({c(colmap,'jan_code')} AS STRING)), ''), '0'),
            REGEXP_REPLACE(CAST({c(colmap,'product_name')} AS STRING), r"[/ï¼].*$", "")
          )
        """
        key_filter = f"{' '.join(key_expr.split())} = @target_key"
        params["target_key"] = selected_key

    where_sql = _compose_where(role_filter, scope_where, key_filter)
    sort_order = "ASC" if st.session_state.yoy_mode == "ãƒ¯ãƒ¼ã‚¹ãƒˆ" else "DESC"

    st.markdown("#### ğŸ§¾ å¾—æ„å…ˆåˆ¥å†…è¨³ï¼ˆå‰å¹´å·®é¡ï¼‰")
    sql_cust = f"""
      WITH fy AS (
        SELECT
          (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
           - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
      ),
      base AS (
        SELECT
          {c(colmap,'customer_name')} AS customer_name,
          SUM(CASE WHEN {c(colmap,'fiscal_year')} = fy.current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS ty_sales,
          SUM(CASE WHEN {c(colmap,'fiscal_year')} = fy.current_fy - 1 THEN {c(colmap,'sales_amount')} ELSE 0 END) AS py_sales
        FROM `{VIEW_UNIFIED}`
        CROSS JOIN fy
        {where_sql}
        GROUP BY customer_name
      )
      SELECT
        customer_name AS `å¾—æ„å…ˆå`,
        ty_sales AS `ä»ŠæœŸå£²ä¸Š`,
        py_sales AS `å‰æœŸå£²ä¸Š`,
        (ty_sales - py_sales) AS `å‰å¹´å·®é¡`
      FROM base
      WHERE ty_sales != 0 OR py_sales != 0
      ORDER BY `å‰å¹´å·®é¡` {sort_order}
      LIMIT 50
    """
    df_cust = query_df_safe(client, sql_cust, params, "YoY Detail Customers")
    if not df_cust.empty:
        st.dataframe(
            df_cust.fillna(0).style.format(
                {"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´å·®é¡": "Â¥{:,.0f}"}
            ),
            use_container_width=True,
            hide_index=True,
        )
    else:
        st.info("å¾—æ„å…ˆåˆ¥å†…è¨³ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    st.markdown("#### ğŸ§ª åŸå› è¿½åŠï¼šJANãƒ»å•†å“åˆ¥ï¼ˆå‰å¹´å·®é¡å¯„ä¸ï¼‰")
    sql_jan = f"""
      WITH fy AS (
        SELECT
          (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
           - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
      ),
      base AS (
        SELECT
          CAST({c(colmap,'jan_code')} AS STRING) AS jan,
          REGEXP_REPLACE(CAST({c(colmap,'product_name')} AS STRING), r"[/ï¼].*$", "") AS product_base,
          CAST({c(colmap,'package_unit')} AS STRING) AS package_unit,
          SUM(CASE WHEN {c(colmap,'fiscal_year')} = fy.current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS ty_sales,
          SUM(CASE WHEN {c(colmap,'fiscal_year')} = fy.current_fy - 1 THEN {c(colmap,'sales_amount')} ELSE 0 END) AS py_sales
        FROM `{VIEW_UNIFIED}`
        CROSS JOIN fy
        {where_sql}
        GROUP BY jan, product_base, package_unit
      )
      SELECT
        jan AS `JAN`,
        product_base AS `ä»£è¡¨å•†å“å`,
        package_unit AS `åŒ…è£…`,
        ty_sales AS `ä»ŠæœŸå£²ä¸Š`,
        py_sales AS `å‰æœŸå£²ä¸Š`,
        (ty_sales - py_sales) AS `å‰å¹´å·®é¡`
      FROM base
      WHERE ty_sales != 0 OR py_sales != 0
      ORDER BY `å‰å¹´å·®é¡` {sort_order}
    """
    df_jan = query_df_safe(client, sql_jan, params, "YoY Detail JAN")
    if not df_jan.empty:
        st.dataframe(
            df_jan.fillna(0).style.format(
                {"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´å·®é¡": "Â¥{:,.0f}"}
            ),
            use_container_width=True,
            hide_index=True,
        )
    else:
        st.info("JANåˆ¥å†…è¨³ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    st.markdown("#### ğŸ“… åŸå› è¿½åŠï¼šæœˆæ¬¡æ¨ç§»ï¼ˆå‰å¹´å·®é¡ï¼‰")
    sql_month = f"""
      WITH fy AS (
        SELECT
          (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
           - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
      ),
      base AS (
        SELECT
          FORMAT_DATE('%Y-%m', {c(colmap,'sales_date')}) AS ym,
          SUM(CASE WHEN {c(colmap,'fiscal_year')} = fy.current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS ty_sales,
          SUM(CASE WHEN {c(colmap,'fiscal_year')} = fy.current_fy - 1 THEN {c(colmap,'sales_amount')} ELSE 0 END) AS py_sales
        FROM `{VIEW_UNIFIED}`
        CROSS JOIN fy
        {where_sql}
        GROUP BY ym
      )
      SELECT
        ym AS `å¹´æœˆ`,
        ty_sales AS `ä»ŠæœŸå£²ä¸Š`,
        py_sales AS `å‰æœŸå£²ä¸Š`,
        (ty_sales - py_sales) AS `å‰å¹´å·®é¡`
      FROM base
      ORDER BY `å¹´æœˆ`
    """
    df_month = query_df_safe(client, sql_month, params, "YoY Detail Month")
    if not df_month.empty:
        st.dataframe(
            df_month.fillna(0).style.format(
                {"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´å·®é¡": "Â¥{:,.0f}"}
            ),
            use_container_width=True,
            hide_index=True,
        )
    else:
        st.info("æœˆæ¬¡æ¨ç§»ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")


# -----------------------------
# â˜… v1.4.10 æ–°è¦ç´å“ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆè¿½åŠ ï¼‰
# -----------------------------
def _render_df_money(df: pd.DataFrame, money_cols: list[str]) -> None:
    fmt = {}
    for col in money_cols:
        if col in df.columns:
            fmt[col] = "Â¥{:,.0f}"
    st.dataframe(df.fillna(0).style.format(fmt), use_container_width=True, hide_index=True)


def render_new_deliveries_section(client: bigquery.Client, login_email: str, is_admin: bool, colmap: Dict[str, str]) -> None:
    st.subheader("ğŸ‰ æ–°è¦ç´å“ã‚µãƒãƒªãƒ¼ï¼ˆRealized / å®Ÿç¸¾ï¼‰")

    # â‘  æœŸé–“è¨­å®šï¼ˆUIã¯è»½ãã€å‡¦ç†ãƒ«ãƒ¼ãƒˆã¯å¢—ã‚„ã•ãªã„ï¼‰
    c1, c2, c3 = st.columns([1, 1, 2])
    window_days = int(c1.selectbox("ãƒˆãƒ¬ãƒ³ãƒ‰æ¯”è¼ƒã®çª“ï¼ˆæ—¥æ•°ï¼‰", options=[7, 14, 30], index=1))
    top_n = int(c2.selectbox("è¡¨ç¤ºä»¶æ•°", options=[10, 20, 50], index=1))
    c3.caption("ç›´è¿‘Næ—¥ vs ãã®å‰Næ—¥ã§ã€Œæ–°è¦ç´å“ãŒå¢—ãˆãŸã€å¯¾è±¡ã‚’æŠ½å‡ºï¼ˆå¢—åˆ†ãƒ†ãƒ¼ãƒ–ãƒ«ã¯ä½œã‚‰ãªã„ï¼‰")

    if not st.button("æ–°è¦ç´å“ï¼ˆã‚µãƒãƒªãƒ¼ï¼‹ãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰ã‚’èª­ã¿è¾¼ã‚€", key="btn_new_deliv"):
        return

    # VIEW_NEW_DELIVERY å´ã¯å›ºå®šåˆ—å‰æï¼šcustomer_code, customer_name, jan_code, product_name, first_sales_date, sales_amount, gross_profit, login_email
    where_ext = "" if is_admin else "AND login_email = @login_email"
    params = None if is_admin else {"login_email": login_email}

    # â‘¡ ã‚µãƒãƒªãƒ¼ï¼ˆæ—¢å­˜è¸è¥²ï¼‰
    sql_summary = f"""
    WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today)
    SELECT
      'â‘  æ˜¨æ—¥' AS `æœŸé–“`, COUNT(DISTINCT customer_code) AS `å¾—æ„å…ˆæ•°`, COUNT(DISTINCT jan_code) AS `å“ç›®æ•°`, SUM(sales_amount) AS `å£²ä¸Š`, SUM(gross_profit) AS `ç²—åˆ©`
    FROM `{VIEW_NEW_DELIVERY}` CROSS JOIN td WHERE first_sales_date = DATE_SUB(today, INTERVAL 1 DAY) {where_ext}
    UNION ALL
    SELECT 'â‘¡ ç›´è¿‘7æ—¥', COUNT(DISTINCT customer_code), COUNT(DISTINCT jan_code), SUM(sales_amount), SUM(gross_profit)
    FROM `{VIEW_NEW_DELIVERY}` CROSS JOIN td WHERE first_sales_date >= DATE_SUB(today, INTERVAL 7 DAY) {where_ext}
    UNION ALL
    SELECT 'â‘¢ å½“æœˆ', COUNT(DISTINCT customer_code), COUNT(DISTINCT jan_code), SUM(sales_amount), SUM(gross_profit)
    FROM `{VIEW_NEW_DELIVERY}` CROSS JOIN td WHERE DATE_TRUNC(first_sales_date, MONTH) = DATE_TRUNC(today, MONTH) {where_ext}
    ORDER BY `æœŸé–“`
    """
    df_new = query_df_safe(client, sql_summary, params, label="New Deliveries Summary")
    if not df_new.empty:
        df_new[["å£²ä¸Š", "ç²—åˆ©"]] = df_new[["å£²ä¸Š", "ç²—åˆ©"]].fillna(0)
        _render_df_money(df_new, ["å£²ä¸Š", "ç²—åˆ©"])
    else:
        st.info("æ–°è¦ç´å“ã‚µãƒãƒªãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    st.divider()

    # â‘¢ ãƒˆãƒ¬ãƒ³ãƒ‰ï¼šå¾—æ„å…ˆï¼ˆæ–°è¦ç´å“ãŒå¢—ãˆã¦ã„ã‚‹å¾—æ„å…ˆï¼‰
    st.markdown("### ğŸ“ˆ å¾—æ„å…ˆãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæ–°è¦ç´å“ãŒå¢—ãˆã¦ã„ã‚‹å¾—æ„å…ˆï¼‰")

    sql_customer_trend = f"""
    WITH td AS (
      SELECT
        CURRENT_DATE('Asia/Tokyo') AS today,
        DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL @w DAY) AS w_start,
        DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL @w*2 DAY) AS prev_start
    ),
    base AS (
      SELECT
        CAST(customer_code AS STRING) AS customer_code,
        ANY_VALUE(customer_name) AS customer_name,
        CASE
          WHEN first_sales_date >= (SELECT w_start FROM td) THEN 'recent'
          WHEN first_sales_date >= (SELECT prev_start FROM td) AND first_sales_date < (SELECT w_start FROM td) THEN 'prev'
          ELSE 'other'
        END AS bucket,
        jan_code,
        sales_amount,
        gross_profit
      FROM `{VIEW_NEW_DELIVERY}`
      CROSS JOIN td
      WHERE first_sales_date >= (SELECT prev_start FROM td)
        {where_ext}
    ),
    agg AS (
      SELECT
        customer_code,
        customer_name,
        SUM(CASE WHEN bucket='recent' THEN 1 ELSE 0 END) AS recent_rows,
        SUM(CASE WHEN bucket='prev' THEN 1 ELSE 0 END) AS prev_rows,
        COUNT(DISTINCT CASE WHEN bucket='recent' THEN jan_code END) AS recent_items,
        COUNT(DISTINCT CASE WHEN bucket='prev' THEN jan_code END) AS prev_items,
        SUM(CASE WHEN bucket='recent' THEN sales_amount ELSE 0 END) AS recent_sales,
        SUM(CASE WHEN bucket='prev' THEN sales_amount ELSE 0 END) AS prev_sales,
        SUM(CASE WHEN bucket='recent' THEN gross_profit ELSE 0 END) AS recent_gp,
        SUM(CASE WHEN bucket='prev' THEN gross_profit ELSE 0 END) AS prev_gp
      FROM base
      GROUP BY customer_code, customer_name
    )
    SELECT
      customer_code AS `å¾—æ„å…ˆCD`,
      customer_name AS `å¾—æ„å…ˆå`,
      recent_items AS `ç›´è¿‘{window_days}æ—¥_æ–°è¦å“ç›®æ•°`,
      prev_items AS `å‰{window_days}æ—¥_æ–°è¦å“ç›®æ•°`,
      (recent_items - prev_items) AS `å¢—æ¸›_å“ç›®æ•°`,
      recent_sales AS `ç›´è¿‘{window_days}æ—¥_å£²ä¸Š`,
      prev_sales AS `å‰{window_days}æ—¥_å£²ä¸Š`,
      (recent_sales - prev_sales) AS `å¢—æ¸›_å£²ä¸Š`,
      recent_gp AS `ç›´è¿‘{window_days}æ—¥_ç²—åˆ©`,
      prev_gp AS `å‰{window_days}æ—¥_ç²—åˆ©`,
      (recent_gp - prev_gp) AS `å¢—æ¸›_ç²—åˆ©`
    FROM agg
    WHERE (recent_items - prev_items) > 0
       OR (recent_sales - prev_sales) > 0
    ORDER BY `å¢—æ¸›_å“ç›®æ•°` DESC, `å¢—æ¸›_å£²ä¸Š` DESC
    LIMIT @topn
    """
    trend_params = {"w": window_days, "topn": top_n}
    if not is_admin:
        trend_params.update({"login_email": login_email})
    df_ct = query_df_safe(client, sql_customer_trend, trend_params, "New Delivery Trend Customers")
    if not df_ct.empty:
        _render_df_money(df_ct, ["ç›´è¿‘14æ—¥_å£²ä¸Š", "å‰14æ—¥_å£²ä¸Š", "å¢—æ¸›_å£²ä¸Š", "ç›´è¿‘14æ—¥_ç²—åˆ©", "å‰14æ—¥_ç²—åˆ©", "å¢—æ¸›_ç²—åˆ©"])
        # ä¸Šã®é‡‘é¡åˆ—åã¯ window_days ã«ã‚ˆã‚Šå¤‰ã‚ã‚‹ãŸã‚ã€å‹•çš„ã«å½“ã¦ã‚‹
        money_cols = [c for c in df_ct.columns if any(k in c for k in ["å£²ä¸Š", "ç²—åˆ©"]) and "å“ç›®" not in c]
        _render_df_money(df_ct, money_cols)
    else:
        st.info("å¢—åŠ å‚¾å‘ã®å¾—æ„å…ˆãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆã¾ãŸã¯æŠ½å‡ºæœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚")

    st.divider()

    # â‘£ ãƒˆãƒ¬ãƒ³ãƒ‰ï¼šã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆåˆ‡ã‚Šå£ï¼‰
    st.markdown("### ğŸ¢ ã‚°ãƒ«ãƒ¼ãƒ—ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæ–°è¦ç´å“ãŒå¢—ãˆã¦ã„ã‚‹ã‚°ãƒ«ãƒ¼ãƒ—ï¼‰")
    group_expr, group_src = resolve_customer_group_sql_expr(client)
    if not group_expr:
        st.info("ã‚°ãƒ«ãƒ¼ãƒ—åˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ã‚°ãƒ«ãƒ¼ãƒ—ãƒˆãƒ¬ãƒ³ãƒ‰ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
    else:
        if group_src:
            st.caption(f"ã‚°ãƒ«ãƒ¼ãƒ—æŠ½å‡ºå…ƒ: `{group_src}`ï¼ˆVIEW_UNIFIEDï¼‰")

        sql_group_trend = f"""
        WITH td AS (
          SELECT
            CURRENT_DATE('Asia/Tokyo') AS today,
            DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL @w DAY) AS w_start,
            DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL @w*2 DAY) AS prev_start
        ),
        nd AS (
          SELECT
            CAST(customer_code AS STRING) AS customer_code,
            jan_code,
            sales_amount,
            gross_profit,
            CASE
              WHEN first_sales_date >= (SELECT w_start FROM td) THEN 'recent'
              WHEN first_sales_date >= (SELECT prev_start FROM td) AND first_sales_date < (SELECT w_start FROM td) THEN 'prev'
              ELSE 'other'
            END AS bucket
          FROM `{VIEW_NEW_DELIVERY}`
          CROSS JOIN td
          WHERE first_sales_date >= (SELECT prev_start FROM td)
            {where_ext}
        ),
        dim_group AS (
          SELECT
            CAST({c(colmap,'customer_code')} AS STRING) AS customer_code,
            {group_expr} AS group_name
          FROM `{VIEW_UNIFIED}`
          GROUP BY customer_code, group_name
        ),
        base AS (
          SELECT
            COALESCE(dg.group_name, 'æœªè¨­å®š') AS group_name,
            nd.bucket,
            nd.jan_code,
            nd.sales_amount,
            nd.gross_profit
          FROM nd
          LEFT JOIN dim_group dg USING(customer_code)
        ),
        agg AS (
          SELECT
            group_name,
            COUNT(DISTINCT CASE WHEN bucket='recent' THEN jan_code END) AS recent_items,
            COUNT(DISTINCT CASE WHEN bucket='prev' THEN jan_code END) AS prev_items,
            SUM(CASE WHEN bucket='recent' THEN sales_amount ELSE 0 END) AS recent_sales,
            SUM(CASE WHEN bucket='prev' THEN sales_amount ELSE 0 END) AS prev_sales,
            SUM(CASE WHEN bucket='recent' THEN gross_profit ELSE 0 END) AS recent_gp,
            SUM(CASE WHEN bucket='prev' THEN gross_profit ELSE 0 END) AS prev_gp
          FROM base
          GROUP BY group_name
        )
        SELECT
          group_name AS `ã‚°ãƒ«ãƒ¼ãƒ—`,
          recent_items AS `ç›´è¿‘{window_days}æ—¥_æ–°è¦å“ç›®æ•°`,
          prev_items AS `å‰{window_days}æ—¥_æ–°è¦å“ç›®æ•°`,
          (recent_items - prev_items) AS `å¢—æ¸›_å“ç›®æ•°`,
          recent_sales AS `ç›´è¿‘{window_days}æ—¥_å£²ä¸Š`,
          prev_sales AS `å‰{window_days}æ—¥_å£²ä¸Š`,
          (recent_sales - prev_sales) AS `å¢—æ¸›_å£²ä¸Š`,
          recent_gp AS `ç›´è¿‘{window_days}æ—¥_ç²—åˆ©`,
          prev_gp AS `å‰{window_days}æ—¥_ç²—åˆ©`,
          (recent_gp - prev_gp) AS `å¢—æ¸›_ç²—åˆ©`
        FROM agg
        WHERE (recent_items - prev_items) > 0
           OR (recent_sales - prev_sales) > 0
        ORDER BY `å¢—æ¸›_å“ç›®æ•°` DESC, `å¢—æ¸›_å£²ä¸Š` DESC
        LIMIT @topn
        """
        gp_params = {"w": window_days, "topn": top_n}
        if not is_admin:
            gp_params.update({"login_email": login_email})
        df_gt = query_df_safe(client, sql_group_trend, gp_params, "New Delivery Trend Groups")
        if not df_gt.empty:
            money_cols = [c for c in df_gt.columns if any(k in c for k in ["å£²ä¸Š", "ç²—åˆ©"]) and "å“ç›®" not in c]
            _render_df_money(df_gt, money_cols)
        else:
            st.info("å¢—åŠ å‚¾å‘ã®ã‚°ãƒ«ãƒ¼ãƒ—ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆã¾ãŸã¯æŠ½å‡ºæœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚")

    st.divider()

    # â‘¤ ãƒˆãƒ¬ãƒ³ãƒ‰ï¼šå•†å“ï¼ˆæ–°è¦ç´å“ãŒå¢—ãˆã¦ã„ã‚‹å•†å“ï¼‰
    st.markdown("### ğŸ’Š å•†å“ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæ–°è¦ç´å“ãŒå¢—ãˆã¦ã„ã‚‹å•†å“ï¼‰")

    sql_product_trend = f"""
    WITH td AS (
      SELECT
        CURRENT_DATE('Asia/Tokyo') AS today,
        DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL @w DAY) AS w_start,
        DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL @w*2 DAY) AS prev_start
    ),
    base AS (
      SELECT
        CAST(jan_code AS STRING) AS jan_code,
        REGEXP_REPLACE(CAST(product_name AS STRING), r"[/ï¼].*$", "") AS product_base,
        CASE
          WHEN first_sales_date >= (SELECT w_start FROM td) THEN 'recent'
          WHEN first_sales_date >= (SELECT prev_start FROM td) AND first_sales_date < (SELECT w_start FROM td) THEN 'prev'
          ELSE 'other'
        END AS bucket,
        sales_amount,
        gross_profit,
        customer_code
      FROM `{VIEW_NEW_DELIVERY}`
      CROSS JOIN td
      WHERE first_sales_date >= (SELECT prev_start FROM td)
        {where_ext}
    ),
    agg AS (
      SELECT
        jan_code,
        product_base,
        COUNT(DISTINCT CASE WHEN bucket='recent' THEN customer_code END) AS recent_customers,
        COUNT(DISTINCT CASE WHEN bucket='prev' THEN customer_code END) AS prev_customers,
        SUM(CASE WHEN bucket='recent' THEN sales_amount ELSE 0 END) AS recent_sales,
        SUM(CASE WHEN bucket='prev' THEN sales_amount ELSE 0 END) AS prev_sales,
        SUM(CASE WHEN bucket='recent' THEN gross_profit ELSE 0 END) AS recent_gp,
        SUM(CASE WHEN bucket='prev' THEN gross_profit ELSE 0 END) AS prev_gp
      FROM base
      GROUP BY jan_code, product_base
    )
    SELECT
      jan_code AS `JAN`,
      product_base AS `ä»£è¡¨å•†å“å(æˆåˆ†)`,
      recent_customers AS `ç›´è¿‘{window_days}æ—¥_æ–°è¦å¾—æ„å…ˆæ•°`,
      prev_customers AS `å‰{window_days}æ—¥_æ–°è¦å¾—æ„å…ˆæ•°`,
      (recent_customers - prev_customers) AS `å¢—æ¸›_å¾—æ„å…ˆæ•°`,
      recent_sales AS `ç›´è¿‘{window_days}æ—¥_å£²ä¸Š`,
      prev_sales AS `å‰{window_days}æ—¥_å£²ä¸Š`,
      (recent_sales - prev_sales) AS `å¢—æ¸›_å£²ä¸Š`,
      recent_gp AS `ç›´è¿‘{window_days}æ—¥_ç²—åˆ©`,
      prev_gp AS `å‰{window_days}æ—¥_ç²—åˆ©`,
      (recent_gp - prev_gp) AS `å¢—æ¸›_ç²—åˆ©`
    FROM agg
    WHERE (recent_customers - prev_customers) > 0
       OR (recent_sales - prev_sales) > 0
    ORDER BY `å¢—æ¸›_å¾—æ„å…ˆæ•°` DESC, `å¢—æ¸›_å£²ä¸Š` DESC
    LIMIT @topn
    """
    pr_params = {"w": window_days, "topn": top_n}
    if not is_admin:
        pr_params.update({"login_email": login_email})
    df_pt = query_df_safe(client, sql_product_trend, pr_params, "New Delivery Trend Products")
    if not df_pt.empty:
        money_cols = [c for c in df_pt.columns if any(k in c for k in ["å£²ä¸Š", "ç²—åˆ©"]) and "å¾—æ„å…ˆ" not in c]
        _render_df_money(df_pt, money_cols)
    else:
        st.info("å¢—åŠ å‚¾å‘ã®æ–°è¦ç´å“å•†å“ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆã¾ãŸã¯æŠ½å‡ºæœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚")


def render_adoption_alerts_section(client: bigquery.Client, login_email: str, is_admin: bool) -> None:
    st.subheader("ğŸš¨ æ¡ç”¨ã‚¢ã‚¤ãƒ†ãƒ ãƒ»å¤±æ³¨ã‚¢ãƒ©ãƒ¼ãƒˆ")
    where_clause = "" if is_admin else "WHERE login_email = @login_email"
    params = None if is_admin else {"login_email": login_email}
    sql = f"""
        SELECT
            staff_name AS `æ‹…å½“è€…å`,
            customer_name AS `å¾—æ„å…ˆå`,
            product_name AS `å•†å“å`,
            last_purchase_date AS `æœ€çµ‚è³¼å…¥æ—¥`,
            adoption_status AS `ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹`,
            current_fy_sales AS `ä»ŠæœŸå£²ä¸Š`,
            previous_fy_sales AS `å‰æœŸå£²ä¸Š`,
            (current_fy_sales - previous_fy_sales) AS `å£²ä¸Šå·®é¡`
        FROM `{VIEW_ADOPTION}`
        {where_clause}
        ORDER BY
            CASE
                WHEN adoption_status LIKE '%ğŸ”´%' THEN 1
                WHEN adoption_status LIKE '%ğŸŸ¡%' THEN 2
                ELSE 3
            END,
            `å£²ä¸Šå·®é¡` ASC
    """
    df_alerts = query_df_safe(client, sql, params, "Adoption Alerts")
    if df_alerts.empty:
        st.info("ç¾åœ¨ã€ã‚¢ãƒ©ãƒ¼ãƒˆå¯¾è±¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df_alerts["æ‹…å½“è€…å"] = df_alerts["æ‹…å½“è€…å"].fillna("æœªè¨­å®š")
    col1, col2 = st.columns(2)
    with col1:
        selected_status = st.multiselect(
            "ğŸ¯ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§çµã‚Šè¾¼ã¿",
            options=df_alerts["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"].unique(),
            default=[s for s in df_alerts["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"].unique() if "ğŸŸ¡" in s or "ğŸ”´" in s],
        )
    with col2:
        all_staffs = sorted(df_alerts["æ‹…å½“è€…å"].unique().tolist())
        selected_staffs = st.multiselect("ğŸ‘¤ æ‹…å½“è€…ã§çµã‚Šè¾¼ã¿", options=all_staffs, default=[])

    df_display = df_alerts.copy()
    if selected_status:
        df_display = df_display[df_display["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"].isin(selected_status)]
    if selected_staffs:
        df_display = df_display[df_display["æ‹…å½“è€…å"].isin(selected_staffs)]

    if df_display.empty:
        st.info("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    for col in ["ä»ŠæœŸå£²ä¸Š", "å‰æœŸå£²ä¸Š", "å£²ä¸Šå·®é¡"]:
        df_display[col] = pd.to_numeric(df_display[col], errors="coerce").fillna(0)

    st.dataframe(
        df_display.style.format(
            {
                "ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}",
                "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}",
                "å£²ä¸Šå·®é¡": "Â¥{:,.0f}",
                "æœ€çµ‚è³¼å…¥æ—¥": lambda t: t.strftime("%Y-%m-%d") if pd.notnull(t) else "",
            }
        ),
        use_container_width=True,
        hide_index=True,
    )


def render_customer_drilldown(client: bigquery.Client, login_email: str, is_admin: bool, scope: ScopeFilter, colmap: Dict[str, str]) -> None:
    st.subheader("ğŸ¯ æ‹…å½“å…ˆãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ ï¼† ææ¡ˆï¼ˆRecoï¼‰")

    role_filter = "" if is_admin else f"{c(colmap,'login_email')} = @login_email"
    scope_filter = scope.where_clause().replace("customer_name", c(colmap, "customer_name"))
    customer_where = _compose_where(role_filter, scope_filter, f"{c(colmap,'customer_name')} IS NOT NULL")

    customer_params: Dict[str, Any] = dict(scope.params or {})
    if not is_admin:
        customer_params["login_email"] = login_email

    sql_cust = f"""
        SELECT DISTINCT {c(colmap,'customer_code')} AS customer_code, {c(colmap,'customer_name')} AS customer_name
        FROM `{VIEW_UNIFIED}`
        {customer_where}
    """
    df_cust = query_df_safe(client, sql_cust, customer_params, "Scoped Customers")
    if df_cust.empty:
        st.info("è¡¨ç¤ºã§ãã‚‹å¾—æ„å…ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    search_term = st.text_input("ğŸ” å¾—æ„å…ˆåã§æ¤œç´¢ï¼ˆä¸€éƒ¨å…¥åŠ›ï¼‰", placeholder="ä¾‹ï¼šå¤è³€")
    filtered_df = df_cust[df_cust["customer_name"].str.contains(search_term, na=False)] if search_term else df_cust
    if filtered_df.empty:
        st.info("æ¤œç´¢æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹å¾—æ„å…ˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    opts = {row["customer_code"]: f"{row['customer_code']} : {row['customer_name']}" for _, row in filtered_df.iterrows()}
    sel = st.selectbox("å¾—æ„å…ˆã‚’é¸æŠ", options=list(opts.keys()), format_func=lambda x: opts[x])
    if not sel:
        return

    st.divider()
    st.markdown("##### ğŸ“¦ ç¾åœ¨ã®æ¡ç”¨ã‚¢ã‚¤ãƒ†ãƒ ï¼ˆç¨¼åƒçŠ¶æ³ï¼‰")
    sql_adopt = f"""
        SELECT
            product_name AS `å•†å“å`,
            adoption_status AS `ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹`,
            last_purchase_date AS `æœ€çµ‚è³¼å…¥æ—¥`,
            current_fy_sales AS `ä»ŠæœŸå£²ä¸Š`,
            previous_fy_sales AS `å‰æœŸå£²ä¸Š`
        FROM `{VIEW_ADOPTION}`
        WHERE customer_code = @c
        ORDER BY
            CASE
                WHEN adoption_status LIKE '%ğŸŸ¢%' THEN 1
                WHEN adoption_status LIKE '%ğŸŸ¡%' THEN 2
                ELSE 3
            END,
            current_fy_sales DESC
    """
    df_adopt = query_df_safe(client, sql_adopt, {"c": sel}, "Customer Adoption")
    if not df_adopt.empty:
        for col in ["ä»ŠæœŸå£²ä¸Š", "å‰æœŸå£²ä¸Š"]:
            df_adopt[col] = pd.to_numeric(df_adopt[col], errors="coerce").fillna(0)
        st.dataframe(
            df_adopt.style.format(
                {
                    "ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}",
                    "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}",
                    "æœ€çµ‚è³¼å…¥æ—¥": lambda t: t.strftime("%Y-%m-%d") if pd.notnull(t) else "",
                }
            ),
            use_container_width=True,
            hide_index=True,
        )
    else:
        st.info("ã“ã®å¾—æ„å…ˆã®æ¡ç”¨ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    st.markdown("<br>", unsafe_allow_html=True)
    st.markdown("##### ğŸ’¡ AI æ¨å¥¨ææ¡ˆå•†å“ï¼ˆRecoï¼‰")

    sql_rec = f"""
        SELECT
          customer_name,
          strong_category,
          priority_rank,
          recommend_jan,
          recommend_product,
          manufacturer,
          market_scale
        FROM `{VIEW_RECOMMEND}`
        WHERE CAST(customer_code AS STRING) = @c
        ORDER BY priority_rank ASC
        LIMIT 10
    """
    df_rec = query_df_safe(client, sql_rec, {"c": sel}, "Recommendation")
    if not df_rec.empty:
        df_disp = df_rec[["priority_rank", "recommend_product", "manufacturer", "strong_category", "market_scale"]].rename(
            columns={
                "priority_rank": "é †ä½",
                "recommend_product": "æ¨å¥¨å•†å“",
                "manufacturer": "ãƒ¡ãƒ¼ã‚«ãƒ¼",
                "strong_category": "å¼·ã¿åˆ†é¡",
                "market_scale": "å¸‚å ´è¦æ¨¡",
            }
        )
        st.dataframe(df_disp, use_container_width=True, hide_index=True)
    else:
        st.info("ç¾åœ¨ã€ã“ã®å¾—æ„å…ˆã¸ã®æ¨å¥¨å•†å“ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")


# -----------------------------
# 5. Main Loop
# -----------------------------
def main() -> None:
    set_page()
    client = setup_bigquery_client()

    colmap = resolve_unified_colmap(client)
    missing = colmap.get("_missing_required")
    if missing:
        st.error("VIEW_UNIFIED ã®å¿…é ˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚VIEWå®šç¾©ï¼ˆåˆ—åï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.code(f"ä¸è¶³ã‚­ãƒ¼: {missing}")
        st.stop()

    with st.sidebar:
        st.header("ğŸ”‘ ãƒ­ã‚°ã‚¤ãƒ³")
        login_id = st.text_input("ãƒ­ã‚°ã‚¤ãƒ³ID (ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹)")
        login_pw = st.text_input("ãƒ‘ã‚¹ã‚³ãƒ¼ãƒ‰ (æºå¸¯ä¸‹4æ¡)", type="password")

        st.divider()
        st.session_state.use_bqstorage = st.checkbox("é«˜é€Ÿèª­è¾¼ (Storage API)", value=True)

        if st.button("ğŸ“¡ é€šä¿¡ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"):
            try:
                client.query("SELECT 1").result(timeout=10)
                st.success("BigQuery æ¥ç¶šæ­£å¸¸")
            except Exception as e:
                st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")

        if st.button("ğŸ§¹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"):
            st.cache_data.clear()
            st.cache_resource.clear()

        with st.expander("ğŸ”§ VIEW_UNIFIED åˆ—ãƒãƒƒãƒ—ï¼ˆè‡ªå‹•è§£æ±ºçµæœï¼‰", expanded=False):
            st.json(colmap)

    if not login_id or not login_pw:
        st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
        return

    role = resolve_role(client, login_id.strip(), login_pw.strip())
    if not role.is_authenticated:
        st.error("âŒ ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    st.success(f"ğŸ”“ ãƒ­ã‚°ã‚¤ãƒ³ä¸­: {role.staff_name} ã•ã‚“")
    c1, c2, c3 = st.columns(3)
    c1.metric("ğŸ‘¤ æ‹…å½“", role.staff_name)
    c2.metric("ğŸ›¡ï¸ æ¨©é™", role.role_key)
    c3.metric("ğŸ“ é›»è©±", role.phone)
    st.divider()

    if role.role_admin_view:
        render_fytd_org_section(client, colmap)
    else:
        render_fytd_me_section(client, role.login_email, colmap)

    st.divider()

    scope = render_scope_filters(client, role)
    st.divider()

    if role.role_admin_view:
        render_group_underperformance_section(client, role, scope, colmap)
        st.divider()
        render_yoy_section(client, role.login_email, is_admin=True, scope=scope, colmap=colmap)
        st.divider()
        render_new_deliveries_section(client, role.login_email, is_admin=True, colmap=colmap)
        st.divider()
        render_adoption_alerts_section(client, role.login_email, is_admin=True)
        st.divider()
        render_customer_drilldown(client, role.login_email, is_admin=True, scope=scope, colmap=colmap)
    else:
        render_yoy_section(client, role.login_email, is_admin=False, scope=scope, colmap=colmap)
        st.divider()
        render_new_deliveries_section(client, role.login_email, is_admin=False, colmap=colmap)
        st.divider()
        render_adoption_alerts_section(client, role.login_email, is_admin=False)
        st.divider()
        render_customer_drilldown(client, role.login_email, is_admin=False, scope=scope, colmap=colmap)


if __name__ == "__main__":
    main()
