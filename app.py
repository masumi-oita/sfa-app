# -*- coding: utf-8 -*-
"""
SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - OS v1.4.9 (True "è¸è¥²ï¼‹è¿½åŠ " / Backward Compatible)

ã€è¸è¥²ï¼ˆv1.4.8ã®æ—¢å­˜æ©Ÿèƒ½ã¯ç¶­æŒï¼‰ã€‘
- YoYï¼šVIEW_UNIFIED ã‹ã‚‰å‹•çš„é›†è¨ˆã«çµ±ä¸€ï¼ˆYJåŒä¸€ã§å•†å“åãŒ2è¡Œå•é¡Œã‚’æŠ‘æ­¢ï¼‰
- YoYï¼šç¬¬ä¸€éšå±¤ã‚’ã€Œã‚¯ãƒªãƒƒã‚¯é¸æŠã€å¯¾å¿œï¼ˆãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿ã§ã‚‚é¸æŠä¿æŒï¼‰
- ã‚¹ã‚³ãƒ¼ãƒ—ï¼šå¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ—åˆ—å€™è£œã‚’ VIEW_UNIFIED ã®ã‚¹ã‚­ãƒ¼ãƒã‹ã‚‰è‡ªå‹•åˆ¤å®š
- Group Display: officialå…ˆé ­ + rawä½µè¨˜
- å¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ— / å¾—æ„å…ˆå˜ä½“ã®åˆ‡æ›¿ ï¼† å•†å“è¦å› ãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ï¼ˆå…¨ä»¶è¡¨ç¤ºï¼‰
- é †ä½ã‚¢ã‚¤ã‚³ãƒ³ã€WHEREäºŒé‡å¯¾ç­–ã€é¸æŠæ¶ˆå¤±ãƒã‚°å¯¾ç­–ã€è¡¨ç¤ºé †åºæœ€é©åŒ–
- â˜…Recoï¼ˆVIEW_RECOMMENDï¼‰ã® customer_code ãŒ INT64 ã®ãŸã‚ CASTå¯¾å¿œï¼ˆv1.4.8è¸è¥²ï¼‰

ã€è¿½åŠ ï¼ˆå¿…é ˆè¦ä»¶ï¼‰ã€‘
- â˜…factåˆ—åã®è‡ªå‹•è§£æ±ºï¼ˆjan/pack/yj ç­‰ï¼‰ï¼šschemaã‚’è¦‹ã¦è‡ªå‹•å¸åï¼ˆå¾Œæ–¹äº’æ›ï¼‰
- â˜…ç®¡ç†è€…ã‚¹ã‚³ãƒ¼ãƒ—å¿…é ˆï¼šã‚¹ã‚³ãƒ¼ãƒ—ç„¡ã—ã¯åŸå‰‡ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆä¾‹å¤–è¨±å¯ã‚’æ˜ç¤ºï¼‰
- â˜…å…¨ä»¶è¡¨ç¤ºã®æ®µéšUIï¼šæ¨å®šï¼ˆDryRunï¼‰â†’ åŒæ„ â†’ å®Ÿè¡Œï¼ˆmaximumBytesBilledä»˜ãï¼‰
- â˜…FYTDã‚µãƒãƒªãƒ¼ã«ã€Œå½“æœˆï¼ˆMTDï¼‰ã®å£²ä¸Šãƒ»ç²—åˆ©ã€ã‚’è¿½åŠ ï¼ˆä»ŠãŒ2æœˆãªã‚‰2/1ã€œä»Šæ—¥ï¼‰
"""

from __future__ import annotations

from dataclasses import dataclass
import re
from typing import Any, Dict, Optional, Tuple, List

import pandas as pd
import streamlit as st
from google.cloud import bigquery
from google.oauth2 import service_account
from pandas.api.types import is_numeric_dtype


# -----------------------------
# 1. Configuration (è¨­å®š)
# -----------------------------
APP_TITLE = "SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"
DEFAULT_LOCATION = "asia-northeast1"
PROJECT_DEFAULT = "salesdb-479915"
DATASET_DEFAULT = "sales_data"

VIEW_UNIFIED = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_unified_grouped"
VIEW_ROLE_CLEAN = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.dim_staff_role_clean"
VIEW_NEW_DELIVERY = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_new_deliveries_realized_daily_fact_all_months"
VIEW_RECOMMEND = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_recommendation_engine"
VIEW_ADOPTION = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_customer_adoption_status"

CUSTOMER_GROUP_COLUMN_CANDIDATES = (
    "customer_group_display",
    "customer_group_official",
    "customer_group_raw",
    "sales_group_name",
)

DEFAULT_USD_PER_TB = 5.0
DEFAULT_USDJPY = 150.0
BYTES_PER_TB = 1024 ** 4


# -----------------------------
# 2. Helpers (è¡¨ç¤ºç”¨)
# -----------------------------
def set_page() -> None:
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)
    st.caption("OS v1.4.9ï½œå®Ÿåƒç¶­æŒ + åˆ—åå·®ç•°å¸å + ç®¡ç†è€…ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³çµ±åˆ¶ï¼ˆæ¨å®šâ†’åŒæ„â†’å®Ÿè¡Œï¼‰ + å½“æœˆ(MTD)è¡¨ç¤º")


def create_default_column_config(df: pd.DataFrame) -> Dict[str, st.column_config.Column]:
    config: Dict[str, st.column_config.Column] = {}
    for col in df.columns:
        if any(k in col for k in ["å£²ä¸Š", "ç²—åˆ©", "é‡‘é¡", "å·®é¡", "å®Ÿç¸¾", "äºˆæ¸¬", "GAP"]):
            config[col] = st.column_config.NumberColumn(col, format="Â¥%d")
        elif any(k in col for k in ["ç‡", "æ¯”", "ãƒšãƒ¼ã‚¹"]):
            config[col] = st.column_config.NumberColumn(col, format="%.1f%%")
        elif "æ—¥" in col or pd.api.types.is_datetime64_any_dtype(df[col]):
            config[col] = st.column_config.DateColumn(col, format="YYYY-MM-DD")
        elif is_numeric_dtype(df[col]):
            config[col] = st.column_config.NumberColumn(col, format="%d")
        else:
            config[col] = st.column_config.TextColumn(col)
    return config


def get_safe_float(row: pd.Series, key: str) -> float:
    val = row.get(key)
    return float(val) if not pd.isna(val) else 0.0


def normalize_product_display_name(name: Any) -> str:
    if pd.isna(name):
        return ""
    text = str(name).strip()
    text = re.sub(r"[/ï¼].*$", "", text)
    return text.strip()


def bq_ident(name: str) -> str:
    s = str(name).strip()
    if not s:
        raise ValueError("Empty identifier")
    if not re.fullmatch(r"[A-Za-z_][A-Za-z0-9_]*", s):
        raise ValueError(f"Unsafe identifier: {s}")
    return f"`{s}`"


# -----------------------------
# 3. BigQuery Connection & Auth
# -----------------------------
@st.cache_resource
def setup_bigquery_client() -> bigquery.Client:
    bq = st.secrets["bigquery"]
    sa_info = dict(bq["service_account"])
    scopes = [
        "https://www.googleapis.com/auth/bigquery",
        "https://www.googleapis.com/auth/drive",
        "https://www.googleapis.com/auth/spreadsheets",
    ]
    creds = service_account.Credentials.from_service_account_info(sa_info, scopes=scopes)
    return bigquery.Client(
        project=PROJECT_DEFAULT,
        credentials=creds,
        location=DEFAULT_LOCATION,
    )


def _normalize_param(value: Any) -> Tuple[str, Optional[Any]]:
    if isinstance(value, tuple) and len(value) == 2:
        p_type, p_value = value
        return str(p_type).upper(), p_value

    if value is None:
        return "STRING", None
    if isinstance(value, bool):
        return "BOOL", value
    if isinstance(value, int):
        return "INT64", value
    if isinstance(value, float):
        return "FLOAT64", value
    if isinstance(value, pd.Timestamp):
        return "TIMESTAMP", value.to_pydatetime()

    return "STRING", str(value)


def query_df_safe(
    client: bigquery.Client,
    sql: str,
    params: Optional[Dict[str, Any]] = None,
    label: str = "",
    timeout_sec: int = 60,
    maximum_bytes_billed: Optional[int] = None,
) -> pd.DataFrame:
    use_bqstorage = st.session_state.get("use_bqstorage", True)
    try:
        job_config = bigquery.QueryJobConfig()
        if params:
            query_params = []
            for key, raw_value in params.items():
                p_type, p_value = _normalize_param(raw_value)
                query_params.append(bigquery.ScalarQueryParameter(key, p_type, p_value))
            job_config.query_parameters = query_params

        if maximum_bytes_billed is not None:
            job_config.maximum_bytes_billed = int(maximum_bytes_billed)

        job = client.query(sql, job_config=job_config)
        job.result(timeout=timeout_sec)
        return job.to_dataframe(create_bqstorage_client=use_bqstorage)
    except Exception as e:
        st.error(f"ã‚¯ã‚¨ãƒªã‚¨ãƒ©ãƒ¼ ({label}):\n{e}")
        return pd.DataFrame()


def estimate_query_bytes(
    client: bigquery.Client,
    sql: str,
    params: Optional[Dict[str, Any]] = None,
    label: str = "Estimate",
) -> Optional[int]:
    try:
        job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)
        if params:
            query_params = []
            for key, raw_value in params.items():
                p_type, p_value = _normalize_param(raw_value)
                query_params.append(bigquery.ScalarQueryParameter(key, p_type, p_value))
            job_config.query_parameters = query_params

        job = client.query(sql, job_config=job_config)
        return int(job.total_bytes_processed or 0)
    except Exception as e:
        st.warning(f"æ¨å®šã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆ{label}ï¼‰: {e}")
        return None


def bytes_to_human(n: int) -> str:
    if n < 1024:
        return f"{n} B"
    units = ["KB", "MB", "GB", "TB", "PB"]
    v = float(n)
    for u in units:
        v /= 1024.0
        if v < 1024.0:
            return f"{v:.2f} {u}"
    return f"{v:.2f} EB"


def estimate_cost_jpy(bytes_processed: int, usd_per_tb: float, usd_jpy: float) -> float:
    tb = bytes_processed / BYTES_PER_TB
    return tb * float(usd_per_tb) * float(usd_jpy)


@dataclass(frozen=True)
class RoleInfo:
    is_authenticated: bool = False
    login_email: str = ""
    staff_name: str = "ã‚²ã‚¹ãƒˆ"
    role_key: str = "GUEST"
    role_admin_view: bool = False
    phone: str = "-"


@dataclass(frozen=True)
class ScopeFilter:
    predicates: tuple[str, ...] = ()
    params: Dict[str, Any] | None = None

    def where_clause(self) -> str:
        if not self.predicates:
            return ""
        return " AND ".join(self.predicates)

    def is_empty(self) -> bool:
        return not self.predicates


@dataclass(frozen=True)
class AdminScanPolicy:
    require_scope: bool = True
    allow_full_scan: bool = False
    max_bytes_billed: int = 0
    must_estimate_before_run: bool = True


def _compose_where(*parts: str) -> str:
    clauses = [p.strip() for p in parts if p and p.strip()]
    if not clauses:
        return ""
    return "WHERE " + " AND ".join(clauses)


def _split_table_fqn(table_fqn: str) -> Tuple[str, str, str]:
    parts = table_fqn.split(".")
    if len(parts) != 3:
        raise ValueError(f"Invalid table FQN: {table_fqn}")
    return parts[0], parts[1], parts[2]


# -----------------------------
# 3.1 Schema utilities (åˆ—åå·®ç•°å¸åã®åŸºç›¤)
# -----------------------------
@st.cache_data(ttl=3600)
def get_table_columns_lower(_client: bigquery.Client, table_fqn: str) -> set[str]:
    project_id, dataset_id, table_name = _split_table_fqn(table_fqn)
    sql = f"""
        SELECT column_name
        FROM `{project_id}.{dataset_id}.INFORMATION_SCHEMA.COLUMNS`
        WHERE table_name = @table_name
    """
    df = query_df_safe(_client, sql, {"table_name": table_name}, f"Schema Check: {table_name}")
    if df.empty or "column_name" not in df.columns:
        return set()
    return {str(c).lower() for c in df["column_name"].dropna().tolist()}


def resolve_col(table_fqn: str, cols_lower: set[str], candidates: List[str], required: bool = True) -> Optional[str]:
    for c in candidates:
        if c.lower() in cols_lower:
            return c
    if required:
        return None
    return None


@st.cache_data(ttl=3600)
def resolve_view_columns_map(_client: bigquery.Client) -> Dict[str, Dict[str, str]]:
    m: Dict[str, Dict[str, str]] = {}

    # --- VIEW_UNIFIEDï¼ˆfactï¼‰
    cols_u = get_table_columns_lower(_client, VIEW_UNIFIED)
    unified: Dict[str, str] = {}

    unified["customer_code"] = resolve_col(VIEW_UNIFIED, cols_u, ["customer_code", "customer_cd", "cust_code"], True) or ""
    unified["customer_name"] = resolve_col(VIEW_UNIFIED, cols_u, ["customer_name", "customer_nm", "cust_name"], True) or ""
    unified["login_email"] = resolve_col(VIEW_UNIFIED, cols_u, ["login_email", "email", "user_email"], True) or ""
    unified["staff_name"] = resolve_col(VIEW_UNIFIED, cols_u, ["staff_name", "æ‹…å½“ç¤¾å“¡å", "æ‹…å½“è€…å", "sales_name"], False) or "staff_name"

    unified["yj_code"] = resolve_col(VIEW_UNIFIED, cols_u, ["yj_code", "yj", "YJCode", "YJ_CODE"], False) or "yj_code"
    unified["jan_code"] = resolve_col(VIEW_UNIFIED, cols_u, ["jan_code", "jan", "JAN", "JAN_CODE"], False) or "jan_code"
    unified["product_name"] = resolve_col(VIEW_UNIFIED, cols_u, ["product_name", "item_name", "å•†å“åç§°", "item_nm"], True) or ""
    unified["package_unit"] = resolve_col(VIEW_UNIFIED, cols_u, ["package_unit", "pack_unit", "pack", "åŒ…è£…å˜ä½", "packaging"], False) or "package_unit"

    unified["sales_date"] = resolve_col(VIEW_UNIFIED, cols_u, ["sales_date", "date", "è²©å£²æ—¥"], True) or ""
    unified["fiscal_year"] = resolve_col(VIEW_UNIFIED, cols_u, ["fiscal_year", "FY", "ä¼šè¨ˆå¹´åº¦"], True) or ""
    unified["sales_amount"] = resolve_col(VIEW_UNIFIED, cols_u, ["sales_amount", "sales", "å£²ä¸Š", "åˆè¨ˆä¾¡æ ¼"], True) or ""
    unified["gross_profit"] = resolve_col(VIEW_UNIFIED, cols_u, ["gross_profit", "gp", "ç²—åˆ©"], True) or ""

    m["unified"] = unified

    # --- VIEW_NEW_DELIVERYï¼ˆæ–°è¦ç´å“ï¼‰
    cols_nd = get_table_columns_lower(_client, VIEW_NEW_DELIVERY)
    nd: Dict[str, str] = {}
    nd["first_sales_date"] = resolve_col(VIEW_NEW_DELIVERY, cols_nd, ["first_sales_date", "first_sale_date", "first_date"], True) or ""
    nd["customer_code"] = resolve_col(VIEW_NEW_DELIVERY, cols_nd, ["customer_code", "customer_cd"], True) or ""
    nd["jan_code"] = resolve_col(VIEW_NEW_DELIVERY, cols_nd, ["jan_code", "jan", "JAN"], True) or ""
    nd["sales_amount"] = resolve_col(VIEW_NEW_DELIVERY, cols_nd, ["sales_amount", "sales", "å£²ä¸Š"], True) or ""
    nd["gross_profit"] = resolve_col(VIEW_NEW_DELIVERY, cols_nd, ["gross_profit", "gp", "ç²—åˆ©"], True) or ""
    nd["login_email"] = resolve_col(VIEW_NEW_DELIVERY, cols_nd, ["login_email", "email", "user_email"], False) or ""
    m["new_delivery"] = nd

    # --- VIEW_ADOPTIONï¼ˆæ¡ç”¨ãƒ»å¤±æ³¨ã‚¢ãƒ©ãƒ¼ãƒˆï¼‰
    cols_ad = get_table_columns_lower(_client, VIEW_ADOPTION)
    ad: Dict[str, str] = {}
    ad["login_email"] = resolve_col(VIEW_ADOPTION, cols_ad, ["login_email", "email", "user_email"], False) or ""
    ad["staff_name"] = resolve_col(VIEW_ADOPTION, cols_ad, ["staff_name", "æ‹…å½“è€…å"], False) or ""
    ad["customer_code"] = resolve_col(VIEW_ADOPTION, cols_ad, ["customer_code", "customer_cd"], True) or ""
    ad["customer_name"] = resolve_col(VIEW_ADOPTION, cols_ad, ["customer_name", "customer_nm"], True) or ""
    ad["product_name"] = resolve_col(VIEW_ADOPTION, cols_ad, ["product_name", "item_name", "å•†å“å"], True) or ""
    ad["last_purchase_date"] = resolve_col(VIEW_ADOPTION, cols_ad, ["last_purchase_date", "last_date", "æœ€çµ‚è³¼å…¥æ—¥"], True) or ""
    ad["adoption_status"] = resolve_col(VIEW_ADOPTION, cols_ad, ["adoption_status", "status", "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"], True) or ""
    ad["current_fy_sales"] = resolve_col(VIEW_ADOPTION, cols_ad, ["current_fy_sales", "cur_sales", "ä»ŠæœŸå£²ä¸Š"], True) or ""
    ad["previous_fy_sales"] = resolve_col(VIEW_ADOPTION, cols_ad, ["previous_fy_sales", "py_sales", "å‰æœŸå£²ä¸Š"], True) or ""
    m["adoption"] = ad

    # --- VIEW_RECOMMENDï¼ˆRecoï¼‰
    cols_rc = get_table_columns_lower(_client, VIEW_RECOMMEND)
    rc: Dict[str, str] = {}
    rc["customer_code"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["customer_code", "customer_cd"], True) or ""
    rc["customer_name"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["customer_name", "customer_nm"], False) or ""
    rc["strong_category"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["strong_category", "category", "å¼·ã¿åˆ†é¡"], False) or ""
    rc["priority_rank"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["priority_rank", "rank", "é †ä½"], True) or ""
    rc["recommend_jan"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["recommend_jan", "jan", "JAN"], False) or ""
    rc["recommend_product"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["recommend_product", "product_name", "æ¨å¥¨å•†å“"], True) or ""
    rc["manufacturer"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["manufacturer", "maker", "ãƒ¡ãƒ¼ã‚«ãƒ¼"], False) or ""
    rc["market_scale"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["market_scale", "scale", "å¸‚å ´è¦æ¨¡"], False) or ""
    m["recommend"] = rc

    return m


def require_colmap_ok(colmap: Dict[str, Dict[str, str]]) -> bool:
    # å¿…é ˆï¼ˆunifiedï¼‰
    u = colmap.get("unified", {})
    required_unified = ["customer_code", "customer_name", "login_email", "product_name", "sales_date", "fiscal_year", "sales_amount", "gross_profit"]
    missing = [k for k in required_unified if not u.get(k)]
    if missing:
        st.error(f"VIEW_UNIFIED å¿…é ˆåˆ—ãŒè§£æ±ºã§ãã¾ã›ã‚“: {missing}\nï¼ˆåˆ—åå·®ç•°å¸åã«å¤±æ•—ã€‚VIEWã®ã‚¹ã‚­ãƒ¼ãƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰")
        return False
    return True


@st.cache_data(ttl=3600)
def role_table_has_login_code(_client: bigquery.Client) -> bool:
    project_id, dataset_id, table_name = _split_table_fqn(VIEW_ROLE_CLEAN)
    sql = f"""
        SELECT 1
        FROM `{project_id}.{dataset_id}.INFORMATION_SCHEMA.COLUMNS`
        WHERE table_name = @table_name
          AND column_name = 'login_code'
        LIMIT 1
    """
    df = query_df_safe(_client, sql, {"table_name": table_name}, "Role Schema Check")
    return not df.empty


# -----------------------------
# 3.2 Customer Group resolution (è¸è¥²)
# -----------------------------
@st.cache_data(ttl=3600)
def get_unified_columns(_client: bigquery.Client) -> set[str]:
    return get_table_columns_lower(_client, VIEW_UNIFIED)


def get_available_customer_group_columns(_client: bigquery.Client) -> list[str]:
    columns = get_unified_columns(_client)
    return [col for col in CUSTOMER_GROUP_COLUMN_CANDIDATES if col in columns]


def resolve_customer_group_sql_expr(_client: bigquery.Client) -> Tuple[Optional[str], Optional[str]]:
    cols = get_unified_columns(_client)

    has_display = "customer_group_display" in cols
    has_official = "customer_group_official" in cols
    has_raw = "customer_group_raw" in cols
    has_old = "sales_group_name" in cols

    if has_display:
        expr = "COALESCE(NULLIF(CAST(customer_group_display AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.customer_group_display"

    if has_official and has_raw:
        official = "NULLIF(CAST(customer_group_official AS STRING), '')"
        raw = "NULLIF(CAST(customer_group_raw AS STRING), '')"
        expr = f"""
          COALESCE(
            CASE
              WHEN {official} IS NOT NULL AND {raw} IS NOT NULL AND {official} != {raw}
                THEN CONCAT({official}, 'ï¼ˆ', {raw}, 'ï¼‰')
              WHEN {official} IS NOT NULL THEN {official}
              WHEN {raw} IS NOT NULL THEN {raw}
              ELSE NULL
            END,
            'æœªè¨­å®š'
          )
        """
        return " ".join(expr.split()), f"{VIEW_UNIFIED}.customer_group_official + customer_group_raw"

    if has_official:
        expr = "COALESCE(NULLIF(CAST(customer_group_official AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.customer_group_official"

    if has_raw:
        expr = "COALESCE(NULLIF(CAST(customer_group_raw AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.customer_group_raw"

    if has_old:
        expr = "COALESCE(NULLIF(CAST(sales_group_name AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.sales_group_name"

    return None, None


# -----------------------------
# 3.3 Admin full scan policy (æ®µéšUI)
# -----------------------------
def get_admin_scan_policy(role: RoleInfo) -> AdminScanPolicy:
    if not role.role_admin_view:
        return AdminScanPolicy(require_scope=False, allow_full_scan=False, max_bytes_billed=0, must_estimate_before_run=False)

    with st.sidebar.expander("ğŸ›¡ï¸ ç®¡ç†è€…ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³çµ±åˆ¶ï¼ˆå¿…èª­ï¼‰", expanded=False):
        st.caption("ã‚¹ã‚³ãƒ¼ãƒ—æœªæŒ‡å®šï¼å…¨ç¤¾ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ã§ã™ã€‚å®Ÿåƒä¿è­·ã®ãŸã‚æ¨å®šâ†’ä¸Šé™â†’å®Ÿè¡Œã®é †ã§çµ±åˆ¶ã—ã¾ã™ã€‚")
        allow_full_scan = st.checkbox("ã‚¹ã‚³ãƒ¼ãƒ—æœªæŒ‡å®šã®ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ã‚’è¨±å¯ã™ã‚‹ï¼ˆä¾‹å¤–ï¼‰", value=False, key="admin_allow_full_scan")
        must_estimate = st.checkbox("ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³æ™‚ã¯æ¨å®šï¼ˆDryRunï¼‰ã‚’å¿…é ˆã«ã™ã‚‹", value=True, key="admin_must_estimate")

        usd_per_tb = st.number_input("æ¨å®šå˜ä¾¡ï¼ˆUSD / TBï¼‰", min_value=0.0, max_value=50.0, value=float(st.session_state.get("usd_per_tb", DEFAULT_USD_PER_TB)), step=0.5)
        usd_jpy = st.number_input("ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆï¼ˆUSDJPYï¼‰", min_value=50.0, max_value=300.0, value=float(st.session_state.get("usd_jpy", DEFAULT_USDJPY)), step=1.0)
        st.session_state["usd_per_tb"] = float(usd_per_tb)
        st.session_state["usd_jpy"] = float(usd_jpy)

        max_gb = st.number_input("maximumBytesBilled ä¸Šé™ï¼ˆGBï¼‰", min_value=0, max_value=5000, value=int(st.session_state.get("admin_max_gb", 200)), step=50)
        st.session_state["admin_max_gb"] = int(max_gb)

        if max_gb == 0:
            st.warning("ä¸Šé™0GBï¼ä¸Šé™ãªã—ï¼ˆéæ¨å¥¨ï¼‰ã€‚å®Ÿåƒä¿è­·ã®è¦³ç‚¹ã§ã¯ä¸Šé™è¨­å®šã‚’æ¨å¥¨ã€‚")

    max_bytes = int(st.session_state.get("admin_max_gb", 200)) * (1024 ** 3)
    if int(st.session_state.get("admin_max_gb", 200)) == 0:
        max_bytes = 0

    return AdminScanPolicy(
        require_scope=True,
        allow_full_scan=bool(st.session_state.get("admin_allow_full_scan", False)),
        max_bytes_billed=max_bytes,
        must_estimate_before_run=bool(st.session_state.get("admin_must_estimate", True)),
    )


def guard_and_run_query_ui(
    client: bigquery.Client,
    role: RoleInfo,
    scope: ScopeFilter,
    sql: str,
    params: Optional[Dict[str, Any]],
    label: str,
    *,
    risky_if_no_scope: bool = True,
    force_estimate: bool = False,
    timeout_sec: int = 120,
) -> pd.DataFrame:
    policy = get_admin_scan_policy(role)

    is_admin = role.role_admin_view
    scope_empty = scope.is_empty()

    if is_admin and policy.require_scope and scope_empty and risky_if_no_scope and (not policy.allow_full_scan):
        st.warning("âš ï¸ ç®¡ç†è€…ã¯ã‚¹ã‚³ãƒ¼ãƒ—å¿…é ˆã§ã™ã€‚ã‚¹ã‚³ãƒ¼ãƒ—ã‚’æŒ‡å®šã™ã‚‹ã‹ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ä¾‹å¤–è¨±å¯ã€ã‚’ONã«ã—ã¦ãã ã•ã„ã€‚")
        return pd.DataFrame()

    max_bytes = None
    if is_admin and scope_empty and policy.allow_full_scan and risky_if_no_scope:
        if policy.max_bytes_billed and policy.max_bytes_billed > 0:
            max_bytes = policy.max_bytes_billed
        else:
            max_bytes = None

    need_estimate = force_estimate or (is_admin and scope_empty and policy.allow_full_scan and risky_if_no_scope)
    if need_estimate:
        st.markdown("##### ğŸ§® æ¨å®šï¼ˆDry Runï¼‰")
        colA, colB, colC = st.columns([1, 1, 2])

        estimate_key = f"estimate_bytes::{label}"
        ran_key = f"estimate_ran::{label}"

        if colA.button("æ¨å®šã™ã‚‹ï¼ˆDryRunï¼‰", key=f"btn_est_{label}", use_container_width=True):
            b = estimate_query_bytes(client, sql, params, label=label)
            st.session_state[estimate_key] = b if b is not None else 0
            st.session_state[ran_key] = True

        b_est = int(st.session_state.get(estimate_key, 0) or 0)
        ran = bool(st.session_state.get(ran_key, False))

        if ran:
            usd_per_tb = float(st.session_state.get("usd_per_tb", DEFAULT_USD_PER_TB))
            usd_jpy = float(st.session_state.get("usd_jpy", DEFAULT_USDJPY))
            jpy = estimate_cost_jpy(b_est, usd_per_tb, usd_jpy)

            colB.metric("æ¨å®šå‡¦ç†é‡", bytes_to_human(b_est))
            colC.metric("æ¨å®šã‚³ã‚¹ãƒˆï¼ˆç›®å®‰ï¼‰", f"Â¥{jpy:,.0f}")

            if max_bytes is not None:
                st.info(f"maximumBytesBilled: {bytes_to_human(max_bytes)}ï¼ˆç®¡ç†è€…ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³çµ±åˆ¶ï¼‰")

            if is_admin and scope_empty and policy.allow_full_scan and policy.must_estimate_before_run:
                st.success("æ¨å®šãŒå®Œäº†ã—ã¾ã—ãŸã€‚å®Ÿè¡Œã§ãã¾ã™ã€‚")
        else:
            st.caption("ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ã‚„å…¨ä»¶è¡¨ç¤ºã§ã¯ã€ã¾ãšæ¨å®šã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

        if is_admin and scope_empty and policy.allow_full_scan and policy.must_estimate_before_run:
            if not ran:
                st.error("æ¨å®šãŒå¿…é ˆã§ã™ï¼ˆæœªå®Ÿè¡Œã®ãŸã‚ã€å®Ÿè¡Œãƒœã‚¿ãƒ³ã¯ç„¡åŠ¹ï¼‰ã€‚")
                return pd.DataFrame()

    st.markdown("##### â–¶ å®Ÿè¡Œ")
    run_disabled = False
    if is_admin and scope_empty and policy.allow_full_scan and policy.must_estimate_before_run and need_estimate:
        ran = bool(st.session_state.get(f"estimate_ran::{label}", False))
        if not ran:
            run_disabled = True

    if st.button(f"å®Ÿè¡Œï¼š{label}", key=f"btn_run_{label}", use_container_width=True, disabled=run_disabled):
        return query_df_safe(
            client,
            sql,
            params=params,
            label=label,
            timeout_sec=timeout_sec,
            maximum_bytes_billed=max_bytes,
        )

    return pd.DataFrame()


# -----------------------------
# 3.4 Scope filters (è¸è¥²ï¼‹å®‰å…¨è£œå¼·)
# -----------------------------
def render_scope_filters(client: bigquery.Client, role: RoleInfo) -> ScopeFilter:
    st.markdown("### ğŸ” åˆ†æã‚¹ã‚³ãƒ¼ãƒ—è¨­å®š")
    predicates: list[str] = []
    params: Dict[str, Any] = {}

    with st.expander("è©³ç´°çµã‚Šè¾¼ã¿ï¼ˆå¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ—ãƒ»å¾—æ„å…ˆåï¼‰", expanded=False):
        c1, c2 = st.columns(2)

        group_expr, group_src = resolve_customer_group_sql_expr(client)
        if group_expr:
            role_where = ""
            role_params: Dict[str, Any] = {}
            if not role.role_admin_view:
                role_where = "WHERE login_email = @login_email"
                role_params["login_email"] = role.login_email

            sql_group = f"""
                SELECT DISTINCT {group_expr} AS group_name
                FROM `{VIEW_UNIFIED}`
                {role_where}
                ORDER BY group_name
                LIMIT 500
            """
            df_group = query_df_safe(client, sql_group, role_params, "Scope Group Options")
            group_opts = ["æŒ‡å®šãªã—"] + (df_group["group_name"].tolist() if not df_group.empty else [])
            selected_group = c1.selectbox("å¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ—", options=group_opts)
            if selected_group != "æŒ‡å®šãªã—":
                predicates.append(f"{group_expr} = @scope_group")
                params["scope_group"] = selected_group

            if group_src:
                c1.caption(f"æŠ½å‡ºå…ƒ: `{group_src}`")
        else:
            c1.caption("ã‚°ãƒ«ãƒ¼ãƒ—åˆ—ãªã—ï¼ˆVIEW_UNIFIEDã«è©²å½“åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼‰")

        keyword = c2.text_input("å¾—æ„å…ˆåï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", placeholder="ä¾‹ï¼šå¤è³€ç—…é™¢")
        if keyword.strip():
            predicates.append("customer_name LIKE @scope_customer_name")
            params["scope_customer_name"] = f"%{keyword.strip()}%"

    return ScopeFilter(predicates=tuple(predicates), params=params)


def resolve_role(client: bigquery.Client, login_email: str, login_code: str) -> RoleInfo:
    if not login_email or not login_code:
        return RoleInfo()

    has_login_code = role_table_has_login_code(client)

    if has_login_code:
        sql = f"""
            SELECT login_email, role_tier
            FROM `{VIEW_ROLE_CLEAN}`
            WHERE login_email = @login_email
              AND CAST(login_code AS STRING) = @login_code
            LIMIT 1
        """
        params: Dict[str, Any] = {"login_email": login_email, "login_code": login_code}
    else:
        sql = f"""
            SELECT login_email, role_tier
            FROM `{VIEW_ROLE_CLEAN}`
            WHERE login_email = @login_email
            LIMIT 1
        """
        params = {"login_email": login_email}

    df = query_df_safe(client, sql, params, "Auth Check")
    if df.empty:
        return RoleInfo(login_email=login_email)

    row = df.iloc[0]
    raw_role = str(row.get("role_tier", "")).strip().upper()
    is_admin = any(x in raw_role for x in ["ADMIN", "MANAGER", "HQ"])

    return RoleInfo(
        is_authenticated=True,
        login_email=login_email,
        staff_name=login_email.split("@")[0],
        role_key="HQ_ADMIN" if is_admin else "SALES",
        role_admin_view=is_admin,
        phone="-",
    )


# -----------------------------
# 4. UI Sections (å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³)
# -----------------------------
def render_summary_metrics(row: pd.Series) -> None:
    s_cur = get_safe_float(row, "sales_amount_fytd")
    s_py_ytd = get_safe_float(row, "sales_amount_py_ytd")
    s_py_total = get_safe_float(row, "sales_amount_py_total")

    s_fc = s_cur * (s_py_total / s_py_ytd) if s_py_ytd > 0 else s_cur

    gp_cur = get_safe_float(row, "gross_profit_fytd")
    gp_py_ytd = get_safe_float(row, "gross_profit_py_ytd")
    gp_py_total = get_safe_float(row, "gross_profit_py_total")
    gp_fc = gp_cur * (gp_py_total / gp_py_ytd) if gp_py_ytd > 0 else gp_cur

    # â˜…è¿½åŠ ï¼šå½“æœˆï¼ˆMTDï¼‰
    s_mtd = get_safe_float(row, "sales_amount_mtd")
    gp_mtd = get_safe_float(row, "gross_profit_mtd")

    st.caption(
        "â€» ã€ä»ŠæœŸäºˆæ¸¬ã€‘ã¯AIäºˆæ¸¬ã§ã¯ãªãã€ã€Œä»ŠæœŸå®Ÿç¸¾ Ã— (æ˜¨å¹´åº¦ç€åœ° Ã· å‰å¹´åŒæœŸ)ã€"
        "ã«ã‚ˆã‚‹å­£ç¯€å¤‰å‹•ã‚’åŠ å‘³ã—ãŸæ¨ç§»ãƒšãƒ¼ã‚¹ï¼ˆç€åœ°è¦‹è¾¼ï¼‰ã§ã™ã€‚"
    )

    st.markdown("##### â–  å£²ä¸Š")
    c1, c2, c3, c4, c5, c6 = st.columns(6)
    c1.metric("â‘  ä»ŠæœŸç´¯è¨ˆ(FYTD)", f"Â¥{s_cur:,.0f}")
    c2.metric("â‘¡ å‰å¹´åŒæœŸ(YTD)", f"Â¥{s_py_ytd:,.0f}", delta=f"{int(s_cur - s_py_ytd):,}" if s_py_ytd > 0 else None)
    c3.metric("â‘¢ æ˜¨å¹´åº¦ç€åœ°", f"Â¥{s_py_total:,.0f}")
    c4.metric("â‘£ ä»ŠæœŸäºˆæ¸¬", f"Â¥{s_fc:,.0f}")
    c5.metric("â‘¤ ç€åœ°GAP", f"Â¥{s_fc - s_py_total:,.0f}", delta=f"{int(s_fc - s_py_total):,}")
    c6.metric("â˜… å½“æœˆ(MTD)", f"Â¥{s_mtd:,.0f}")

    st.markdown("##### â–  ç²—åˆ©")
    c1, c2, c3, c4, c5, c6 = st.columns(6)
    c1.metric("â‘  ä»ŠæœŸç´¯è¨ˆ(FYTD)", f"Â¥{gp_cur:,.0f}")
    c2.metric("â‘¡ å‰å¹´åŒæœŸ(YTD)", f"Â¥{gp_py_ytd:,.0f}", delta=f"{int(gp_cur - gp_py_ytd):,}" if gp_py_ytd > 0 else None)
    c3.metric("â‘¢ æ˜¨å¹´åº¦ç€åœ°", f"Â¥{gp_py_total:,.0f}")
    c4.metric("â‘£ ä»ŠæœŸäºˆæ¸¬", f"Â¥{gp_fc:,.0f}")
    c5.metric("â‘¤ ç€åœ°GAP", f"Â¥{gp_fc - gp_py_total:,.0f}", delta=f"{int(gp_fc - gp_py_total):,}")
    c6.metric("â˜… å½“æœˆ(MTD)", f"Â¥{gp_mtd:,.0f}")


def render_fytd_org_section(client: bigquery.Client, colmap: Dict[str, Dict[str, str]]) -> None:
    st.subheader("ğŸ¢ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå…¨ç¤¾ã‚µãƒãƒªãƒ¼")

    if "org_data_loaded" not in st.session_state:
        st.session_state.org_data_loaded = False

    if st.button("å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_org_load"):
        st.session_state.org_data_loaded = True

    if st.session_state.get("org_data_loaded"):
        u = colmap["unified"]
        sales_date = bq_ident(u["sales_date"])
        fiscal_year = bq_ident(u["fiscal_year"])
        sales_amount = bq_ident(u["sales_amount"])
        gross_profit = bq_ident(u["gross_profit"])

        sql = f"""
            WITH today_info AS (
              SELECT
                CURRENT_DATE('Asia/Tokyo') AS today,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today,
                DATE_TRUNC(CURRENT_DATE('Asia/Tokyo'), MONTH) AS month_start,
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                    - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
            )
            SELECT
              SUM(CASE WHEN {fiscal_year} = current_fy THEN {sales_amount} ELSE 0 END) AS sales_amount_fytd,
              SUM(CASE WHEN {fiscal_year} = current_fy THEN {gross_profit} ELSE 0 END) AS gross_profit_fytd,
              SUM(CASE WHEN {fiscal_year} = current_fy - 1 AND {sales_date} <= py_today THEN {sales_amount} ELSE 0 END) AS sales_amount_py_ytd,
              SUM(CASE WHEN {fiscal_year} = current_fy - 1 AND {sales_date} <= py_today THEN {gross_profit} ELSE 0 END) AS gross_profit_py_ytd,
              SUM(CASE WHEN {fiscal_year} = current_fy - 1 THEN {sales_amount} ELSE 0 END) AS sales_amount_py_total,
              SUM(CASE WHEN {fiscal_year} = current_fy - 1 THEN {gross_profit} ELSE 0 END) AS gross_profit_py_total,
              SUM(CASE WHEN {sales_date} >= month_start AND {sales_date} <= today THEN {sales_amount} ELSE 0 END) AS sales_amount_mtd,
              SUM(CASE WHEN {sales_date} >= month_start AND {sales_date} <= today THEN {gross_profit} ELSE 0 END) AS gross_profit_mtd
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN today_info
        """
        df_org = query_df_safe(client, sql, None, "Org Summary")
        if not df_org.empty:
            render_summary_metrics(df_org.iloc[0])


def render_fytd_me_section(client: bigquery.Client, login_email: str, colmap: Dict[str, Dict[str, str]]) -> None:
    st.subheader("ğŸ‘¤ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå€‹äººã‚µãƒãƒªãƒ¼")
    if st.button("è‡ªåˆ†ã®æˆç¸¾ã‚’èª­ã¿è¾¼ã‚€", key="btn_me_load"):
        u = colmap["unified"]
        sales_date = bq_ident(u["sales_date"])
        fiscal_year = bq_ident(u["fiscal_year"])
        sales_amount = bq_ident(u["sales_amount"])
        gross_profit = bq_ident(u["gross_profit"])
        login_col = bq_ident(u["login_email"])

        sql = f"""
            WITH today_info AS (
              SELECT
                CURRENT_DATE('Asia/Tokyo') AS today,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today,
                DATE_TRUNC(CURRENT_DATE('Asia/Tokyo'), MONTH) AS month_start,
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                    - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
            )
            SELECT
              SUM(CASE WHEN {fiscal_year} = current_fy THEN {sales_amount} ELSE 0 END) AS sales_amount_fytd,
              SUM(CASE WHEN {fiscal_year} = current_fy THEN {gross_profit} ELSE 0 END) AS gross_profit_fytd,
              SUM(CASE WHEN {fiscal_year} = current_fy - 1 AND {sales_date} <= py_today THEN {sales_amount} ELSE 0 END) AS sales_amount_py_ytd,
              SUM(CASE WHEN {fiscal_year} = current_fy - 1 AND {sales_date} <= py_today THEN {gross_profit} ELSE 0 END) AS gross_profit_py_ytd,
              SUM(CASE WHEN {fiscal_year} = current_fy - 1 THEN {sales_amount} ELSE 0 END) AS sales_amount_py_total,
              SUM(CASE WHEN {fiscal_year} = current_fy - 1 THEN {gross_profit} ELSE 0 END) AS gross_profit_py_total,
              SUM(CASE WHEN {sales_date} >= month_start AND {sales_date} <= today THEN {sales_amount} ELSE 0 END) AS sales_amount_mtd,
              SUM(CASE WHEN {sales_date} >= month_start AND {sales_date} <= today THEN {gross_profit} ELSE 0 END) AS gross_profit_mtd
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN today_info
            WHERE {login_col} = @login_email
        """
        df_me = query_df_safe(client, sql, {"login_email": login_email}, "Me Summary")
        if not df_me.empty:
            render_summary_metrics(df_me.iloc[0])


def render_group_underperformance_section(client: bigquery.Client, role: RoleInfo, scope: ScopeFilter) -> None:
    st.subheader("ğŸ¢ å¾—æ„å…ˆãƒ»ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ï¼† è¦å› åˆ†æ")

    # --- UIï¼ˆè¦ªï¼šã‚°ãƒ«ãƒ¼ãƒ—/å¾—æ„å…ˆã€ãƒ™ã‚¹ãƒˆ/ãƒ¯ãƒ¼ã‚¹ãƒˆï¼‰ ---
    c1, c2 = st.columns(2)
    view_choice = c1.radio("ğŸ“Š åˆ†æã®å˜ä½", ["ğŸ¢ ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥", "ğŸ¥ å¾—æ„å…ˆå˜ä½“"], horizontal=True, key="grpperf_view_choice")
    mode_choice = c2.radio("ğŸ† ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŸºæº–", ["ğŸ“‰ ä¸‹è½å¹…ãƒ¯ãƒ¼ã‚¹ãƒˆ", "ğŸ“ˆ ä¸Šæ˜‡å¹…ãƒ™ã‚¹ãƒˆ"], horizontal=True, key="grpperf_mode_choice")

    perf_view = "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" if "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" in view_choice else "å¾—æ„å…ˆåˆ¥"
    perf_mode = "ãƒ¯ãƒ¼ã‚¹ãƒˆ" if "ãƒ¯ãƒ¼ã‚¹ãƒˆ" in mode_choice else "ãƒ™ã‚¹ãƒˆ"
    sort_order = "ASC" if perf_mode == "ãƒ¯ãƒ¼ã‚¹ãƒˆ" else "DESC"

    group_expr, group_src = resolve_customer_group_sql_expr(client)
    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" and not group_expr:
        st.info("ã‚°ãƒ«ãƒ¼ãƒ—åˆ†æã«åˆ©ç”¨ã§ãã‚‹åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆVIEW_UNIFIEDã«ã‚°ãƒ«ãƒ¼ãƒ—åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚")
        return

    # --- ãƒ•ã‚£ãƒ«ã‚¿çµ„ç«‹ ---
    role_filter = "" if role.role_admin_view else "login_email = @login_email"
    scope_filter_clause = scope.where_clause()
    filter_sql = _compose_where(role_filter, scope_filter_clause)

    params: Dict[str, Any] = dict(scope.params or {})
    if not role.role_admin_view:
        params["login_email"] = role.login_email

    # --- è¦ªãƒ©ãƒ³ã‚­ãƒ³ã‚°SQL ---
    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥":
        sql_parent = f"""
            WITH fy AS (
              SELECT
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                 - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
            )
            SELECT
              {group_expr} AS `åç§°`,
              SUM(CASE WHEN fiscal_year = current_fy THEN sales_amount ELSE 0 END) AS `ä»ŠæœŸå£²ä¸Š`,
              SUM(CASE WHEN fiscal_year = current_fy - 1 AND sales_date <= py_today THEN sales_amount ELSE 0 END) AS `å‰å¹´åŒæœŸå£²ä¸Š`,
              SUM(CASE WHEN fiscal_year = current_fy THEN gross_profit ELSE 0 END) AS `ä»ŠæœŸç²—åˆ©`,
              SUM(CASE WHEN fiscal_year = current_fy - 1 AND sales_date <= py_today THEN gross_profit ELSE 0 END) AS `å‰å¹´åŒæœŸç²—åˆ©`
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN fy
            {filter_sql}
            GROUP BY `åç§°`
            HAVING `å‰å¹´åŒæœŸå£²ä¸Š` > 0 OR `ä»ŠæœŸå£²ä¸Š` > 0
            ORDER BY (`ä»ŠæœŸå£²ä¸Š` - `å‰å¹´åŒæœŸå£²ä¸Š`) {sort_order}
            LIMIT 50
        """
    else:
        sql_parent = f"""
            WITH fy AS (
              SELECT
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                 - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
            )
            SELECT
              customer_code AS `ã‚³ãƒ¼ãƒ‰`,
              ANY_VALUE(customer_name) AS `åç§°`,
              SUM(CASE WHEN fiscal_year = current_fy THEN sales_amount ELSE 0 END) AS `ä»ŠæœŸå£²ä¸Š`,
              SUM(CASE WHEN fiscal_year = current_fy - 1 AND sales_date <= py_today THEN sales_amount ELSE 0 END) AS `å‰å¹´åŒæœŸå£²ä¸Š`,
              SUM(CASE WHEN fiscal_year = current_fy THEN gross_profit ELSE 0 END) AS `ä»ŠæœŸç²—åˆ©`,
              SUM(CASE WHEN fiscal_year = current_fy - 1 AND sales_date <= py_today THEN gross_profit ELSE 0 END) AS `å‰å¹´åŒæœŸç²—åˆ©`
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN fy
            {filter_sql}
            GROUP BY `ã‚³ãƒ¼ãƒ‰`
            HAVING `å‰å¹´åŒæœŸå£²ä¸Š` > 0 OR `ä»ŠæœŸå£²ä¸Š` > 0
            ORDER BY (`ä»ŠæœŸå£²ä¸Š` - `å‰å¹´åŒæœŸå£²ä¸Š`) {sort_order}
            LIMIT 50
        """

    df_parent = query_df_safe(client, sql_parent, params, f"Parent Perf {perf_view}")
    if df_parent.empty:
        st.info("è¡¨ç¤ºã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # --- è¡¨ç¤ºç”¨ã®æ´¾ç”Ÿåˆ— ---
    df_parent["å£²ä¸Šå·®é¡"] = df_parent["ä»ŠæœŸå£²ä¸Š"] - df_parent["å‰å¹´åŒæœŸå£²ä¸Š"]
    df_parent["å£²ä¸Šæˆé•·ç‡"] = df_parent.apply(
        lambda r: ((r["ä»ŠæœŸå£²ä¸Š"] / r["å‰å¹´åŒæœŸå£²ä¸Š"] - 1) * 100) if r["å‰å¹´åŒæœŸå£²ä¸Š"] else 0,
        axis=1,
    )
    df_parent["ç²—åˆ©å·®é¡"] = df_parent["ä»ŠæœŸç²—åˆ©"] - df_parent["å‰å¹´åŒæœŸç²—åˆ©"]

    def get_parent_rank_icon(rank: int, mode: str) -> str:
        if mode == "ãƒ™ã‚¹ãƒˆ":
            if rank == 1:
                return "ğŸ¥‡ 1ä½"
            if rank == 2:
                return "ğŸ¥ˆ 2ä½"
            if rank == 3:
                return "ğŸ¥‰ 3ä½"
            return f"ğŸŒŸ {rank}ä½"
        else:
            if rank == 1:
                return "ğŸš¨ 1ä½"
            if rank == 2:
                return "âš ï¸ 2ä½"
            if rank == 3:
                return "âš¡ 3ä½"
            return f"ğŸ“‰ {rank}ä½"

    df_parent.insert(0, "é †ä½", [get_parent_rank_icon(i + 1, perf_mode) for i in range(len(df_parent))])

    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" and group_src:
        st.caption(f"æŠ½å‡ºå…ƒã‚°ãƒ«ãƒ¼ãƒ—åˆ—: `{group_src}`")

    # â˜…é‡è¦ï¼šé¸æŠçŠ¶æ…‹ã‚’æ°¸ç¶šåŒ–ï¼ˆâ˜‘ãªã©ã§rerunã—ã¦ã‚‚ãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ãŒæ¶ˆãˆãªã„ï¼‰
    sel_state_key = f"grpperf_selected_id::{perf_view}::{perf_mode}"
    sel_name_key = f"grpperf_selected_name::{perf_view}::{perf_mode}"

    if st.button("é¸æŠè§£é™¤ï¼ˆãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ã‚’é–‰ã˜ã‚‹ï¼‰", key=f"grpperf_clear::{perf_view}::{perf_mode}"):
        st.session_state.pop(sel_state_key, None)
        st.session_state.pop(sel_name_key, None)
        st.rerun()

    event = st.dataframe(
        df_parent.style.format(
            {
                "ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}",
                "å‰å¹´åŒæœŸå£²ä¸Š": "Â¥{:,.0f}",
                "ä»ŠæœŸç²—åˆ©": "Â¥{:,.0f}",
                "å‰å¹´åŒæœŸç²—åˆ©": "Â¥{:,.0f}",
                "å£²ä¸Šå·®é¡": "Â¥{:,.0f}",
                "å£²ä¸Šæˆé•·ç‡": "{:.1f}%",
                "ç²—åˆ©å·®é¡": "Â¥{:,.0f}",
            }
        ),
        use_container_width=True,
        hide_index=True,
        selection_mode="single-row",
        on_select="rerun",
        key=f"grid_parent::{perf_view}::{perf_mode}",
    )

    # --- é¸æŠã®å–å¾—ï¼ˆå–ã‚ŒãŸã‚‰ä¿å­˜ã€å–ã‚Œãªã„rerunã§ã¯ä¿å­˜å€¤ã‚’ä½¿ã†ï¼‰ ---
    selected_parent_id = st.session_state.get(sel_state_key)
    selected_parent_name = st.session_state.get(sel_name_key)

    try:
        sel_rows = []
        if hasattr(event, "selection") and hasattr(event.selection, "rows"):
            sel_rows = event.selection.rows
        elif isinstance(event, dict) and "selection" in event:
            sel_rows = event["selection"].get("rows", [])

        if sel_rows:
            idx = sel_rows[0]
            if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥":
                selected_parent_id = str(df_parent.iloc[idx]["åç§°"])
                selected_parent_name = selected_parent_id
            else:
                selected_parent_id = str(df_parent.iloc[idx]["ã‚³ãƒ¼ãƒ‰"])
                selected_parent_name = str(df_parent.iloc[idx]["åç§°"])

            st.session_state[sel_state_key] = selected_parent_id
            st.session_state[sel_name_key] = selected_parent_name
    except Exception:
        pass

    # --- ãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ï¼ˆè¦å› ï¼å“ç›®ï¼‰ ---
    if not selected_parent_id:
        st.info("ä¸Šã®è¡¨ã‹ã‚‰ã‚°ãƒ«ãƒ¼ãƒ—/å¾—æ„å…ˆã‚’1ä»¶ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€å“ç›®è¦å› ï¼ˆãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ï¼‰ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
        return

    st.markdown(f"#### ğŸ” è¦å› åˆ†æï¼ˆå•†å“ãƒ™ãƒ¼ã‚¹ {perf_mode}ãƒ»å…¨ä»¶ä¸€è¦§ï¼‰")

    drill_params = dict(params)
    drill_params["parent_id"] = selected_parent_id

    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥":
        drill_filter_sql = _compose_where(role_filter, scope_filter_clause, f"{group_expr} = @parent_id")
    else:
        drill_filter_sql = _compose_where(role_filter, scope_filter_clause, "customer_code = @parent_id")

    sql_drill = f"""
        WITH fy AS (
          SELECT (
            EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
            - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END
          ) AS current_fy,
          DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
        ),
        base_raw AS (
          SELECT
            COALESCE(
              NULLIF(NULLIF(TRIM(CAST(yj_code AS STRING)), ''), '0'),
              NULLIF(NULLIF(TRIM(CAST(jan_code AS STRING)), ''), '0'),
              TRIM(CAST(product_name AS STRING))
            ) AS yj_key,
            REGEXP_REPLACE(CAST(product_name AS STRING), r"[/ï¼].*$", "") AS product_base,
            SUM(CASE WHEN fiscal_year = current_fy THEN sales_amount ELSE 0 END) AS ty_sales,
            SUM(CASE WHEN fiscal_year = current_fy - 1 AND sales_date <= py_today THEN sales_amount ELSE 0 END) AS py_sales
          FROM `{VIEW_UNIFIED}`
          CROSS JOIN fy
          {drill_filter_sql}
          GROUP BY yj_key, product_base
        ),
        base AS (
          SELECT
            yj_key AS yj_code,
            ARRAY_AGG(product_base ORDER BY ty_sales DESC LIMIT 1)[OFFSET(0)] AS product_name,
            SUM(ty_sales) AS ty_sales,
            SUM(py_sales) AS py_sales
          FROM base_raw
          GROUP BY yj_code
        )
        SELECT
          yj_code,
          product_name,
          ty_sales AS sales_amount,
          py_sales AS py_sales_amount,
          (ty_sales - py_sales) AS sales_diff_yoy
        FROM base
        WHERE ty_sales > 0 OR py_sales > 0
        ORDER BY sales_diff_yoy {sort_order}
    """

    df_drill = query_df_safe(client, sql_drill, drill_params, "Parent Drilldown")
    if df_drill.empty:
        st.info("è¦å› ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    df_drill["product_name"] = df_drill["product_name"].apply(normalize_product_display_name)
    df_drill = df_drill.fillna(0)

    df_drill.insert(0, "è¦å› é †ä½", [get_parent_rank_icon(i + 1, perf_mode) for i in range(len(df_drill))])

    st.dataframe(
        df_drill[["è¦å› é †ä½", "product_name", "sales_amount", "py_sales_amount", "sales_diff_yoy"]].rename(
            columns={
                "product_name": "ä»£è¡¨å•†å“å(æˆåˆ†)",
                "sales_amount": "ä»ŠæœŸå£²ä¸Š",
                "py_sales_amount": "å‰å¹´åŒæœŸå£²ä¸Š",
                "sales_diff_yoy": "å‰å¹´æ¯”å·®é¡",
            }
        ).style.format({"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´åŒæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´æ¯”å·®é¡": "Â¥{:,.0f}"}),
        use_container_width=True,
        hide_index=True,
    )


def render_yoy_section(
    client: bigquery.Client,
    role: RoleInfo,
    scope: ScopeFilter,
    colmap: Dict[str, Dict[str, str]],
) -> None:
    st.subheader("ğŸ“Š å¹´é–“ YoY ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆæˆåˆ†ãƒ»YJå„ªå…ˆï½œYJ=0/nullã¯JANã‚­ãƒ¼ã§è¿½è·¡ï¼‰")

    if "yoy_mode" not in st.session_state:
        st.session_state.yoy_mode = "ãƒ¯ãƒ¼ã‚¹ãƒˆ"  # ãƒ¯ãƒ¼ã‚¹ãƒˆ / ãƒ™ã‚¹ãƒˆ / æ–°è¦
    if "yoy_df" not in st.session_state:
        st.session_state.yoy_df = pd.DataFrame()
    if "selected_yoy_key" not in st.session_state:
        st.session_state.selected_yoy_key = "å…¨æˆåˆ†ã‚’è¡¨ç¤º"

    u = colmap["unified"]
    login_col = bq_ident(u["login_email"])
    sales_date = bq_ident(u["sales_date"])
    fiscal_year = bq_ident(u["fiscal_year"])
    sales_amount = bq_ident(u["sales_amount"])
    jan_col = bq_ident(u["jan_code"])
    yj_col = bq_ident(u["yj_code"])
    prod_col = bq_ident(u["product_name"])
    pack_col = bq_ident(u["package_unit"])
    customer_name = bq_ident(u["customer_name"])

    c1, c2, c3 = st.columns(3)

    def load_yoy(mode_name: str) -> None:
        st.session_state.yoy_mode = mode_name

        role_filter = "" if role.role_admin_view else f"{login_col} = @login_email"
        scope_where = scope.where_clause()
        where_sql = _compose_where(role_filter, scope_where)

        params: Dict[str, Any] = dict(scope.params or {})
        if not role.role_admin_view:
            params["login_email"] = role.login_email

        if mode_name == "ãƒ¯ãƒ¼ã‚¹ãƒˆ":
            diff_filter = "py_sales > 0 AND (ty_sales - py_sales) < 0"
            order_by = "sales_diff_yoy ASC"
        elif mode_name == "ãƒ™ã‚¹ãƒˆ":
            diff_filter = "py_sales > 0 AND (ty_sales - py_sales) > 0"
            order_by = "sales_diff_yoy DESC"
        else:
            diff_filter = "py_sales = 0 AND ty_sales > 0"
            order_by = "ty_sales DESC"

        sql = f"""
            WITH fy AS (
              SELECT
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                 - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
            ),
            base_raw AS (
              SELECT
                COALESCE(
                  NULLIF(NULLIF(TRIM(CAST({yj_col} AS STRING)), ''), '0'),
                  NULLIF(NULLIF(TRIM(CAST({jan_col} AS STRING)), ''), '0'),
                  REGEXP_REPLACE(CAST({prod_col} AS STRING), r"[/ï¼].*$", "")
                ) AS yj_key,
                REGEXP_REPLACE(CAST({prod_col} AS STRING), r"[/ï¼].*$", "") AS product_base,
                SUM(CASE WHEN {fiscal_year} = fy.current_fy THEN {sales_amount} ELSE 0 END) AS ty_sales,
                SUM(CASE WHEN {fiscal_year} = fy.current_fy - 1 THEN {sales_amount} ELSE 0 END) AS py_sales
              FROM `{VIEW_UNIFIED}`
              CROSS JOIN fy
              {where_sql}
              GROUP BY yj_key, product_base
            ),
            base AS (
              SELECT
                yj_key,
                ARRAY_AGG(product_base ORDER BY ty_sales DESC LIMIT 1)[OFFSET(0)] AS product_name,
                SUM(ty_sales) AS ty_sales,
                SUM(py_sales) AS py_sales
              FROM base_raw
              GROUP BY yj_key
            )
            SELECT
              yj_key,
              product_name,
              ty_sales,
              py_sales,
              (ty_sales - py_sales) AS sales_diff_yoy
            FROM base
            WHERE {diff_filter}
            ORDER BY {order_by}
            LIMIT 100
        """
        st.session_state.yoy_df = query_df_safe(client, sql, params, f"YoY Load {mode_name}")

    with c1:
        if st.button("ğŸ“‰ ä¸‹è½å¹…ãƒ¯ãƒ¼ã‚¹ãƒˆ", use_container_width=True):
            load_yoy("ãƒ¯ãƒ¼ã‚¹ãƒˆ")
    with c2:
        if st.button("ğŸ“ˆ ä¸Šæ˜‡å¹…ãƒ™ã‚¹ãƒˆ", use_container_width=True):
            load_yoy("ãƒ™ã‚¹ãƒˆ")
    with c3:
        if st.button("ğŸ†• æ–°è¦/æ¯”è¼ƒä¸èƒ½", use_container_width=True):
            load_yoy("æ–°è¦")

    if st.session_state.yoy_df.empty:
        st.info("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã‚€ã«ã¯ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
        return

    df_rank = st.session_state.yoy_df.copy()
    df_rank["product_name"] = df_rank["product_name"].apply(normalize_product_display_name)

    st.markdown(f"#### ğŸ† ç¬¬ä¸€éšå±¤ï¼šæˆåˆ†ã‚­ãƒ¼ï¼ˆYJå„ªå…ˆï¼‰{st.session_state.yoy_mode} ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    event = st.dataframe(
        df_rank[["product_name", "ty_sales", "py_sales", "sales_diff_yoy"]].rename(
            columns={
                "product_name": "ä»£è¡¨å•†å“å(æˆåˆ†)",
                "ty_sales": "ä»ŠæœŸå£²ä¸Š",
                "py_sales": "å‰æœŸå£²ä¸Š",
                "sales_diff_yoy": "å‰å¹´æ¯”å·®é¡",
            }
        ).style.format({"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´æ¯”å·®é¡": "Â¥{:,.0f}"}),
        use_container_width=True,
        hide_index=True,
        selection_mode="single-row",
        on_select="rerun",
        key=f"grid_yoy_{st.session_state.yoy_mode}",
    )

    try:
        sel_rows = event.selection.rows if hasattr(event, "selection") else []
        if sel_rows:
            st.session_state.selected_yoy_key = str(df_rank.iloc[sel_rows[0]]["yj_key"])
    except Exception:
        pass

    st.divider()
    st.header("ğŸ” ç¬¬äºŒéšå±¤ï¼šè©³ç´°åˆ†æï¼ˆã‚¹ã‚³ãƒ¼ãƒ—å†…ï¼‰")

    key_opts = ["å…¨æˆåˆ†ã‚’è¡¨ç¤º"] + list(df_rank["yj_key"].astype(str).unique())
    display_map = {"å…¨æˆåˆ†ã‚’è¡¨ç¤º": "ğŸš© ã‚¹ã‚³ãƒ¼ãƒ—å†…ã®å…¨æˆåˆ†ã‚’åˆè¨ˆã—ã¦è¡¨ç¤º"}
    for _, r in df_rank.iterrows():
        k = str(r["yj_key"])
        display_map[k] = f"{normalize_product_display_name(r['product_name'])}ï¼ˆå·®é¡: Â¥{r['sales_diff_yoy']:,.0f}ï¼‰"

    idx = 0
    if st.session_state.selected_yoy_key in key_opts:
        idx = key_opts.index(st.session_state.selected_yoy_key)

    selected_key = st.selectbox(
        "è©³ç´°ã‚’è¦‹ãŸã„æˆåˆ†ã‚­ãƒ¼ã‚’é¸æŠï¼ˆ[å…¨æˆåˆ†ã‚’è¡¨ç¤º]ã§å…¨é‡ï¼‰",
        options=key_opts,
        index=idx,
        format_func=lambda x: display_map.get(x, x),
    )
    st.session_state.selected_yoy_key = selected_key

    role_filter = "" if role.role_admin_view else f"{login_col} = @login_email"
    scope_where = scope.where_clause()

    params: Dict[str, Any] = dict(scope.params or {})
    if not role.role_admin_view:
        params["login_email"] = role.login_email

    key_filter = ""
    if selected_key != "å…¨æˆåˆ†ã‚’è¡¨ç¤º":
        key_expr = f"""
          COALESCE(
            NULLIF(NULLIF(TRIM(CAST({yj_col} AS STRING)), ''), '0'),
            NULLIF(NULLIF(TRIM(CAST({jan_col} AS STRING)), ''), '0'),
            REGEXP_REPLACE(CAST({prod_col} AS STRING), r"[/ï¼].*$", "")
          )
        """
        key_filter = f"{' '.join(key_expr.split())} = @target_key"
        params["target_key"] = selected_key

    where_sql = _compose_where(role_filter, scope_where, key_filter)
    sort_order = "ASC" if st.session_state.yoy_mode == "ãƒ¯ãƒ¼ã‚¹ãƒˆ" else "DESC"

    st.markdown("#### ğŸ§¾ å¾—æ„å…ˆåˆ¥å†…è¨³ï¼ˆå‰å¹´å·®é¡ï¼‰")
    sql_cust = f"""
      WITH fy AS (
        SELECT
          (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
           - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
      ),
      base AS (
        SELECT
          CAST({customer_name} AS STRING) AS customer_name,
          SUM(CASE WHEN {fiscal_year} = fy.current_fy THEN {sales_amount} ELSE 0 END) AS ty_sales,
          SUM(CASE WHEN {fiscal_year} = fy.current_fy - 1 THEN {sales_amount} ELSE 0 END) AS py_sales
        FROM `{VIEW_UNIFIED}`
        CROSS JOIN fy
        {where_sql}
        GROUP BY customer_name
      )
      SELECT
        customer_name AS `å¾—æ„å…ˆå`,
        ty_sales AS `ä»ŠæœŸå£²ä¸Š`,
        py_sales AS `å‰æœŸå£²ä¸Š`,
        (ty_sales - py_sales) AS `å‰å¹´å·®é¡`
      FROM base
      WHERE ty_sales != 0 OR py_sales != 0
      ORDER BY `å‰å¹´å·®é¡` {sort_order}
      LIMIT 50
    """
    df_cust = query_df_safe(client, sql_cust, params, "YoY Detail Customers")
    if not df_cust.empty:
        st.dataframe(
            df_cust.fillna(0).style.format(
                {"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´å·®é¡": "Â¥{:,.0f}"}
            ),
            use_container_width=True,
            hide_index=True,
        )
    else:
        st.info("å¾—æ„å…ˆåˆ¥å†…è¨³ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    st.markdown("#### ğŸ§ª åŸå› è¿½åŠï¼šJANãƒ»å•†å“åˆ¥ï¼ˆå‰å¹´å·®é¡å¯„ä¸ï¼‰ï½œå…¨ä»¶/æ®µéšUIå¯¾å¿œ")
    with st.expander("JANãƒ»å•†å“åˆ¥ã®å…¨ä»¶è¡¨ç¤ºè¨­å®šï¼ˆé‡ã„å ´åˆã¯åˆ¶é™æ¨å¥¨ï¼‰", expanded=False):
        jan_limit_mode = st.radio("è¡¨ç¤ºä»¶æ•°", ["ä¸Šä½/ä¸‹ä½ã®ã¿ï¼ˆæ¨å¥¨ï¼‰", "å…¨ä»¶ï¼ˆå±é™ºï¼‰"], horizontal=True, key="yoy_jan_limit_mode")
        if jan_limit_mode == "ä¸Šä½/ä¸‹ä½ã®ã¿ï¼ˆæ¨å¥¨ï¼‰":
            jan_limit = st.slider("å–å¾—ä»¶æ•°ï¼ˆJANåˆ¥ï¼‰", min_value=100, max_value=5000, value=800, step=100, key="yoy_jan_limit")
        else:
            jan_limit = 0
    jan_limit_sql = f"LIMIT {int(jan_limit)}" if jan_limit and jan_limit > 0 else ""

    sql_jan = f"""
      WITH fy AS (
        SELECT
          (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
           - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
      ),
      base AS (
        SELECT
          CAST({jan_col} AS STRING) AS jan,
          REGEXP_REPLACE(CAST({prod_col} AS STRING), r"[/ï¼].*$", "") AS product_base,
          CAST({pack_col} AS STRING) AS package_unit,
          SUM(CASE WHEN {fiscal_year} = fy.current_fy THEN {sales_amount} ELSE 0 END) AS ty_sales,
          SUM(CASE WHEN {fiscal_year} = fy.current_fy - 1 THEN {sales_amount} ELSE 0 END) AS py_sales
        FROM `{VIEW_UNIFIED}`
        CROSS JOIN fy
        {where_sql}
        GROUP BY jan, product_base, package_unit
      )
      SELECT
        jan AS `JAN`,
        product_base AS `ä»£è¡¨å•†å“å`,
        package_unit AS `åŒ…è£…`,
        ty_sales AS `ä»ŠæœŸå£²ä¸Š`,
        py_sales AS `å‰æœŸå£²ä¸Š`,
        (ty_sales - py_sales) AS `å‰å¹´å·®é¡`
      FROM base
      WHERE ty_sales != 0 OR py_sales != 0
      ORDER BY `å‰å¹´å·®é¡` {sort_order}
      {jan_limit_sql}
    """

    df_jan = guard_and_run_query_ui(
        client,
        role,
        scope,
        sql_jan,
        params,
        label="YoY JANãƒ»å•†å“åˆ¥ï¼ˆå…¨ä»¶/æ®µéšUIï¼‰",
        risky_if_no_scope=True,
        force_estimate=(jan_limit == 0),
        timeout_sec=180,
    )
    if not df_jan.empty:
        st.dataframe(
            df_jan.fillna(0).style.format(
                {"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´å·®é¡": "Â¥{:,.0f}"}
            ),
            use_container_width=True,
            hide_index=True,
        )
    else:
        st.info("JANåˆ¥å†…è¨³ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆã¾ãŸã¯æœªå®Ÿè¡Œï¼‰ã€‚")

    st.markdown("#### ğŸ“… åŸå› è¿½åŠï¼šæœˆæ¬¡æ¨ç§»ï¼ˆå‰å¹´å·®é¡ï¼‰")
    sql_month = f"""
      WITH fy AS (
        SELECT
          (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
           - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
      ),
      base AS (
        SELECT
          FORMAT_DATE('%Y-%m', {sales_date}) AS ym,
          SUM(CASE WHEN {fiscal_year} = fy.current_fy THEN {sales_amount} ELSE 0 END) AS ty_sales,
          SUM(CASE WHEN {fiscal_year} = fy.current_fy - 1 THEN {sales_amount} ELSE 0 END) AS py_sales
        FROM `{VIEW_UNIFIED}`
        CROSS JOIN fy
        {where_sql}
        GROUP BY ym
      )
      SELECT
        ym AS `å¹´æœˆ`,
        ty_sales AS `ä»ŠæœŸå£²ä¸Š`,
        py_sales AS `å‰æœŸå£²ä¸Š`,
        (ty_sales - py_sales) AS `å‰å¹´å·®é¡`
      FROM base
      ORDER BY `å¹´æœˆ`
    """
    df_month = query_df_safe(client, sql_month, params, "YoY Detail Month")
    if not df_month.empty:
        st.dataframe(
            df_month.fillna(0).style.format(
                {"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´å·®é¡": "Â¥{:,.0f}"}
            ),
            use_container_width=True,
            hide_index=True,
        )
    else:
        st.info("æœˆæ¬¡æ¨ç§»ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")


def render_new_deliveries_section(
    client: bigquery.Client,
    role: RoleInfo,
    colmap: Dict[str, Dict[str, str]],
) -> None:
    st.subheader("ğŸ‰ æ–°è¦ç´å“ã‚µãƒãƒªãƒ¼ï¼ˆRealized / å®Ÿç¸¾ï¼‰")
    if st.button("æ–°è¦ç´å“å®Ÿç¸¾ã‚’èª­ã¿è¾¼ã‚€", key="btn_new_deliv"):
        nd = colmap["new_delivery"]
        first_date = bq_ident(nd["first_sales_date"])
        customer_code = bq_ident(nd["customer_code"])
        jan_code = bq_ident(nd["jan_code"])
        sales_amount = bq_ident(nd["sales_amount"])
        gross_profit = bq_ident(nd["gross_profit"])
        login_col = bq_ident(nd["login_email"]) if nd.get("login_email") else None

        where_ext = ""
        params = None
        if (not role.role_admin_view) and login_col is not None:
            where_ext = f"AND {login_col} = @login_email"
            params = {"login_email": role.login_email}
        elif not role.role_admin_view and login_col is None:
            st.warning("æ–°è¦ç´å“VIEWã« login_email ãŒç„¡ã„ãŸã‚ã€å€‹äººçµã‚Šè¾¼ã¿ã¯ã§ãã¾ã›ã‚“ï¼ˆå…¨ä½“ã‚’è¡¨ç¤ºã—ã¾ã™ï¼‰ã€‚")

        sql = f"""
        WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today)
        SELECT
          'â‘  æ˜¨æ—¥' AS `æœŸé–“`,
          COUNT(DISTINCT CAST({customer_code} AS STRING)) AS `å¾—æ„å…ˆæ•°`,
          COUNT(DISTINCT CAST({jan_code} AS STRING)) AS `å“ç›®æ•°`,
          SUM({sales_amount}) AS `å£²ä¸Š`,
          SUM({gross_profit}) AS `ç²—åˆ©`
        FROM `{VIEW_NEW_DELIVERY}` CROSS JOIN td
        WHERE {first_date} = DATE_SUB(today, INTERVAL 1 DAY) {where_ext}
        UNION ALL
        SELECT
          'â‘¡ ç›´è¿‘7æ—¥',
          COUNT(DISTINCT CAST({customer_code} AS STRING)),
          COUNT(DISTINCT CAST({jan_code} AS STRING)),
          SUM({sales_amount}),
          SUM({gross_profit})
        FROM `{VIEW_NEW_DELIVERY}` CROSS JOIN td
        WHERE {first_date} >= DATE_SUB(today, INTERVAL 7 DAY) {where_ext}
        UNION ALL
        SELECT
          'â‘¢ å½“æœˆ',
          COUNT(DISTINCT CAST({customer_code} AS STRING)),
          COUNT(DISTINCT CAST({jan_code} AS STRING)),
          SUM({sales_amount}),
          SUM({gross_profit})
        FROM `{VIEW_NEW_DELIVERY}` CROSS JOIN td
        WHERE DATE_TRUNC({first_date}, MONTH) = DATE_TRUNC(today, MONTH) {where_ext}
        ORDER BY `æœŸé–“`
        """
        df_new = query_df_safe(client, sql, params, label="New Deliveries")

        if not df_new.empty:
            df_new[["å£²ä¸Š", "ç²—åˆ©"]] = df_new[["å£²ä¸Š", "ç²—åˆ©"]].fillna(0)
            st.dataframe(
                df_new.style.format({"å£²ä¸Š": "Â¥{:,.0f}", "ç²—åˆ©": "Â¥{:,.0f}"}),
                use_container_width=True,
                hide_index=True,
            )
        else:
            st.info("æ–°è¦ç´å“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")


def render_adoption_alerts_section(
    client: bigquery.Client,
    role: RoleInfo,
    colmap: Dict[str, Dict[str, str]],
) -> None:
    st.subheader("ğŸš¨ æ¡ç”¨ã‚¢ã‚¤ãƒ†ãƒ ãƒ»å¤±æ³¨ã‚¢ãƒ©ãƒ¼ãƒˆ")

    ad = colmap["adoption"]
    login_col = bq_ident(ad["login_email"]) if ad.get("login_email") else None

    staff_name = bq_ident(ad["staff_name"]) if ad.get("staff_name") else None
    customer_name = bq_ident(ad["customer_name"])
    product_name = bq_ident(ad["product_name"])
    last_purchase_date = bq_ident(ad["last_purchase_date"])
    adoption_status = bq_ident(ad["adoption_status"])
    current_fy_sales = bq_ident(ad["current_fy_sales"])
    previous_fy_sales = bq_ident(ad["previous_fy_sales"])

    where_clause = ""
    params = None
    if (not role.role_admin_view) and login_col is not None:
        where_clause = f"WHERE {login_col} = @login_email"
        params = {"login_email": role.login_email}
    elif not role.role_admin_view and login_col is None:
        st.warning("æ¡ç”¨ã‚¢ãƒ©ãƒ¼ãƒˆVIEWã« login_email ãŒç„¡ã„ãŸã‚ã€å€‹äººçµã‚Šè¾¼ã¿ã¯ã§ãã¾ã›ã‚“ï¼ˆå…¨ä½“ã‚’è¡¨ç¤ºã—ã¾ã™ï¼‰ã€‚")

    staff_select = f"CAST({staff_name} AS STRING) AS `æ‹…å½“è€…å`," if staff_name else "'-' AS `æ‹…å½“è€…å`,"

    sql = f"""
        SELECT
            {staff_select}
            CAST({customer_name} AS STRING) AS `å¾—æ„å…ˆå`,
            CAST({product_name} AS STRING) AS `å•†å“å`,
            {last_purchase_date} AS `æœ€çµ‚è³¼å…¥æ—¥`,
            CAST({adoption_status} AS STRING) AS `ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹`,
            {current_fy_sales} AS `ä»ŠæœŸå£²ä¸Š`,
            {previous_fy_sales} AS `å‰æœŸå£²ä¸Š`,
            ({current_fy_sales} - {previous_fy_sales}) AS `å£²ä¸Šå·®é¡`
        FROM `{VIEW_ADOPTION}`
        {where_clause}
        ORDER BY
            CASE
                WHEN CAST({adoption_status} AS STRING) LIKE '%ğŸ”´%' THEN 1
                WHEN CAST({adoption_status} AS STRING) LIKE '%ğŸŸ¡%' THEN 2
                ELSE 3
            END,
            `å£²ä¸Šå·®é¡` ASC
    """
    df_alerts = query_df_safe(client, sql, params, "Adoption Alerts")
    if df_alerts.empty:
        st.info("ç¾åœ¨ã€ã‚¢ãƒ©ãƒ¼ãƒˆå¯¾è±¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df_alerts["æ‹…å½“è€…å"] = df_alerts["æ‹…å½“è€…å"].fillna("æœªè¨­å®š")
    col1, col2 = st.columns(2)
    with col1:
        selected_status = st.multiselect(
            "ğŸ¯ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§çµã‚Šè¾¼ã¿",
            options=df_alerts["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"].unique(),
            default=[s for s in df_alerts["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"].unique() if "ğŸŸ¡" in s or "ğŸ”´" in s],
        )
    with col2:
        all_staffs = sorted(df_alerts["æ‹…å½“è€…å"].unique().tolist())
        selected_staffs = st.multiselect("ğŸ‘¤ æ‹…å½“è€…ã§çµã‚Šè¾¼ã¿", options=all_staffs, default=[])

    df_display = df_alerts.copy()
    if selected_status:
        df_display = df_display[df_display["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"].isin(selected_status)]
    if selected_staffs:
        df_display = df_display[df_display["æ‹…å½“è€…å"].isin(selected_staffs)]

    if df_display.empty:
        st.info("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    for col in ["ä»ŠæœŸå£²ä¸Š", "å‰æœŸå£²ä¸Š", "å£²ä¸Šå·®é¡"]:
        df_display[col] = pd.to_numeric(df_display[col], errors="coerce").fillna(0)

    st.dataframe(
        df_display.style.format(
            {
                "ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}",
                "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}",
                "å£²ä¸Šå·®é¡": "Â¥{:,.0f}",
                "æœ€çµ‚è³¼å…¥æ—¥": lambda t: t.strftime("%Y-%m-%d") if pd.notnull(t) else "",
            }
        ),
        use_container_width=True,
        hide_index=True,
    )


def render_customer_drilldown(
    client: bigquery.Client,
    role: RoleInfo,
    scope: ScopeFilter,
    colmap: Dict[str, Dict[str, str]],
) -> None:
    st.subheader("ğŸ¯ æ‹…å½“å…ˆãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ ï¼† ææ¡ˆï¼ˆRecoï¼‰")

    u = colmap["unified"]
    login_col = bq_ident(u["login_email"])
    customer_code = bq_ident(u["customer_code"])
    customer_name = bq_ident(u["customer_name"])

    role_filter = "" if role.role_admin_view else f"{login_col} = @login_email"
    scope_filter = scope.where_clause()
    customer_where = _compose_where(role_filter, scope_filter, f"{customer_name} IS NOT NULL")

    customer_params: Dict[str, Any] = dict(scope.params or {})
    if not role.role_admin_view:
        customer_params["login_email"] = role.login_email

    # ç®¡ç†è€…ã§ã‚¹ã‚³ãƒ¼ãƒ—ãªã—ã¯å±é™º â†’ æ®µéšUI
    sql_cust = f"""
        SELECT DISTINCT
          CAST({customer_code} AS STRING) AS customer_code,
          CAST({customer_name} AS STRING) AS customer_name
        FROM `{VIEW_UNIFIED}`
        {customer_where}
        ORDER BY customer_name
        LIMIT 3000
    """
    df_cust = guard_and_run_query_ui(
        client,
        role,
        scope,
        sql_cust,
        customer_params,
        label="å¾—æ„å…ˆä¸€è¦§ã‚’å–å¾—ï¼ˆãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ï¼‰",
        risky_if_no_scope=True,
        force_estimate=False,
        timeout_sec=120,
    )
    if df_cust.empty:
        st.info("è¡¨ç¤ºã§ãã‚‹å¾—æ„å…ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆã¾ãŸã¯æœªå®Ÿè¡Œï¼‰ã€‚")
        return

    search_term = st.text_input("ğŸ” å¾—æ„å…ˆåã§æ¤œç´¢ï¼ˆä¸€éƒ¨å…¥åŠ›ï¼‰", placeholder="ä¾‹ï¼šå¤è³€")
    filtered_df = df_cust[df_cust["customer_name"].str.contains(search_term, na=False)] if search_term else df_cust
    if filtered_df.empty:
        st.info("æ¤œç´¢æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹å¾—æ„å…ˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    opts = {row["customer_code"]: f"{row['customer_code']} : {row['customer_name']}" for _, row in filtered_df.iterrows()}
    sel = st.selectbox("å¾—æ„å…ˆã‚’é¸æŠ", options=list(opts.keys()), format_func=lambda x: opts[x])
    if not sel:
        return

    st.divider()
    st.markdown("##### ğŸ“¦ ç¾åœ¨ã®æ¡ç”¨ã‚¢ã‚¤ãƒ†ãƒ ï¼ˆç¨¼åƒçŠ¶æ³ï¼‰")

    ad = colmap["adoption"]
    ad_customer_code = bq_ident(ad["customer_code"])
    ad_product_name = bq_ident(ad["product_name"])
    ad_status = bq_ident(ad["adoption_status"])
    ad_last = bq_ident(ad["last_purchase_date"])
    ad_cur = bq_ident(ad["current_fy_sales"])
    ad_py = bq_ident(ad["previous_fy_sales"])

    sql_adopt = f"""
        SELECT
            CAST({ad_product_name} AS STRING) AS `å•†å“å`,
            CAST({ad_status} AS STRING) AS `ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹`,
            {ad_last} AS `æœ€çµ‚è³¼å…¥æ—¥`,
            {ad_cur} AS `ä»ŠæœŸå£²ä¸Š`,
            {ad_py} AS `å‰æœŸå£²ä¸Š`
        FROM `{VIEW_ADOPTION}`
        WHERE CAST({ad_customer_code} AS STRING) = @c
        ORDER BY
            CASE
                WHEN CAST({ad_status} AS STRING) LIKE '%ğŸŸ¢%' THEN 1
                WHEN CAST({ad_status} AS STRING) LIKE '%ğŸŸ¡%' THEN 2
                ELSE 3
            END,
            {ad_cur} DESC
    """
    df_adopt = query_df_safe(client, sql_adopt, {"c": sel}, "Customer Adoption")
    if not df_adopt.empty:
        for col in ["ä»ŠæœŸå£²ä¸Š", "å‰æœŸå£²ä¸Š"]:
            df_adopt[col] = pd.to_numeric(df_adopt[col], errors="coerce").fillna(0)
        st.dataframe(
            df_adopt.style.format(
                {
                    "ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}",
                    "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}",
                    "æœ€çµ‚è³¼å…¥æ—¥": lambda t: t.strftime("%Y-%m-%d") if pd.notnull(t) else "",
                }
            ),
            use_container_width=True,
            hide_index=True,
        )
    else:
        st.info("ã“ã®å¾—æ„å…ˆã®æ¡ç”¨ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    st.markdown("<br>", unsafe_allow_html=True)
    st.markdown("##### ğŸ’¡ AI æ¨å¥¨ææ¡ˆå•†å“ï¼ˆRecoï¼‰")

    rc = colmap["recommend"]
    rc_customer_code = bq_ident(rc["customer_code"])
    rc_rank = bq_ident(rc["priority_rank"])
    rc_prod = bq_ident(rc["recommend_product"])
    rc_manu = bq_ident(rc["manufacturer"]) if rc.get("manufacturer") else None
    rc_cat = bq_ident(rc["strong_category"]) if rc.get("strong_category") else None
    rc_scale = bq_ident(rc["market_scale"]) if rc.get("market_scale") else None

    select_cols = [
        f"{rc_rank} AS priority_rank",
        f"{rc_prod} AS recommend_product",
    ]
    if rc_manu:
        select_cols.append(f"{rc_manu} AS manufacturer")
    else:
        select_cols.append("NULL AS manufacturer")
    if rc_cat:
        select_cols.append(f"{rc_cat} AS strong_category")
    else:
        select_cols.append("NULL AS strong_category")
    if rc_scale:
        select_cols.append(f"{rc_scale} AS market_scale")
    else:
        select_cols.append("NULL AS market_scale")

    sql_rec = f"""
        SELECT
          {", ".join(select_cols)}
        FROM `{VIEW_RECOMMEND}`
        WHERE CAST({rc_customer_code} AS STRING) = @c
        ORDER BY priority_rank ASC
        LIMIT 10
    """
    df_rec = query_df_safe(client, sql_rec, {"c": sel}, "Recommendation")
    if not df_rec.empty:
        df_disp = df_rec.rename(
            columns={
                "priority_rank": "é †ä½",
                "recommend_product": "æ¨å¥¨å•†å“",
                "manufacturer": "ãƒ¡ãƒ¼ã‚«ãƒ¼",
                "strong_category": "å¼·ã¿åˆ†é¡",
                "market_scale": "å¸‚å ´è¦æ¨¡",
            }
        )[["é †ä½", "æ¨å¥¨å•†å“", "ãƒ¡ãƒ¼ã‚«ãƒ¼", "å¼·ã¿åˆ†é¡", "å¸‚å ´è¦æ¨¡"]]
        st.dataframe(df_disp, use_container_width=True, hide_index=True)
    else:
        st.info("ç¾åœ¨ã€ã“ã®å¾—æ„å…ˆã¸ã®æ¨å¥¨å•†å“ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")


# -----------------------------
# 5. Main Loop
# -----------------------------
def main() -> None:
    set_page()
    client = setup_bigquery_client()

    with st.sidebar:
        st.header("ğŸ”‘ ãƒ­ã‚°ã‚¤ãƒ³")
        login_id = st.text_input("ãƒ­ã‚°ã‚¤ãƒ³ID (ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹)")
        login_pw = st.text_input("ãƒ‘ã‚¹ã‚³ãƒ¼ãƒ‰ (æºå¸¯ä¸‹4æ¡)", type="password")

        st.divider()
        st.session_state.use_bqstorage = st.checkbox("é«˜é€Ÿèª­è¾¼ (Storage API)", value=True)

        if st.button("ğŸ“¡ é€šä¿¡ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"):
            try:
                client.query("SELECT 1").result(timeout=10)
                st.success("BigQuery æ¥ç¶šæ­£å¸¸")
            except Exception as e:
                st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")

        if st.button("ğŸ§¹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"):
            st.cache_data.clear()
            st.cache_resource.clear()

        st.divider()
        st.caption("â€» ç®¡ç†è€…ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³çµ±åˆ¶ã¯ã€ãƒ­ã‚°ã‚¤ãƒ³å¾Œã«æœ‰åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚")

    if not login_id or not login_pw:
        st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
        return

    role = resolve_role(client, login_id.strip(), login_pw.strip())
    if not role.is_authenticated:
        st.error("âŒ ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # åˆ—åå·®ç•°å¸åï¼ˆå¿…é ˆï¼‰
    colmap = resolve_view_columns_map(client)
    if not require_colmap_ok(colmap):
        return

    st.success(f"ğŸ”“ ãƒ­ã‚°ã‚¤ãƒ³ä¸­: {role.staff_name} ã•ã‚“")
    c1, c2, c3 = st.columns(3)
    c1.metric("ğŸ‘¤ æ‹…å½“", role.staff_name)
    c2.metric("ğŸ›¡ï¸ æ¨©é™", role.role_key)
    c3.metric("ğŸ“ é›»è©±", role.phone)
    st.divider()

    # è¡¨ç¤ºé †åºï¼šã‚µãƒãƒªãƒ¼ã‚’æœ€ä¸Šéƒ¨ï¼ˆè¸è¥² + MTDè¿½åŠ ï¼‰
    if role.role_admin_view:
        render_fytd_org_section(client, colmap)
    else:
        render_fytd_me_section(client, role.login_email, colmap)

    st.divider()

    # ã‚¹ã‚³ãƒ¼ãƒ—è¨­å®š
    scope = render_scope_filters(client, role)
    st.divider()

    # ç®¡ç†è€…ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³çµ±åˆ¶UIï¼ˆãƒ­ã‚°ã‚¤ãƒ³å¾Œã«è¡¨ç¤ºï¼‰
    _ = get_admin_scan_policy(role)

    if role.role_admin_view:
        render_group_underperformance_section(client, role, scope, colmap)
        st.divider()
        render_yoy_section(client, role, scope, colmap)
        st.divider()
        render_new_deliveries_section(client, role, colmap)
        st.divider()
        render_adoption_alerts_section(client, role, colmap)
        st.divider()
        render_customer_drilldown(client, role, scope, colmap)
    else:
        render_yoy_section(client, role, scope, colmap)
        st.divider()
        render_new_deliveries_section(client, role, colmap)
        st.divider()
        render_adoption_alerts_section(client, role, colmap)
        st.divider()
        render_customer_drilldown(client, role, scope, colmap)


if __name__ == "__main__":
    main()
