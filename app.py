# app.py

# -*- coding: utf-8 -*-

"""

SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - OS v1.9.8 (Master Integrated / High Performance)



ã€æ›´æ–°å±¥æ­´ v1.9.8ã€‘

- [Integration] æ‹…å½“è€…å°å¸³(sales_staff_master)ã‚’ãƒã‚¹ã‚¿ãƒ¼ã¨ã—ã¦çµ±åˆã€‚

- [Feature] ãƒ­ã‚°ã‚¤ãƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œé›»è©±ç•ªå·ã€è¡¨ç¤ºãŠã‚ˆã³ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãƒ™ãƒ¼ã‚¹ã®æ¨©é™åˆ¤å®šã‚’å®Ÿè£…ã€‚

- [Structure] v1.9.7ã®å‹•çš„SQLã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å®Œå…¨è¸è¥²ã€‚

"""



from __future__ import annotations



import json

from dataclasses import dataclass

from typing import Any, Dict, List, Optional, Tuple



import pandas as pd

import streamlit as st

from pandas.api.types import is_numeric_dtype



from google.cloud import bigquery

from google.oauth2 import service_account





# -----------------------------

# 1. Configuration

# -----------------------------

APP_TITLE = "SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"

DEFAULT_LOCATION = "asia-northeast1"

CACHE_TTL_SEC = 300



APP_URL = "https://sfa-premium-app-2.streamlit.app/"

PROJECT_DEFAULT = "salesdb-479915"

DATASET_DEFAULT = "sales_data"



# â˜…åˆ†æã®åœŸå°ã¨ãªã‚‹çµ±åˆView

VIEW_UNIFIED = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_unified"



# KPIã‚«ãƒ¼ãƒ‰ç”¨ãªã©ã®æ—¢å­˜View

VIEW_FYTD_ORG = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_admin_org_fytd_summary_scoped"

VIEW_FYTD_ME = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_staff_fytd_summary_scoped"

VIEW_YOY_TOP = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_top_current_month_named"

VIEW_YOY_BOTTOM = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_bottom_current_month_named"

VIEW_YOY_UNCOMP = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_uncomparable_current_month_named"

VIEW_RECOMMEND = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_recommendation_engine"

VIEW_FACT_DAILY = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_login_jan_daily"



# â˜…ã€æ›´æ–°ã€‘å‚ç…§å…ˆã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆé€£æºãƒ†ãƒ¼ãƒ–ãƒ«ã«å¤‰æ›´

VIEW_ROLE = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.sales_staff_master"



# é™¤å¤–ã‚³ãƒ¼ãƒ‰å®šç¾©

NOISE_JAN_SQL = "('0', '22221', '99998', '33334')"





# -----------------------------

# 2. Helpers (Display) - å¤‰æ›´ãªã—

# -----------------------------

def set_page():

    st.set_page_config(page_title=APP_TITLE, layout="wide")

    st.title(APP_TITLE)

    st.caption("OS v1.9.8 (Master Integrated)ï½œBigQueryé›†è¨ˆãƒ»å‹•çš„SQLç‰ˆ")



def get_qr_code_url(url: str) -> str:

    return f"https://api.qrserver.com/v1/create-qr-code/?size=150x150&data={url}"



def rename_columns_for_display(df: pd.DataFrame, mapping: Dict[str, str]) -> pd.DataFrame:

    if df is None or df.empty: return df

    cols = {c: mapping.get(c, c) for c in df.columns}

    return df.rename(columns=cols)



def create_default_column_config(df: pd.DataFrame) -> Dict[str, st.column_config.Column]:

    config = {}

    for col in df.columns:

        if any(k in col for k in ["å£²ä¸Š", "ç²—åˆ©", "é‡‘é¡", "å·®", "å®Ÿç¸¾", "äºˆæ¸¬", "GAP"]):

            config[col] = st.column_config.NumberColumn(col, format="Â¥%d")

        elif any(k in col for k in ["ç‡", "æ¯”", "ãƒšãƒ¼ã‚¹"]):

            config[col] = st.column_config.NumberColumn(col, format="%.1f%%")

        elif is_numeric_dtype(df[col]):

            config[col] = st.column_config.NumberColumn(col, format="%d")

        else:

            config[col] = st.column_config.TextColumn(col)

    return config



def get_safe_float(row: pd.Series, key: str) -> float:

    val = row.get(key)

    if pd.isna(val): return 0.0

    return float(val)



JP_COLS_FYTD = {

    "login_email": "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«", "display_name": "æ‹…å½“è€…å",

    "sales_amount_fytd": "å£²ä¸Šï¼ˆFYTDï¼‰", "gross_profit_fytd": "ç²—åˆ©ï¼ˆFYTDï¼‰",

    "sales_amount_py_total": "å‰å¹´å£²ä¸Šå®Ÿç¸¾ï¼ˆå¹´ï¼‰", "sales_forecast_total": "å£²ä¸Šç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰",

    "gross_profit_py_total": "å‰å¹´ç²—åˆ©å®Ÿç¸¾ï¼ˆå¹´ï¼‰", "gp_forecast_total": "ç²—åˆ©ç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰"

}

JP_COLS_YOY = {

    "customer_code": "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", "customer_name": "å¾—æ„å…ˆå",

    "sales_amount": "å£²ä¸Šï¼ˆå½“æœˆï¼‰", "gross_profit": "ç²—åˆ©ï¼ˆå½“æœˆï¼‰",

    "sales_amount_py": "å£²ä¸Šï¼ˆå‰å¹´åŒæœˆï¼‰", "sales_diff_yoy": "å‰å¹´å·®ï¼ˆå£²ä¸Šï¼‰"

}





# -----------------------------

# 3. BigQuery Connection

# -----------------------------

def setup_bigquery_client() -> Tuple[bigquery.Client, str, str, str]:

    if "bigquery" not in st.secrets:

        st.error("âŒ Secretsè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

        st.stop()

    bq = st.secrets["bigquery"]

    project_id = str(bq.get("project_id"))

    location = str(bq.get("location") or DEFAULT_LOCATION)

    sa = dict(bq.get("service_account"))

    creds = service_account.Credentials.from_service_account_info(sa)

    client = bigquery.Client(project=project_id, credentials=creds, location=location)

    return client, project_id, location, json.dumps(sa)



def query_df_safe(client: bigquery.Client, sql: str, params: Optional[Dict[str, Any]] = None, label: str = "", use_bqstorage: bool = True, timeout_sec: int = 60) -> pd.DataFrame:

    try:

        job_config = bigquery.QueryJobConfig()

        qparams = []

        if params:

            for k, v in params.items():

                if isinstance(v, int): qparams.append(bigquery.ScalarQueryParameter(k, "INT64", v))

                elif isinstance(v, float): qparams.append(bigquery.ScalarQueryParameter(k, "FLOAT64", v))

                else: qparams.append(bigquery.ScalarQueryParameter(k, "STRING", str(v)))

        if qparams: job_config.query_parameters = qparams

        job = client.query(sql, job_config=job_config)

        job.result(timeout=timeout_sec)

        return job.to_dataframe(create_bqstorage_client=use_bqstorage)

    except Exception as e:

        st.error(f"Query Failed: {label}\n{e}")

        return pd.DataFrame()



# â˜…ã€æ›´æ–°ã€‘é›»è©±ç•ªå·ã¨è¡¨ç¤ºåã‚’è¿½åŠ 

@dataclass(frozen=True)

class RoleInfo:

    login_email: str

    staff_name: str = "ã‚²ã‚¹ãƒˆ"

    role_key: str = "SALES"

    role_admin_view: bool = False

    phone: str = "-"

    area_name: str = "æœªè¨­å®š"



# â˜…ã€æ›´æ–°ã€‘ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ(sales_staff_master)ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã‚ˆã†ã«å¤‰æ›´

def resolve_role(client, login_email) -> RoleInfo:

    # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå´ã®åˆ—åã«åˆã‚ã›ã¦SQLã‚’èª¿æ•´

    sql = f"""

    SELECT 

        email, 

        staff_name, 

        role, 

        phone 

    FROM `{VIEW_ROLE}` 

    WHERE email = @login_email 

    LIMIT 1

    """

    df = query_df_safe(client, sql, {"login_email": login_email}, "Role Check")

    

    if df.empty: 

        return RoleInfo(login_email=login_email)

    

    r = df.iloc[0]

    raw_role = str(r.get("role", "")).strip().upper()

    

    # æ¨©é™åˆ¤å®šï¼ˆADMINæ–‡å­—ãŒå«ã¾ã‚Œã‚‹ã‹ã€æ˜ç¤ºçš„ãªãƒªã‚¹ãƒˆã§åˆ¤å®šï¼‰

    is_admin = any(x in raw_role for x in ["ADMIN", "MANAGER", "HQ"])

    rk = "HQ_ADMIN" if is_admin else "SALES"

    

    return RoleInfo(

        login_email=login_email,

        staff_name=str(r.get("staff_name", "ä¸æ˜")),

        role_key=rk,

        role_admin_view=is_admin,

        phone=str(r.get("phone", "-")),

        area_name=raw_role # roleã‚’ãã®ã¾ã¾ã‚¨ãƒªã‚¢åã¨ã—ã¦æµç”¨

    )



def run_scoped_query(client, sql_template, scope_col, login_email, allow_fallback=False):

    sql = sql_template.replace("__WHERE__", f"WHERE {scope_col} = @login_email")

    df = query_df_safe(client, sql, {"login_email": login_email}, "Scoped Query")

    if not df.empty: return df

    if allow_fallback:

        sql_all = sql_template.replace("__WHERE__", f'WHERE {scope_col} = "all" OR {scope_col} IS NULL')

        return query_df_safe(client, sql_all, None, "Fallback Query")

    return pd.DataFrame()





# -----------------------------

# 4. â˜…BigQuery Calculation Logicâ˜… - å¤‰æ›´ãªã—

# -----------------------------

def fetch_ranking_from_bq(client, ranking_type: str, axis_mode: str, is_sales_mode: bool) -> pd.DataFrame:

    is_worst = (ranking_type == "worst")

    is_product = (axis_mode == "product")

    group_col = "product_name" if is_product else "customer_name"

    target_val = "sales_amount" if is_sales_mode else "gross_profit"

    order_dir = "ASC" if is_worst else "DESC"



    sql = f"""

    WITH base_stats AS (

        SELECT MAX(fiscal_year) AS current_fy FROM `{VIEW_UNIFIED}`

    )

    SELECT

        {group_col} AS name,

        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN sales_amount ELSE 0 END) AS sales_cur,

        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN gross_profit ELSE 0 END) AS gp_cur,

        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) - 1 THEN sales_amount ELSE 0 END) AS sales_prev,

        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN {target_val} ELSE 0 END) - 

        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) - 1 THEN {target_val} ELSE 0 END) AS diff_val,

        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN sales_amount ELSE 0 END) - 

        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) - 1 THEN sales_amount ELSE 0 END) AS sales_diff,

        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN gross_profit ELSE 0 END) - 

        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) - 1 THEN gross_profit ELSE 0 END) AS gp_diff

    FROM `{VIEW_UNIFIED}`

    WHERE

        jan_code NOT IN {NOISE_JAN_SQL}

        AND jan_code NOT LIKE '999%'

        AND LENGTH(jan_code) > 5

    GROUP BY {group_col}

    HAVING (sales_cur > 0 OR sales_prev > 0)

    ORDER BY diff_val {order_dir}

    LIMIT 1000

    """

    return query_df_safe(client, sql, None, "Ranking Query")



def fetch_drilldown_from_bq(client, key_col: str, key_val: str, target_col: str, is_worst: bool, is_sales_mode: bool) -> pd.DataFrame:

    order_dir = "ASC" if is_worst else "DESC"

    sort_col_alias = "å£²ä¸Šå·®é¡" if is_sales_mode else "ç²—åˆ©å·®é¡"

    target_label = "å¾—æ„å…ˆå" if target_col == "customer_name" else "å•†å“å"



    sql = f"""

        SELECT 

            {target_col} AS `{target_label}`,

            SUM(CASE WHEN fiscal_year = 2025 THEN sales_amount ELSE 0 END) as `ä»Šå¹´å£²ä¸Š`,

            SUM(CASE WHEN fiscal_year = 2024 THEN sales_amount ELSE 0 END) as `å‰å¹´å£²ä¸Š`,

            SUM(CASE WHEN fiscal_year = 2025 THEN sales_amount ELSE 0 END) - 

            SUM(CASE WHEN fiscal_year = 2024 THEN sales_amount ELSE 0 END) as `å£²ä¸Šå·®é¡`,

            SUM(CASE WHEN fiscal_year = 2025 THEN gross_profit ELSE 0 END) as `ä»Šå¹´ç²—åˆ©`,

            SUM(CASE WHEN fiscal_year = 2025 THEN gross_profit ELSE 0 END) - 

            SUM(CASE WHEN fiscal_year = 2024 THEN gross_profit ELSE 0 END) as `ç²—åˆ©å·®é¡`

        FROM `{VIEW_UNIFIED}`

        WHERE {key_col} = @key_val

        GROUP BY 1

        ORDER BY `{sort_col_alias}` {order_dir}

        LIMIT 500

    """

    return query_df_safe(client, sql, {"key_val": key_val}, "Drilldown Query")





# -----------------------------

# 5. UI Layout - é–¢æ•°å®šç¾©ã¯è¸è¥²

# -----------------------------

def sidebar_controls() -> Dict[str, Any]:

    st.sidebar.image(get_qr_code_url(APP_URL), caption="ğŸ“±ã‚¹ãƒãƒ›ã§ã‚¢ã‚¯ã‚»ã‚¹", width=150)

    st.sidebar.divider()

    if st.sidebar.button("Clear Cache"):

        st.cache_data.clear()

        st.sidebar.success("Cache Cleared.")

    return {}



def get_login_email_ui() -> str:

    st.sidebar.header("Login Simulation")

    default = st.secrets.get("default_login_email", "") if "default_login_email" in st.secrets else ""

    return st.sidebar.text_input("Login Email", value=default).strip()



def render_interactive_ranking_matrix(client, ranking_type: str, axis_mode: str, is_sales_mode: bool):

    is_worst = (ranking_type == "worst")

    is_product = (axis_mode == "product")

    label_col = "å•†å“å" if is_product else "å¾—æ„å…ˆå"

    mode_label = "å£²ä¸Š" if is_sales_mode else "ç²—åˆ©"

    df_rank = fetch_ranking_from_bq(client, ranking_type, axis_mode, is_sales_mode)

    if df_rank.empty:

        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

        return

    df_disp = df_rank.rename(columns={"name": label_col, "sales_cur": "ä»Šå¹´å£²ä¸Š", "sales_prev": "å‰å¹´å£²ä¸Š", "sales_diff": "å£²ä¸Šå·®é¡", "gp_cur": "ä»Šå¹´ç²—åˆ©", "gp_diff": "ç²—åˆ©å·®é¡"})

    if is_sales_mode: cols = [label_col, "å£²ä¸Šå·®é¡", "ä»Šå¹´å£²ä¸Š", "å‰å¹´å£²ä¸Š", "ç²—åˆ©å·®é¡", "ä»Šå¹´ç²—åˆ©"]

    else: cols = [label_col, "ç²—åˆ©å·®é¡", "ä»Šå¹´ç²—åˆ©", "å£²ä¸Šå·®é¡", "ä»Šå¹´å£²ä¸Š", "å‰å¹´å£²ä¸Š"]

    st.markdown(f"##### â‘  {label_col}ã‚’é¸æŠ ({mode_label}ãƒ™ãƒ¼ã‚¹)")

    st.caption(f"â€»{mode_label}ã®å¢—æ¸›é¡ãŒå¤§ãã„é † (è¨ˆç®—: BigQuery)")

    key_suffix = f"{ranking_type}_{axis_mode}_{mode_label}"

    event = st.dataframe(df_disp[cols], use_container_width=True, hide_index=True, column_config=create_default_column_config(df_disp), height=400, on_select="rerun", selection_mode="single-row", key=f"t1_{key_suffix}")

    if len(event.selection["rows"]) > 0:

        idx = event.selection["rows"][0]

        selected_val = df_disp.iloc[idx][label_col]

        st.divider()

        st.subheader(f"ğŸ” å†…è¨³åˆ†æ: {selected_val}")

        key_col = "product_name" if is_product else "customer_name"

        target_col = "customer_name" if is_product else "product_name"

        df_drill = fetch_drilldown_from_bq(client, key_col, selected_val, target_col, is_worst, is_sales_mode)

        if df_drill.empty: st.warning("è©³ç´°ãƒ‡ãƒ¼ã‚¿ãªã—")

        else:

            drill_label = "å¾—æ„å…ˆå" if is_product else "å•†å“å"

            if is_sales_mode: d_cols = [drill_label, "å£²ä¸Šå·®é¡", "ä»Šå¹´å£²ä¸Š", "å‰å¹´å£²ä¸Š", "ç²—åˆ©å·®é¡", "ä»Šå¹´ç²—åˆ©"]

            else: d_cols = [drill_label, "ç²—åˆ©å·®é¡", "ä»Šå¹´ç²—åˆ©", "å£²ä¸Šå·®é¡", "ä»Šå¹´å£²ä¸Š", "å‰å¹´å£²ä¸Š"]

            st.dataframe(df_drill[d_cols], use_container_width=True, hide_index=True, column_config=create_default_column_config(df_drill), key=f"t2_{key_suffix}")



def render_fytd_org_section(client, login_email):

    st.subheader("ğŸ¢ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå…¨ç¤¾")

    if st.button("å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_org_load", use_container_width=True):

        st.session_state.org_data_loaded = True

    if st.session_state.org_data_loaded:

        sql_kpi = f"SELECT * FROM `{VIEW_FYTD_ORG}` __WHERE__ LIMIT 100"

        df_org = run_scoped_query(client, sql_kpi, "viewer_email", login_email, allow_fallback=True)

        if not df_org.empty:

            row = df_org.iloc[0]

            s_cur, s_py, s_fc = get_safe_float(row,'sales_amount_fytd'), get_safe_float(row,'sales_amount_py_total'), get_safe_float(row,'sales_forecast_total')

            gp_cur, gp_py, gp_fc = get_safe_float(row,'gross_profit_fytd'), get_safe_float(row,'gross_profit_py_total'), get_safe_float(row,'gp_forecast_total')

            st.markdown("##### â–  å£²ä¸Š (Sales)")

            c1, c2, c3, c4 = st.columns(4); c1.metric("â‘  ç¾çŠ¶", f"Â¥{s_cur:,.0f}"); c2.metric("â‘¡ æ˜¨å¹´", f"Â¥{s_py:,.0f}"); c3.metric("â‘¢ äºˆæ¸¬", f"Â¥{s_fc:,.0f}"); c4.metric("â‘£ GAP", f"Â¥{s_fc - s_py:,.0f}", delta_color="off")

            st.markdown("##### â–  ç²—åˆ© (Gross Profit)")

            c5, c6, c7, c8 = st.columns(4); c5.metric("â‘  ç¾çŠ¶", f"Â¥{gp_cur:,.0f}"); c6.metric("â‘¡ æ˜¨å¹´", f"Â¥{gp_py:,.0f}"); c7.metric("â‘¢ äºˆæ¸¬", f"Â¥{gp_fc:,.0f}"); c8.metric("â‘£ GAP", f"Â¥{gp_fc - gp_py:,.0f}", delta_color="off")

            st.divider()

        st.subheader("ğŸ“Š å¢—æ¸›è¦å› åˆ†æ (å¤šæ¬¡å…ƒ)")

        c_axis, c_val = st.columns(2)

        with c_axis: axis_sel = st.radio("é›†è¨ˆè»¸:", ["ğŸ“¦ å•†å“è»¸", "ğŸ¥ å¾—æ„å…ˆè»¸"], horizontal=True); axis_mode = "product" if "å•†å“" in axis_sel else "customer"

        with c_val: val_sel = st.radio("è©•ä¾¡æŒ‡æ¨™:", ["ğŸ’° å£²ä¸Šé‡‘é¡", "ğŸ’¹ ç²—åˆ©é‡‘é¡"], horizontal=True); is_sales_mode = "å£²ä¸Š" in val_sel

        tab_worst, tab_best = st.tabs(["ğŸ“‰ ãƒ¯ãƒ¼ã‚¹ãƒˆ (æ¸›)", "ğŸ“ˆ ãƒ™ã‚¹ãƒˆ (å¢—)"])

        with tab_worst: render_interactive_ranking_matrix(client, "worst", axis_mode, is_sales_mode)

        with tab_best: render_interactive_ranking_matrix(client, "best", axis_mode, is_sales_mode)

    else: st.info("ğŸ‘† ä¸Šã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")



def render_fytd_me_section(client, login_email):

    st.subheader("ğŸ‘¤ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œè‡ªåˆ†")

    if st.button("è‡ªåˆ†ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_me", use_container_width=True):

        sql = f"SELECT * FROM `{VIEW_FYTD_ME}` __WHERE__ LIMIT 100"

        df_me = run_scoped_query(client, sql, "login_email", login_email)

        if df_me.empty: return

        df_disp = rename_columns_for_display(df_me, JP_COLS_FYTD)

        cols = list(df_disp.columns)

        if "æ‹…å½“è€…å" in cols: cols.remove("æ‹…å½“è€…å"); cols.insert(0, "æ‹…å½“è€…å")

        col_cfg = create_default_column_config(df_disp[cols])

        st.dataframe(df_disp[cols], use_container_width=True, hide_index=True, column_config=col_cfg)



def render_yoy_section(client, login_email, allow_fallback):

    st.subheader("ğŸ“Š å½“æœˆYoYï¼ˆå¾—æ„å…ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰")

    c1, c2, c3 = st.columns(3)

    def _show_table(title, view_name, key):

        if st.button(title, key=key, use_container_width=True):

            sql = f"SELECT * FROM `{view_name}` __WHERE__ LIMIT 200"

            df = run_scoped_query(client, sql, "login_email", login_email, allow_fallback)

            if not df.empty:

                df_disp = rename_columns_for_display(df, JP_COLS_YOY)

                st.dataframe(df_disp, use_container_width=True, hide_index=True)

    with c1: _show_table("YoY Top (ä¼¸ã³)", VIEW_YOY_TOP, "btn_top")

    with c2: _show_table("YoY Bottom (è½ã¡)", VIEW_YOY_BOTTOM, "btn_btm")

    with c3: _show_table("æ–°è¦/æ¯”è¼ƒä¸èƒ½", VIEW_YOY_UNCOMP, "btn_unc")



def render_customer_drilldown(client, login_email):

    st.subheader("ğŸ¯ å¾—æ„å…ˆåˆ¥ãƒ»æˆ¦ç•¥ææ¡ˆ")

    sql_cust = f"SELECT DISTINCT customer_code, customer_name FROM `{VIEW_FACT_DAILY}` WHERE login_email = @login_email ORDER BY customer_code"

    df_cust = query_df_safe(client, sql_cust, {"login_email": login_email}, "Cust List")

    if df_cust.empty: return

    cust_options = {row["customer_code"]: f"{row['customer_code']} : {row['customer_name']}" for _, row in df_cust.iterrows()}

    selected_code = st.selectbox("åˆ†æã™ã‚‹å¾—æ„å…ˆã‚’é¸æŠã—ã¦ãã ã•ã„", options=cust_options.keys(), format_func=lambda x: cust_options[x])

    if not selected_code: return

    st.divider()

    sql_rec = f"SELECT * FROM `{VIEW_RECOMMEND}` WHERE customer_code = @cust_code ORDER BY priority_rank ASC"

    df_rec = query_df_safe(client, sql_rec, {"cust_code": selected_code}, "Recommendation")

    c1, c2 = st.columns([1, 2])

    with c1:

        st.markdown("#### ğŸ¥ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«")

        strong = df_rec.iloc[0].get("strong_category", "-") if not df_rec.empty else "-"

        st.info(f"ä¸»åŠ›é ˜åŸŸ: **{strong}**")

    with c2:

        st.markdown("#### ğŸ’¡ AIææ¡ˆãƒªã‚¹ãƒˆ")

        if not df_rec.empty:

            disp_df = df_rec[["priority_rank", "recommend_product", "manufacturer", "market_scale"]].rename(columns={"priority_rank": "é †ä½", "recommend_product": "å•†å“", "manufacturer": "ãƒ¡ãƒ¼ã‚«ãƒ¼", "market_scale": "è¦æ¨¡"})

            st.dataframe(disp_df, use_container_width=True, hide_index=True)

    with st.expander("å‚è€ƒ: ç¾åœ¨ã®æ¡ç”¨å“ãƒªã‚¹ãƒˆã‚’è¦‹ã‚‹"):

        sql_adopted = f"SELECT m.product_name, SUM(t.sales_amount) as sales_fytd, SUM(t.gross_profit) as gp_fytd FROM `{VIEW_FACT_DAILY}` t LEFT JOIN `{PROJECT_DEFAULT}.{DATASET_DEFAULT}.vw_item_master_norm` m ON CAST(t.jan AS STRING) = CAST(m.jan_code AS STRING) WHERE t.customer_code = @cust_code AND t.fiscal_year = 2025 GROUP BY 1 ORDER BY 2 DESC LIMIT 100"

        df_adopted = query_df_safe(client, sql_adopted, {"cust_code": selected_code}, "Adopted List")

        renamed_df = df_adopted.rename(columns={"product_name": "å•†å“å", "sales_fytd": "å£²ä¸Š(FYTD)", "gp_fytd": "ç²—åˆ©(FYTD)"})

        st.dataframe(renamed_df, use_container_width=True, column_config=create_default_column_config(renamed_df))





# -----------------------------

# 6. Main - â˜…è¡¨ç¤ºåã¨é›»è©±ç•ªå·ã‚’è¿½åŠ 

# -----------------------------

def main():

    if 'org_data_loaded' not in st.session_state: st.session_state.org_data_loaded = False

    set_page()

    client, project_id, location, sa_json = setup_bigquery_client()

    _ = sidebar_controls()

    login_email = get_login_email_ui()

    st.divider()

    

    # â˜…æ¨©é™æƒ…å ±ã®è§£æ±ºï¼ˆsales_staff_masterã‚’å‚ç…§ï¼‰

    role = resolve_role(client, login_email)

    

    # â˜…è¡¨ç¤ºã‚’å°‘ã—ãƒªãƒƒãƒã«ä¿®æ­£ï¼ˆåå‰ã¨é›»è©±ç•ªå·ã‚’è¡¨ç¤ºï¼‰

    st.write(f"ğŸ‘¤ **æ‹…å½“:** {role.staff
