# app.py
# -*- coding: utf-8 -*-
"""
SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - OS v1.7.3 (UI Polish: Commas & Totals)

ã€æ›´æ–°å±¥æ­´ v1.7.3ã€‘
- [UI] å…¨ã¦ã®æ•°å€¤ãƒ†ãƒ¼ãƒ–ãƒ«ã«3æ¡ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼ˆÂ¥1,234,567ï¼‰ã‚’é©ç”¨
- [UI] YoYãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚„è©³ç´°åˆ†æãƒ†ãƒ¼ãƒ–ãƒ«ã®æœ€ä¸‹è¡Œã«ã€Œåˆè¨ˆï¼ˆTotalï¼‰ã€è¡Œã‚’è‡ªå‹•è¿½åŠ 
- [Logic] ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆå€¤ã®åˆè¨ˆè¡Œã¯èª¤è§£ã‚’æ‹›ããŸã‚ç©ºæ¬„ã«ã™ã‚‹å‡¦ç†ã‚’å®Ÿè£…
"""

from __future__ import annotations

import json
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st
from pandas.api.types import is_numeric_dtype

from google.cloud import bigquery
from google.oauth2 import service_account
from google.api_core.exceptions import BadRequest, GoogleAPICallError


# -----------------------------
# Configuration & Constants
# -----------------------------
APP_TITLE = "SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"
DEFAULT_LOCATION = "asia-northeast1"
CACHE_TTL_SEC = 300

PROJECT_DEFAULT = "salesdb-479915"
DATASET_DEFAULT = "sales_data"

# BigQuery Views (FQN)
VIEW_ROLE = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_dim_staff_role_dedup"
VIEW_FYTD_ORG = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_admin_org_fytd_summary_scoped"
VIEW_WORST_RANK = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_admin_product_yoy_worst_ranking"
VIEW_FYTD_ME = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_staff_fytd_summary_scoped"
VIEW_YOY_TOP = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_top_current_month_named"
VIEW_YOY_BOTTOM = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_bottom_current_month_named"
VIEW_YOY_UNCOMP = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_uncomparable_current_month_named"
VIEW_RECOMMEND = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_recommendation_engine"
VIEW_FACT_DAILY = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_login_jan_daily"


# -----------------------------
# Display Mappings
# -----------------------------
JP_COLS_FYTD = {
    "viewer_email": "é–²è¦§è€…ãƒ¡ãƒ¼ãƒ«",
    "login_email": "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«",
    "display_name": "æ‹…å½“è€…å",
    "role_tier": "ãƒ­ãƒ¼ãƒ«",
    "area_name": "ã‚¨ãƒªã‚¢",
    "current_month": "åŸºæº–æ—¥",
    "fy_start": "å¹´åº¦é–‹å§‹",
    "sales_amount_fytd": "å£²ä¸Šï¼ˆFYTDï¼‰",
    "gross_profit_fytd": "ç²—åˆ©ï¼ˆFYTDï¼‰",
    "gross_profit_rate_fytd": "ç²—åˆ©ç‡ï¼ˆFYTDï¼‰",
    "sales_amount_py_fytd": "å£²ä¸Šï¼ˆå‰å¹´FYTDï¼‰",
    "gross_profit_py_fytd": "ç²—åˆ©ï¼ˆå‰å¹´FYTDï¼‰",
    "sales_diff_fytd": "å‰å¹´å·®ï¼ˆå£²ä¸Šï¼‰",
    "gp_diff_fytd": "å‰å¹´å·®ï¼ˆç²—åˆ©ï¼‰",
    "sales_forecast_total": "å£²ä¸Šç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰",
    "pacing_rate": "å£²ä¸Šå¯¾å‰å¹´ãƒšãƒ¼ã‚¹",
    "sales_amount_py_total": "å‰å¹´å£²ä¸Šå®Ÿç¸¾ï¼ˆå¹´ï¼‰",
    "gp_forecast_total": "ç²—åˆ©ç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰",
    "gp_pacing_rate": "ç²—åˆ©å¯¾å‰å¹´ãƒšãƒ¼ã‚¹",
    "gross_profit_py_total": "å‰å¹´ç²—åˆ©å®Ÿç¸¾ï¼ˆå¹´ï¼‰",
}

JP_COLS_YOY = {
    "login_email": "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«",
    "display_name": "æ‹…å½“è€…å",
    "month": "å¯¾è±¡æœˆï¼ˆæœˆåˆï¼‰",
    "customer_code": "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰",
    "customer_name": "å¾—æ„å…ˆå",
    "sales_amount": "å£²ä¸Šï¼ˆå½“æœˆï¼‰",
    "gross_profit": "ç²—åˆ©ï¼ˆå½“æœˆï¼‰",
    "gross_profit_rate": "ç²—åˆ©ç‡ï¼ˆå½“æœˆï¼‰",
    "sales_amount_py": "å£²ä¸Šï¼ˆå‰å¹´åŒæœˆï¼‰",
    "gross_profit_py": "ç²—åˆ©ï¼ˆå‰å¹´åŒæœˆï¼‰",
    "gross_profit_rate_py": "ç²—åˆ©ç‡ï¼ˆå‰å¹´åŒæœˆï¼‰",
    "sales_diff_yoy": "å‰å¹´å·®ï¼ˆå£²ä¸Šï¼‰",
    "gp_diff_yoy": "å‰å¹´å·®ï¼ˆç²—åˆ©ï¼‰",
    "sales_yoy_rate": "å‰å¹´åŒæœˆæ¯”ï¼ˆå£²ä¸Šï¼‰",
    "gp_yoy_rate": "å‰å¹´åŒæœˆæ¯”ï¼ˆç²—åˆ©ï¼‰",
}


# -----------------------------
# Utility Functions
# -----------------------------
def rename_columns_for_display(df: pd.DataFrame, mapping: Dict[str, str]) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    cols = {c: mapping.get(c, c) for c in df.columns}
    return df.rename(columns=cols)

def append_total_row(df: pd.DataFrame, label_col: str = None) -> pd.DataFrame:
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ•°å€¤åˆ—ã‚’åˆè¨ˆã—ã€æœ€ä¸‹è¡Œã«ã€Œåˆè¨ˆã€è¡Œã‚’è¿½åŠ ã™ã‚‹é–¢æ•°
    """
    if df.empty:
        return df
        
    # æ•°å€¤ã‚«ãƒ©ãƒ ã‚’ç‰¹å®š
    num_cols = df.select_dtypes(include=['number']).columns
    
    # åˆè¨ˆã‚’è¨ˆç®—
    total_data = {}
    for col in df.columns:
        if col in num_cols:
            # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆç³»ã®åˆ—ï¼ˆç‡ã€æ¯”ã€ãƒšãƒ¼ã‚¹ï¼‰ã¯åˆè¨ˆã—ã¦ã‚‚æ„å‘³ãŒãªã„ã®ã§Noneã«ã™ã‚‹
            if any(k in col for k in ["ç‡", "æ¯”", "ãƒšãƒ¼ã‚¹", "rate", "pace"]):
                total_data[col] = None
            else:
                total_data[col] = df[col].sum()
        else:
            total_data[col] = "" # æ–‡å­—åˆ—ã‚«ãƒ©ãƒ ã¯ç©ºæ–‡å­—

    # åˆè¨ˆè¡Œã®ãƒ©ãƒ™ãƒ«è¨­å®š
    # æŒ‡å®šãŒãªã‘ã‚Œã°ã€ä¸€ç•ªå·¦ã®åˆ—ã«ã€Œåˆè¨ˆã€ã¨å…¥ã‚Œã‚‹
    target_label_col = label_col if label_col and label_col in df.columns else df.columns[0]
    total_data[target_label_col] = "=== åˆè¨ˆ ==="
    
    # è¡Œã‚’è¿½åŠ 
    df_total = pd.DataFrame([total_data])
    return pd.concat([df, df_total], ignore_index=True)

def get_column_config(df: pd.DataFrame) -> Dict[str, st.column_config.Column]:
    """
    ã‚«ãƒ©ãƒ åã«åŸºã¥ã„ã¦ã€Streamlitã®è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šç­‰ï¼‰ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹é–¢æ•°
    """
    config = {}
    for col in df.columns:
        # é‡‘é¡ãƒ»æ•°å€¤ç³» -> 3æ¡ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š (Â¥ãƒãƒ¼ã‚¯ä»˜ã)
        if any(k in col for k in ["å£²ä¸Š", "ç²—åˆ©", "é‡‘é¡", "å·®", "å®Ÿç¸¾", "äºˆæ¸¬", "GAP", "amount", "profit", "diff"]):
            config[col] = st.column_config.NumberColumn(
                col, format="Â¥%d"
            )
        # ç‡ãƒ»ãƒšãƒ¼ã‚¹ç³» -> ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨ç¤º
        elif any(k in col for k in ["ç‡", "æ¯”", "ãƒšãƒ¼ã‚¹", "rate", "pace"]):
            config[col] = st.column_config.NumberColumn(
                col, format="%.1f%%"
            )
        # ãã®ä»–æ•°å€¤
        elif is_numeric_dtype(df[col]):
            config[col] = st.column_config.NumberColumn(
                col, format="%d"
            )
        # ãƒ†ã‚­ã‚¹ãƒˆç³»
        else:
            config[col] = st.column_config.TextColumn(col)
            
    return config


# -----------------------------
# Role Management
# -----------------------------
@dataclass(frozen=True)
class RoleInfo:
    login_email: str
    role_key: str = "SALES"
    role_admin_view: bool = False
    role_admin_edit: bool = False
    role_sales_view: bool = True
    area_name: str = "æœªè¨­å®š"

def normalize_role_key(role_key: str) -> str:
    rk = (role_key or "").strip().upper()
    if rk in ("HQ_ADMIN", "AREA_MANAGER", "SALES"):
        return rk
    return "SALES"


# -----------------------------
# BigQuery Client & Auth
# -----------------------------
def _secrets_has_bigquery() -> bool:
    if "bigquery" not in st.secrets:
        return False
    bq = st.secrets.get("bigquery", {})
    return bool(bq.get("project_id")) and bool(bq.get("service_account"))

def _get_bq_from_secrets() -> Tuple[str, str, Dict[str, Any]]:
    bq = st.secrets["bigquery"]
    project_id = str(bq.get("project_id"))
    location = str(bq.get("location") or DEFAULT_LOCATION)
    sa = dict(bq.get("service_account"))
    return project_id, location, sa

def setup_bigquery_client() -> Tuple[bigquery.Client, str, str, str]:
    if not _secrets_has_bigquery():
        st.error("âŒ Secretsè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚")
        st.stop()
        
    project_id, location, sa = _get_bq_from_secrets()
    sa_json = json.dumps(sa)
    
    creds = service_account.Credentials.from_service_account_info(sa)
    client = bigquery.Client(project=project_id, credentials=creds, location=location)
    
    return client, project_id, location, sa_json


# -----------------------------
# Query Execution Helpers
# -----------------------------
def _build_query_parameters(params: Optional[Dict[str, Any]]) -> List[bigquery.ScalarQueryParameter]:
    qparams = []
    if not params:
        return qparams
    for k, v in params.items():
        if isinstance(v, bool):
            qparams.append(bigquery.ScalarQueryParameter(k, "BOOL", v))
        elif isinstance(v, int):
            qparams.append(bigquery.ScalarQueryParameter(k, "INT64", v))
        elif isinstance(v, float):
            qparams.append(bigquery.ScalarQueryParameter(k, "FLOAT64", v))
        elif v is None:
            qparams.append(bigquery.ScalarQueryParameter(k, "STRING", ""))
        else:
            qparams.append(bigquery.ScalarQueryParameter(k, "STRING", str(v)))
    return qparams

def _show_bq_error_context(title: str, sql: str, exc: Exception):
    st.error(f"Query Failed: {title}")
    st.write(f"Exception: {exc}")

@st.cache_data(show_spinner=False, ttl=CACHE_TTL_SEC)
def cached_query_df(
    project_id: str, location: str, sa_json: str, sql: str, params_json: str,
    use_bqstorage: bool, timeout_sec: int
) -> pd.DataFrame:
    sa = json.loads(sa_json)
    creds = service_account.Credentials.from_service_account_info(sa)
    client = bigquery.Client(project=project_id, credentials=creds, location=location)
    
    params = json.loads(params_json) if params_json else {}
    job_config = bigquery.QueryJobConfig()
    qparams = _build_query_parameters(params)
    if qparams:
        job_config.query_parameters = qparams
    job = client.query(sql, job_config=job_config)
    job.result(timeout=timeout_sec)
    return job.to_dataframe(create_bqstorage_client=use_bqstorage)

def query_df_safe(
    client: bigquery.Client, sql: str, params: Optional[Dict[str, Any]] = None,
    label: str = "", use_bqstorage: bool = True, timeout_sec: int = 60,
    cache_key: Optional[Tuple[str, str, str]] = None
) -> pd.DataFrame:
    params_json = json.dumps(params or {}, ensure_ascii=False, sort_keys=True)
    try:
        if cache_key:
            project_id, location, sa_json = cache_key
            return cached_query_df(
                project_id, location, sa_json, sql, params_json, use_bqstorage, timeout_sec
            )
        else:
            job_config = bigquery.QueryJobConfig()
            qparams = _build_query_parameters(params or {})
            if qparams:
                job_config.query_parameters = qparams
            job = client.query(sql, job_config=job_config)
            job.result(timeout=timeout_sec)
            return job.to_dataframe(create_bqstorage_client=use_bqstorage)
    except (BadRequest, GoogleAPICallError, Exception) as e:
        _show_bq_error_context(label, sql, e)
        return pd.DataFrame()


# -----------------------------
# Component: User Interface
# -----------------------------
def set_page():
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)
    st.caption("OS v1.7.3ï½œæˆ¦ç•¥ææ¡ˆï½œãƒ¯ãƒ¼ã‚¹ãƒˆåˆ†æï½œç€åœ°äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

def sidebar_controls() -> Dict[str, Any]:
    st.sidebar.header("System Settings")
    use_bqstorage = st.sidebar.toggle("Use Storage API (Fast)", value=True)
    timeout_sec = st.sidebar.slider("Query Timeout (sec)", 10, 300, 60, 10)
    show_sql = st.sidebar.toggle("Show SQL (Debug)", value=False)
    if st.sidebar.button("Clear Cache"):
        st.cache_data.clear()
        st.sidebar.success("Cache Cleared.")
    return {"use_bqstorage": use_bqstorage, "timeout_sec": timeout_sec, "show_sql": show_sql}

def get_login_email_ui() -> str:
    st.sidebar.header("Login Simulation")
    default_email = st.secrets.get("default_login_email", "") if "default_login_email" in st.secrets else ""
    login_email = st.sidebar.text_input("Login Email", value=default_email).strip()
    if not login_email:
        st.info("Please enter login email.")
        st.stop()
    return login_email

def resolve_role(client, cache_key, login_email, opts) -> RoleInfo:
    sql = f"""
    SELECT login_email, role_tier, role_admin_view, area_name
    FROM `{VIEW_ROLE}` WHERE login_email = @login_email LIMIT 1
    """
    df = query_df_safe(client, sql, {"login_email": login_email}, "Role Check",
                       opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    if df.empty:
        return RoleInfo(login_email=login_email)
    
    r = df.iloc[0]
    return RoleInfo(
        login_email=login_email,
        role_key=normalize_role_key(str(r.get("role_tier"))),
        role_admin_view=bool(r.get("role_admin_view")),
        area_name=str(r.get("area_name", "æœªè¨­å®š"))
    )

def run_scoped_query(client, cache_key, sql_template, scope_col, login_email, opts, allow_fallback=False):
    sql = sql_template.replace("__WHERE__", f"WHERE {scope_col} = @login_email")
    if opts["show_sql"]: st.code(sql, language="sql")
    df = query_df_safe(client, sql, {"login_email": login_email}, "Scoped Query",
                       opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    if not df.empty: return df

    if allow_fallback:
        sql_all = sql_template.replace("__WHERE__", f'WHERE {scope_col} = "all" OR {scope_col} IS NULL')
        if opts["show_sql"]: st.code(sql_all, language="sql")
        df_all = query_df_safe(client, sql_all, None, "Fallback Query",
                               opts["use_bqstorage"], opts["timeout_sec"], cache_key)
        return df_all
        
    return pd.DataFrame()


# -----------------------------
# Component: Render Sections
# -----------------------------

def render_fytd_org_section(client, cache_key, login_email, opts):
    """
    å…¨ç¤¾KPI + ãƒ¯ãƒ¼ã‚¹ãƒˆãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æ
    """
    st.subheader("ğŸ¢ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå…¨ç¤¾")
    
    if st.button("å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_org_load", use_container_width=True):
        st.session_state.org_data_loaded = True
    
    if st.session_state.org_data_loaded:
        
        # KPI Data Fetch
        sql_kpi = f"SELECT * FROM `{VIEW_FYTD_ORG}` __WHERE__ LIMIT 100"
        df_org = run_scoped_query(client, cache_key, sql_kpi, "viewer_email", login_email, opts, allow_fallback=True)
        
        if not df_org.empty:
            row = df_org.iloc[0]
            
            # --- å€¤ã®å–å¾— ---
            s_cur_fytd = float(row.get('sales_amount_fytd', 0))
            s_py_total = float(row.get('sales_amount_py_total', 0))
            s_forecast = float(row.get('sales_forecast_total', 0))
            s_gap = s_forecast - s_py_total
            
            gp_cur_fytd = float(row.get('gross_profit_fytd', 0))
            gp_py_total = float(row.get('gross_profit_py_total', 0))
            gp_forecast = float(row.get('gp_forecast_total', 0))
            gp_gap = gp_forecast - gp_py_total

            # --- KPIè¡¨ç¤º ---
            st.markdown("##### â–  å£²ä¸Š (Sales)")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("â‘  ç¾çŠ¶ (FYTD)", f"Â¥{s_cur_fytd:,.0f}")
            c2.metric("â‘¡ æ˜¨å¹´åº¦å®Ÿç¸¾ (é€šå¹´)", f"Â¥{s_py_total:,.0f}")
            c3.metric("â‘¢ ç€åœ°äºˆæ¸¬ (é€šå¹´)", f"Â¥{s_forecast:,.0f}", delta_color="normal")
            c4.metric("â‘£ GAP (äºˆæ¸¬ - æ˜¨å¹´)", f"Â¥{s_gap:,.0f}", delta=None, delta_color="off")

            st.markdown("##### â–  ç²—åˆ© (Gross Profit)")
            c5, c6, c7, c8 = st.columns(4)
            c5.metric("â‘  ç¾çŠ¶ (FYTD)", f"Â¥{gp_cur_fytd:,.0f}")
            c6.metric("â‘¡ æ˜¨å¹´åº¦å®Ÿç¸¾ (é€šå¹´)", f"Â¥{gp_py_total:,.0f}")
            c7.metric("â‘¢ ç€åœ°äºˆæ¸¬ (é€šå¹´)", f"Â¥{gp_forecast:,.0f}", delta_color="normal")
            c8.metric("â‘£ GAP (äºˆæ¸¬ - æ˜¨å¹´)", f"Â¥{gp_gap:,.0f}", delta=None, delta_color="off")
            
            st.divider()

        # --- Interactive Worst Ranking ---
        st.subheader("ğŸ“‰ æ¸›å°‘è¦å› åˆ†æ (ãƒ¯ãƒ¼ã‚¹ãƒˆãƒ©ãƒ³ã‚­ãƒ³ã‚°)")
        
        sql_rank = f"SELECT * FROM `{VIEW_WORST_RANK}` LIMIT 3000"
        df_raw = query_df_safe(client, sql_rank, None, "Worst Raw", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
        
        if df_raw.empty:
            st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        c_axis1, c_axis2 = st.columns(2)
        with c_axis1:
            axis_mode = st.radio("â‘  é›†è¨ˆè»¸:", ["ğŸ“¦ å•†å“è»¸", "ğŸ¥ å¾—æ„å…ˆè»¸"], horizontal=True, key="worst_axis_radio")
            is_product_mode = "å•†å“" in axis_mode
        with c_axis2:
            value_mode = st.radio("â‘¡ è©•ä¾¡æŒ‡æ¨™:", ["ğŸ’° å£²ä¸Šé‡‘é¡", "ğŸ’¹ ç²—åˆ©é‡‘é¡"], horizontal=True, key="worst_value_radio")
            is_sales_mode = "å£²ä¸Š" in value_mode

        if is_sales_mode:
            col_target = "sales_diff"
            col_cur = "sales_cur"
            col_prev = "sales_prev"
            label_diff = "å£²ä¸Šæ¸›å°‘é¡"
            label_cur = "ä»Šå¹´å£²ä¸Š"
            label_prev = "å‰å¹´å£²ä¸Š"
        else:
            col_target = "gp_diff"
            col_cur = "gp_cur"
            col_prev = "gp_prev"
            label_diff = "ç²—åˆ©æ¸›å°‘é¡"
            label_cur = "ä»Šå¹´ç²—åˆ©"
            label_prev = "å‰å¹´ç²—åˆ©"

        if st.session_state.worst_view_mode == 'ranking':
            target_key = "product_name" if is_product_mode else "customer_name"
            target_label = "å•†å“å" if is_product_mode else "å¾—æ„å…ˆå"
            
            st.markdown(f"**ãƒ¯ãƒ¼ã‚¹ãƒˆãƒ©ãƒ³ã‚­ãƒ³ã‚° ({label_diff}é †)**")
            
            df_group = df_raw.groupby(target_key)[[col_target, col_cur, col_prev]].sum().reset_index()
            df_group = df_group.sort_values(col_target, ascending=True)
            
            # åˆè¨ˆè¡Œã®è¿½åŠ 
            df_display = append_total_row(df_group, label_col=target_key)
            
            # è¡¨ç¤ºè¨­å®šã®è‡ªå‹•ç”Ÿæˆ
            col_cfg = get_column_config(df_display)
            # ç‰¹å®šåˆ—ã®ãƒ©ãƒ™ãƒ«ä¸Šæ›¸ã
            col_cfg[target_key].label = target_label
            col_cfg[col_target].label = label_diff
            col_cfg[col_cur].label = label_cur
            col_cfg[col_prev].label = label_prev
            
            st.dataframe(
                df_display[[target_key, col_target, col_cur, col_prev]], 
                column_config=col_cfg, 
                use_container_width=True, 
                hide_index=True, 
                height=400
            )

            st.divider()
            
            options_list = df_group[target_key].tolist()
            selected_item = st.selectbox(f"è©³ç´°åˆ†æã™ã‚‹å¯¾è±¡ã‚’é¸æŠ:", options_list, key="worst_selectbox")

            if st.button("è©³ç´°åˆ†æã¸ç§»å‹• â¡", type="primary"):
                st.session_state.worst_selected_name = selected_item
                st.session_state.worst_view_mode = 'detail'
                st.rerun()

        elif st.session_state.worst_view_mode == 'detail':
            target_name = st.session_state.worst_selected_name
            
            if st.button("â¬… ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«æˆ»ã‚‹"):
                st.session_state.worst_view_mode = 'ranking'
                st.session_state.worst_selected_name = None
                st.rerun()

            st.title(f"ğŸ” è©³ç´°åˆ†æ: {target_name}")
            st.caption(f"æŒ‡æ¨™: {label_diff}")
            
            if is_product_mode:
                df_detail = df_raw[df_raw["product_name"] == target_name].copy()
                main_col = "customer_name"
                col_label = "å¾—æ„å…ˆå"
            else:
                df_detail = df_raw[df_raw["customer_name"] == target_name].copy()
                main_col = "product_name"
                col_label = "å•†å“å"
            
            df_detail = df_detail.sort_values(col_target, ascending=True)
            
            # åˆè¨ˆè¡Œè¿½åŠ 
            df_display = append_total_row(df_detail, label_col=main_col)
            
            # è¨­å®šç”Ÿæˆ
            col_cfg = get_column_config(df_display)
            col_cfg[main_col].label = col_label
            col_cfg[col_target].label = label_diff
            col_cfg[col_cur].label = label_cur
            col_cfg[col_prev].label = label_prev

            st.dataframe(
                df_display[[main_col, col_target, col_cur, col_prev]],
                column_config=col_cfg,
                use_container_width=True,
                hide_index=True
            )
    else:
        st.info("ğŸ‘† ä¸Šã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")

def render_fytd_me_section(client, cache_key, login_email, opts):
    """
    ã‚¨ãƒªã‚¢/å€‹äºº KPI (ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºã‚’æ”¹å–„)
    """
    st.subheader("ğŸ‘¤ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œè‡ªåˆ†")
    if st.button("è‡ªåˆ†ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_me", use_container_width=True):
        sql = f"SELECT * FROM `{VIEW_FYTD_ME}` __WHERE__ LIMIT 100"
        df_me = run_scoped_query(client, cache_key, sql, "login_email", login_email, opts)
        
        if df_me.empty:
            st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        row = df_me.iloc[0]
        
        # --- å€¤ã®å–å¾— ---
        s_cur_fytd = float(row.get('sales_amount_fytd', 0))
        s_py_total = float(row.get('sales_amount_py_total', 0))
        s_forecast = float(row.get('sales_forecast_total', 0))
        s_gap = s_forecast - s_py_total
        
        gp_cur_fytd = float(row.get('gross_profit_fytd', 0))
        gp_py_total = float(row.get('gross_profit_py_total', 0))
        gp_forecast = float(row.get('gp_forecast_total', 0))
        gp_gap = gp_forecast - gp_py_total

        # --- KPIè¡¨ç¤º (2x4 Grid) ---
        st.markdown("##### â–  å£²ä¸Š (Sales)")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("â‘  ç¾çŠ¶ (FYTD)", f"Â¥{s_cur_fytd:,.0f}")
        c2.metric("â‘¡ æ˜¨å¹´åº¦å®Ÿç¸¾ (é€šå¹´)", f"Â¥{s_py_total:,.0f}")
        c3.metric("â‘¢ ç€åœ°äºˆæ¸¬ (é€šå¹´)", f"Â¥{s_forecast:,.0f}")
        c4.metric("â‘£ GAP (äºˆæ¸¬ - æ˜¨å¹´)", f"Â¥{s_gap:,.0f}", delta_color="off")

        st.markdown("##### â–  ç²—åˆ© (Gross Profit)")
        c5, c6, c7, c8 = st.columns(4)
        c5.metric("â‘  ç¾çŠ¶ (FYTD)", f"Â¥{gp_cur_fytd:,.0f}")
        c6.metric("â‘¡ æ˜¨å¹´åº¦å®Ÿç¸¾ (é€šå¹´)", f"Â¥{gp_py_total:,.0f}")
        c7.metric("â‘¢ ç€åœ°äºˆæ¸¬ (é€šå¹´)", f"Â¥{gp_forecast:,.0f}")
        c8.metric("â‘£ GAP (äºˆæ¸¬ - æ˜¨å¹´)", f"Â¥{gp_gap:,.0f}", delta_color="off")
        
        st.divider()
        
        # --- ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º (æ”¹å–„ç‰ˆ) ---
        df_disp = rename_columns_for_display(df_me, JP_COLS_FYTD)
        
        # åˆ—ã®ä¸¦ã³æ›¿ãˆ
        cols = list(df_disp.columns)
        if "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«" in cols: cols.remove("ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«")
        if "é–²è¦§è€…ãƒ¡ãƒ¼ãƒ«" in cols: cols.remove("é–²è¦§è€…ãƒ¡ãƒ¼ãƒ«")
        if "æ‹…å½“è€…å" in cols:
            cols.remove("æ‹…å½“è€…å")
            cols.insert(0, "æ‹…å½“è€…å")
        
        # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šé©ç”¨
        col_cfg = get_column_config(df_disp[cols])
        
        st.dataframe(
            df_disp[cols], 
            use_container_width=True, 
            hide_index=True, 
            column_config=col_cfg
        )

def render_yoy_section(client, cache_key, login_email, allow_fallback, opts):
    st.subheader("ğŸ“Š å½“æœˆYoYï¼ˆå¾—æ„å…ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰")
    c1, c2, c3 = st.columns(3)
    
    def _show_table(title, view_name, key):
        if st.button(title, key=key, use_container_width=True):
            sql = f"SELECT * FROM `{view_name}` __WHERE__ LIMIT 200"
            df = run_scoped_query(client, cache_key, sql, "login_email", login_email, opts, allow_fallback)
            if not df.empty:
                # --- ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º (æ”¹å–„ç‰ˆ) ---
                df_disp = rename_columns_for_display(df, JP_COLS_YOY)
                
                cols = list(df_disp.columns)
                if "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«" in cols: cols.remove("ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«")
                if "æ‹…å½“è€…å" in cols:
                    cols.remove("æ‹…å½“è€…å")
                    cols.insert(0, "æ‹…å½“è€…å")
                
                # åˆè¨ˆè¡Œã‚’è¿½åŠ 
                df_final = append_total_row(df_disp[cols], label_col="æ‹…å½“è€…å" if "æ‹…å½“è€…å" in cols else None)
                
                # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šé©ç”¨
                col_cfg = get_column_config(df_final)
                
                st.dataframe(
                    df_final, 
                    use_container_width=True, 
                    hide_index=True,
                    column_config=col_cfg
                )
            else:
                st.info("0ä»¶ã§ã™ã€‚")

    with c1: _show_table("YoY Top (ä¼¸ã³)", VIEW_YOY_TOP, "btn_top")
    with c2: _show_table("YoY Bottom (è½ã¡)", VIEW_YOY_BOTTOM, "btn_btm")
    with c3: _show_table("æ–°è¦/æ¯”è¼ƒä¸èƒ½", VIEW_YOY_UNCOMP, "btn_unc")

def render_customer_drilldown(client, cache_key, login_email, opts):
    st.subheader("ğŸ¯ å¾—æ„å…ˆåˆ¥ãƒ»æˆ¦ç•¥ææ¡ˆï¼ˆAI Gap Analysisï¼‰")
    
    sql_cust = f"""
    SELECT DISTINCT customer_code, customer_name
    FROM `{VIEW_FACT_DAILY}`
    WHERE login_email = @login_email
    ORDER BY customer_code
    """
    df_cust = query_df_safe(client, sql_cust, {"login_email": login_email}, "Cust List", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    
    if df_cust.empty:
        st.info("æ‹…å½“å¾—æ„å…ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆã¾ãŸã¯ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«ä¸ä¸€è‡´ï¼‰ã€‚")
        return

    cust_options = {row["customer_code"]: f"{row['customer_code']} : {row['customer_name']}" for _, row in df_cust.iterrows()}
    selected_code = st.selectbox("åˆ†æã™ã‚‹å¾—æ„å…ˆã‚’é¸æŠã—ã¦ãã ã•ã„", options=cust_options.keys(), format_func=lambda x: cust_options[x])
    
    if not selected_code:
        return

    st.divider()
    
    sql_rec = f"""
    SELECT * FROM `{VIEW_RECOMMEND}`
    WHERE customer_code = @cust_code
    ORDER BY priority_rank ASC
    """
    df_rec = query_df_safe(client, sql_rec, {"cust_code": selected_code}, "Recommendation", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    
    c1, c2 = st.columns([1, 2])
    
    with c1:
        st.markdown("#### ğŸ¥ å¾—æ„å…ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«")
        if not df_rec.empty:
            strong_cat = df_rec.iloc[0].get("strong_category", "-")
            st.info(f"ã“ã®å¾—æ„å…ˆã®ä¸»åŠ›é ˜åŸŸ(ãƒ¡ãƒ¼ã‚«ãƒ¼): **{strong_cat}**")
            st.caption("â€»è³¼å…¥å®Ÿç¸¾ã‚·ã‚§ã‚¢No.1ã®ãƒ¡ãƒ¼ã‚«ãƒ¼")
        else:
            st.warning("ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆã¾ãŸã¯ä¸»è¦å“å®Œç´æ¸ˆã¿ï¼‰")
            strong_cat = "(ä¸æ˜)"

    with c2:
        st.markdown("#### ğŸ’¡ AIææ¡ˆãƒªã‚¹ãƒˆï¼ˆæœªæ¡ç”¨ã®ãƒãƒ£ãƒ³ã‚¹å•†å“ï¼‰")
        st.caption(f"å…¨ç¤¾ã® **{strong_cat}** å£²ä¸ŠTOP10ã®ã†ã¡ã€**æœªæ¡ç”¨**ã®å•†å“")
        
        if df_rec.empty:
            st.success("ğŸ‰ ã“ã®é ˜åŸŸã®ä¸»è¦å•†å“ã¯ã™ã¹ã¦æ¡ç”¨æ¸ˆã¿ã§ã™ã€‚")
        else:
            disp_df = df_rec[[
                "priority_rank", "recommend_product", "manufacturer", "market_scale"
            ]].rename(columns={
                "priority_rank": "å„ªå…ˆé †ä½",
                "recommend_product": "æ¨å¥¨å•†å“å",
                "manufacturer": "ãƒ¡ãƒ¼ã‚«ãƒ¼",
                "market_scale": "å…¨ç¤¾å£²ä¸Šè¦æ¨¡"
            })
            
            # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé©ç”¨
            col_cfg = get_column_config(disp_df)
            
            st.dataframe(
                disp_df,
                use_container_width=True,
                hide_index=True,
                column_config=col_cfg
            )
            
    with st.expander("å‚è€ƒ: ç¾åœ¨ã®æ¡ç”¨å“ãƒªã‚¹ãƒˆã‚’è¦‹ã‚‹"):
        sql_adopted = f"""
        SELECT 
            m.product_name, 
            SUM(t.sales_amount) as sales_fytd
        FROM `{VIEW_FACT_DAILY}` t
        LEFT JOIN `{PROJECT_DEFAULT}.{DATASET_DEFAULT}.vw_item_master_norm` m 
            ON CAST(t.jan AS STRING) = CAST(m.jan_code AS STRING)
        WHERE t.customer_code = @cust_code
          AND t.fiscal_year = 2025
        GROUP BY 1
        ORDER BY 2 DESC
        LIMIT 100
        """
        df_adopted = query_df_safe(client, sql_adopted, {"cust_code": selected_code}, "Adopted List", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
        
        renamed_df = df_adopted.rename(columns={"product_name": "å•†å“å", "sales_fytd": "å£²ä¸Š(FYTD)"})
        col_cfg = get_column_config(renamed_df)
        
        st.dataframe(
            renamed_df,
            use_container_width=True,
            column_config=col_cfg
        )


# -----------------------------
# Main Execution
# -----------------------------
def main():
    # 0. Session State Initialization
    if 'worst_view_mode' not in st.session_state:
        st.session_state.worst_view_mode = 'ranking'
    if 'worst_selected_name' not in st.session_state:
        st.session_state.worst_selected_name = None
    if 'org_data_loaded' not in st.session_state:
        st.session_state.org_data_loaded = False

    set_page()
    
    # 1. Connection (Secrets Only)
    client, project_id, location, sa_json = setup_bigquery_client()
    cache_key = (project_id, location, sa_json)
    
    # 2. Controls
    opts = sidebar_controls()
    login_email = get_login_email_ui()
    
    st.divider()

    # 3. Role Check
    role = resolve_role(client, cache_key, login_email, opts)
    st.write(f"**Login:** {role.login_email} / **Role:** {role.role_key} ({role.area_name})")
    
    is_admin = role.role_key in ("HQ_ADMIN", "AREA_MANAGER")
    
    st.divider()
    
    # 4. Routing with Tabs
    if is_admin:
        t1, t2, t3 = st.tabs(["ğŸ¢ å…¨ç¤¾çŠ¶æ³", "ğŸ‘¤ ã‚¨ãƒªã‚¢/å€‹äºº", "ğŸ¯ æˆ¦ç•¥ææ¡ˆ(Beta)"])
        with t1: render_fytd_org_section(client, cache_key, login_email, opts)
        with t2:
            render_fytd_me_section(client, cache_key, login_email, opts)
            st.divider()
            render_yoy_section(client, cache_key, login_email, is_admin, opts)
        with t3:
            render_customer_drilldown(client, cache_key, login_email, opts)

    else:
        # Sales Role
        t1, t2, t3 = st.tabs(["ğŸ‘¤ ä»Šå¹´ã®æˆç¸¾", "ğŸ“Š å¾—æ„å…ˆåˆ†æ", "ğŸ¯ ææ¡ˆã‚’ä½œã‚‹"])
        with t1: render_fytd_me_section(client, cache_key, login_email, opts)
        with t2: render_yoy_section(client, cache_key, login_email, is_admin, opts)
        with t3: render_customer_drilldown(client, cache_key, login_email, opts)

    st.caption("Updated: v1.7.3 (Totals & Commas)")

if __name__ == "__main__":
    main()
