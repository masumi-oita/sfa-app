# ============================================================
# SFA Sales OS (å…¥å£) - app.py  ãƒ•ãƒ«ã‚³ãƒ¼ãƒ‰ï¼ˆãƒã‚§ãƒƒã‚¯æ©Ÿæ§‹å…¥ã‚Šï¼‰
# ------------------------------------------------------------
# ç›®çš„:
#  - ã€Œã©ã®SQLãŒé…ã„ã‹ã€ã‚’ç”»é¢ä¸Šã«å¯è¦–åŒ–ï¼ˆqueryæ™‚é–“ / dfè»¢é€æ™‚é–“ / bytes processedï¼‰
#  - BigQuery Storage API ã‚’ä½¿ãˆã‚‹å ´åˆã¯è‡ªå‹•åˆ©ç”¨ï¼ˆdfè»¢é€é«˜é€ŸåŒ–ï¼‰
#  - Streamlit rerun é€£ç™ºã§BQã‚’å©ã‹ãªã„ï¼ˆcache + form submitï¼‰
#  - ç®¡ç†è€…: FYTDæ§‹é€  â†’ FYTD MoM â†’ å½“æœˆYoY â†’ ãƒ‰ãƒªãƒ«
#  - è¡¨ç¤ºã¯æ—¥æœ¬èªã€æ‹…å½“è€…ã¯ emailâ†’æ°å
# ------------------------------------------------------------
# æ³¨æ„:
#  - requirements.txt ã«æ¨å¥¨: google-cloud-bigquery-storage>=2.24.0
#    ï¼ˆç„¡ãã¦ã‚‚å‹•ããŒé…ããªã‚Šã‚„ã™ã„ï¼‰
# ============================================================

from __future__ import annotations

import os
import re
import time
from dataclasses import dataclass
from typing import Any, Dict, Optional, Tuple, List

import pandas as pd
import streamlit as st
from google.cloud import bigquery

# ----------------------------
# åŸºæœ¬è¨­å®š
# ----------------------------
PROJECT_ID = os.getenv("BQ_PROJECT_ID", "salesdb-479915")
DATASET = os.getenv("BQ_DATASET", "sales_data")

# VIEW / TABLEï¼ˆã‚ãªãŸã®ç’°å¢ƒã«å­˜åœ¨ã—ã¦ã„ã‚‹å‰æï¼‰
V_SYS_MONTH = f"`{PROJECT_ID}.{DATASET}.v_sys_current_month`"

V_ADMIN_ORG_FYTD_SCOPED = f"`{PROJECT_ID}.{DATASET}.v_admin_org_fytd_summary_scoped`"
V_ADMIN_FYTD_MOM_TOP_SCOPED = f"`{PROJECT_ID}.{DATASET}.v_admin_customer_fytd_top_named_scoped`"
V_ADMIN_FYTD_MOM_BOTTOM_SCOPED = f"`{PROJECT_ID}.{DATASET}.v_admin_customer_fytd_bottom_named_scoped`"

V_YOY_TOP = f"`{PROJECT_ID}.{DATASET}.v_sales_customer_yoy_top_current_month`"
V_YOY_BOTTOM = f"`{PROJECT_ID}.{DATASET}.v_sales_customer_yoy_bottom_current_month`"
V_YOY_INVALID = f"`{PROJECT_ID}.{DATASET}.v_sales_customer_yoy_uncomparable_current_month`"

V_FACT = f"`{PROJECT_ID}.{DATASET}.v_sales_fact_login_jan_daily`"
V_STAFF_EMAIL_NAME = f"`{PROJECT_ID}.{DATASET}.v_staff_email_name`"
DIM_STAFF_ROLE = f"`{PROJECT_ID}.{DATASET}.dim_staff_role`"

# ----------------------------
# ãƒšãƒ¼ã‚¸è¨­å®š
# ----------------------------
st.set_page_config(page_title="SFA Sales OSï¼ˆå…¥å£ï¼‰", layout="wide")

# ----------------------------
# è¡¨ç¤ºè£œåŠ©
# ----------------------------
def yen(x: Any) -> str:
    try:
        if pd.isna(x):
            return ""
        return f"Â¥{int(round(float(x))):,}"
    except Exception:
        return ""


def pct(x: Any) -> str:
    try:
        if pd.isna(x):
            return ""
        return f"{float(x) * 100:.1f}%"
    except Exception:
        return ""


def safe_lower(s: Any) -> str:
    return str(s).strip().lower() if s is not None else ""


def parse_code_from_label(label: str) -> str:
    m = re.search(r"\((.+?)\)\s*$", label)
    return m.group(1) if m else label


# ----------------------------
# ãƒã‚§ãƒƒã‚¯/è¨ˆæ¸¬æ§‹é€ ä½“
# ----------------------------
@dataclass
class QueryPerf:
    name: str
    ok: bool
    query_sec: float
    df_sec: float
    total_sec: float
    bytes_gb: float
    rows: int
    job_id: str
    note: str


# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è¨ˆæ¸¬ãƒ­ã‚°ã‚’ä¿æŒ
if "perf_logs" not in st.session_state:
    st.session_state.perf_logs: List[QueryPerf] = []

if "cache_bust" not in st.session_state:
    st.session_state.cache_bust = 0  # æ‰‹å‹•ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ã—ãŸã„æ™‚ã«ä½¿ã†

# ----------------------------
# BigQuery Clientï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
# ----------------------------
@st.cache_resource
def get_bq_client() -> bigquery.Client:
    return bigquery.Client(project=PROJECT_ID)


# ----------------------------
# BigQuery â†’ DataFrameï¼ˆãƒã‚§ãƒƒã‚¯æ©Ÿæ§‹å…¥ã‚Šï¼‰
# ----------------------------
def _make_job_config(params: Optional[Dict[str, Any]]) -> bigquery.QueryJobConfig:
    qps = []
    if params:
        for k, v in params.items():
            # ã„ã£ãŸã‚“ STRING ã§çµ±ä¸€ï¼ˆå¿…è¦ãªã‚‰å‹ã‚’å¢—ã‚„ã™ï¼‰
            qps.append(bigquery.ScalarQueryParameter(k, "STRING", str(v)))
    return bigquery.QueryJobConfig(query_parameters=qps)


def _to_df(result, prefer_storage_api: bool) -> Tuple[pd.DataFrame, float, str]:
    """
    to_dataframe ã®æ™‚é–“ã¨ã€Storage API åˆ©ç”¨çŠ¶æ³ã®noteã‚’è¿”ã™
    """
    t1 = time.time()
    note = ""
    try:
        # Storage API ã‚’ä½¿ãˆã‚‹ã¨è»¢é€ãŒé€Ÿã„ï¼ˆbigquery-storage ãŒç„¡ã„ã¨ä¾‹å¤–ã«ãªã‚‹ã“ã¨ãŒã‚ã‚‹ï¼‰
        if prefer_storage_api:
            df = result.to_dataframe(create_bqstorage_client=True)
            note = "df:StorageAPI"
        else:
            df = result.to_dataframe()
            note = "df:REST"
    except Exception as e:
        # Storage API ãŒç„¡ã„ç­‰ã§è½ã¡ãŸã‚‰ REST ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        df = result.to_dataframe()
        note = f"df:fallback(REST) ({type(e).__name__})"
    t2 = time.time()
    return df, (t2 - t1), note


@st.cache_data(ttl=300, show_spinner=False)
def qdf_cached(
    sql: str,
    params: Optional[Dict[str, Any]],
    prefer_storage_api: bool,
    cache_bust: int,
) -> Tuple[pd.DataFrame, QueryPerf]:
    """
    cache_data å¯¾å¿œï¼ˆè¿”ã‚Šå€¤ã« DataFrame + è¨ˆæ¸¬çµæœã‚’å«ã‚ã‚‹ï¼‰
    """
    client = get_bq_client()
    t0 = time.time()

    job = client.query(sql, job_config=_make_job_config(params))
    try:
        result = job.result()  # ã“ã“ãŒé•·ã„ãªã‚‰ BQ è¨ˆç®—ãŒé‡ã„
        t_query_done = time.time()

        df, df_sec, df_note = _to_df(result, prefer_storage_api=prefer_storage_api)
        t_end = time.time()

        bytes_gb = float(job.total_bytes_processed or 0) / 1e9
        perf = QueryPerf(
            name="",
            ok=True,
            query_sec=(t_query_done - t0),
            df_sec=df_sec,
            total_sec=(t_end - t0),
            bytes_gb=bytes_gb,
            rows=int(df.shape[0]),
            job_id=str(job.job_id),
            note=df_note,
        )
        return df, perf
    except Exception as e:
        t_end = time.time()
        perf = QueryPerf(
            name="",
            ok=False,
            query_sec=0.0,
            df_sec=0.0,
            total_sec=(t_end - t0),
            bytes_gb=0.0,
            rows=0,
            job_id=str(getattr(job, "job_id", "")),
            note=f"ERROR: {type(e).__name__}: {e}",
        )
        return pd.DataFrame(), perf


def qdf(
    name: str,
    sql: str,
    params: Optional[Dict[str, Any]] = None,
    prefer_storage_api: bool = True,
    show_check: bool = True,
) -> pd.DataFrame:
    """
    ç”»é¢è¡¨ç¤ºç”¨ãƒ©ãƒƒãƒ‘: è¨ˆæ¸¬çµæœã‚’ session_state ã«ç©ã‚€ + å¿…è¦ãªã‚‰è¡¨ç¤º
    """
    df, perf = qdf_cached(
        sql=sql,
        params=params,
        prefer_storage_api=prefer_storage_api,
        cache_bust=st.session_state.cache_bust,
    )
    perf.name = name
    st.session_state.perf_logs.append(perf)

    if show_check:
        # ç”»é¢ã«è»½ãå‡ºã™ï¼ˆé‡ã„ã¨ãã®çŠ¯äººç‰¹å®šï¼‰
        if perf.ok:
            st.caption(
                f"âœ… [{perf.name}] "
                f"query={perf.query_sec:.1f}s / df={perf.df_sec:.1f}s / total={perf.total_sec:.1f}s "
                f"| bytes={perf.bytes_gb:.2f}GB | rows={perf.rows:,} | {perf.note}"
            )
        else:
            st.caption(f"âŒ [{perf.name}] {perf.note} (total={perf.total_sec:.1f}s)")
    return df


# ----------------------------
# æ¨©é™ãƒ»æ°åè§£æ±º
# ----------------------------
@st.cache_data(ttl=600, show_spinner=False)
def get_staff_name_norm(login_email: str) -> str:
    df = qdf_cached(
        sql=f"""
            SELECT staff_name_norm
            FROM {V_STAFF_EMAIL_NAME}
            WHERE LOWER(login_email)=@email
            LIMIT 1
        """,
        params={"email": login_email},
        prefer_storage_api=True,
        cache_bust=0,
    )[0]
    if df.empty:
        return login_email
    return str(df.iloc[0]["staff_name_norm"])


@st.cache_data(ttl=600, show_spinner=False)
def get_role_scope(login_email: str) -> Dict[str, Any]:
    df = qdf_cached(
        sql=f"""
            SELECT role_tier, area_name, scope_type
            FROM {DIM_STAFF_ROLE}
            WHERE LOWER(login_email)=@email
            LIMIT 1
        """,
        params={"email": login_email},
        prefer_storage_api=True,
        cache_bust=0,
    )[0]
    if df.empty:
        return {}
    return df.iloc[0].to_dict()


# ----------------------------
# UI: ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆãƒ­ã‚°ã‚¤ãƒ³/è¨­å®š/ãƒã‚§ãƒƒã‚¯ï¼‰
# ----------------------------
with st.sidebar:
    st.header("ãƒ­ã‚°ã‚¤ãƒ³")

    user_email = safe_lower(st.text_input("user_emailï¼ˆãƒ¡ãƒ¼ãƒ«ï¼‰", value=safe_lower(st.query_params.get("user_email", ""))))
    if user_email:
        st.query_params["user_email"] = user_email

    prefer_storage_api = st.toggle("é«˜é€Ÿè»¢é€ï¼ˆStorage APIï¼‰ã‚’è©¦ã™", value=True)
    show_checks = st.toggle("ãƒã‚§ãƒƒã‚¯è¡¨ç¤ºï¼ˆSQLè¨ˆæ¸¬ã‚’è¡¨ç¤ºï¼‰", value=True)

    col_a, col_b = st.columns(2)
    if col_a.button("è¨ˆæ¸¬ãƒ­ã‚°ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.perf_logs = []
    if col_b.button("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–"):
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã«å™›ã¾ã›ã¦å¼·åˆ¶å†å–å¾—
        st.session_state.cache_bust += 1
        st.session_state.perf_logs = []

    st.divider()
    st.caption("â€»5åˆ†ä»¥ä¸Šé…ã„å ´åˆã€ã“ã“ã‚’ONã«ã—ã¦ã€ã©ã®SQLãŒé…ã„ã‹ã€ã‚’ç‰¹å®šã—ã¾ã™ã€‚")

if not user_email:
    st.title("SFA Sales OSï¼ˆå…¥å£ï¼‰")
    st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ user_email ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ----------------------------
# ãƒ˜ãƒƒãƒ€ï¼ˆå¯¾è±¡æœˆ/æ°å/ãƒ­ãƒ¼ãƒ«ï¼‰
# ----------------------------
st.title("SFA Sales OSï¼ˆå…¥å£ï¼‰")

sys_df = qdf(
    name="sys_current_month",
    sql=f"SELECT * FROM {V_SYS_MONTH} LIMIT 1",
    params=None,
    prefer_storage_api=prefer_storage_api,
    show_check=show_checks,
)
current_month = str(sys_df.iloc[0]["current_month"]) if not sys_df.empty and "current_month" in sys_df.columns else "2026-01-01"

staff_name = get_staff_name_norm(user_email)
role = get_role_scope(user_email)

c1, c2, c3, c4 = st.columns(4)
c1.metric("Current month", current_month)
c2.metric("ãƒ­ã‚°ã‚¤ãƒ³", staff_name)
c3.metric("role_tier", role.get("role_tier", "-"))
c4.metric("area", role.get("area_name", "-"))

st.divider()

# ----------------------------
# ã‚¿ãƒ–æ§‹æˆ
# ----------------------------
tab_admin, tab_drill, tab_perf = st.tabs(["ç®¡ç†è€…å…¥å£ï¼ˆåˆ†æï¼‰", "ãƒ‰ãƒªãƒ«ï¼ˆæ˜ç´°ï¼‰", "è¨ˆæ¸¬ãƒ­ã‚°ï¼ˆé…ã„åŸå› ï¼‰"])

# ============================================================
# ç®¡ç†è€…å…¥å£ï¼ˆåˆ†æï¼‰
# ============================================================
with tab_admin:
    st.subheader("A) å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰")

    # FYTD çµ„ç¹”ã‚µãƒãƒªãƒ¼ï¼ˆscopedï¼‰
    org = qdf(
        name="admin_org_fytd_summary_scoped",
        sql=f"""
            SELECT
              sales_amount_fytd,
              gross_profit_fytd,
              gross_profit_rate_fytd
            FROM {V_ADMIN_ORG_FYTD_SCOPED}
            WHERE viewer_email=@email
            LIMIT 1
        """,
        params={"email": user_email},
        prefer_storage_api=prefer_storage_api,
        show_check=show_checks,
    )

    if org.empty:
        st.warning("FYTDã‚µãƒãƒªãƒ¼ãŒå–å¾—ã§ãã¾ã›ã‚“ï¼ˆscoped/role ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰")
    else:
        r = org.iloc[0]
        k1, k2, k3 = st.columns(3)
        k1.metric("FYTD å£²ä¸Š", yen(r.get("sales_amount_fytd")))
        k2.metric("FYTD ç²—åˆ©", yen(r.get("gross_profit_fytd")))
        k3.metric("FYTD ç²—åˆ©ç‡", pct(r.get("gross_profit_rate_fytd")))

    st.divider()
    st.subheader("B) FYTD MoMï¼ˆå‰æœˆå·®ï¼‰ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    left, right = st.columns(2)

    with left:
        st.markdown("### ğŸ“‰ ä¸‹è½ï¼ˆFYTD å‰æœˆå·®ï¼‰")
        bottom = qdf(
            name="admin_customer_fytd_bottom_named_scoped",
            sql=f"""
                SELECT
                  å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰,
                  å¾—æ„å…ˆå,
                  æ”¯åº—å,
                  sales_amount_fytd,
                  gross_profit_fytd,
                  sales_diff_mom,
                  gross_profit_diff_mom
                FROM {V_ADMIN_FYTD_MOM_BOTTOM_SCOPED}
                WHERE viewer_email=@email
                ORDER BY sales_diff_mom ASC
                LIMIT 50
            """,
            params={"email": user_email},
            prefer_storage_api=prefer_storage_api,
            show_check=show_checks,
        )

        if not bottom.empty:
            show = bottom.copy()
            # æ—¥æœ¬èªæ•´å½¢
            show.rename(columns={
                "sales_amount_fytd": "FYTDå£²ä¸Š",
                "gross_profit_fytd": "FYTDç²—åˆ©",
                "sales_diff_mom": "å‰æœˆå·®_å£²ä¸Š",
                "gross_profit_diff_mom": "å‰æœˆå·®_ç²—åˆ©",
            }, inplace=True)
            st.dataframe(show, use_container_width=True, height=520)
        else:
            st.info("ãƒ‡ãƒ¼ã‚¿ãªã—")

    with right:
        st.markdown("### ğŸ“ˆ ä¼¸é•·ï¼ˆFYTD å‰æœˆå·®ï¼‰")
        top = qdf(
            name="admin_customer_fytd_top_named_scoped",
            sql=f"""
                SELECT
                  å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰,
                  å¾—æ„å…ˆå,
                  æ”¯åº—å,
                  sales_amount_fytd,
                  gross_profit_fytd,
                  sales_diff_mom,
                  gross_profit_diff_mom
                FROM {V_ADMIN_FYTD_MOM_TOP_SCOPED}
                WHERE viewer_email=@email
                ORDER BY sales_diff_mom DESC
                LIMIT 50
            """,
            params={"email": user_email},
            prefer_storage_api=prefer_storage_api,
            show_check=show_checks,
        )

        if not top.empty:
            show = top.copy()
            show.rename(columns={
                "sales_amount_fytd": "FYTDå£²ä¸Š",
                "gross_profit_fytd": "FYTDç²—åˆ©",
                "sales_diff_mom": "å‰æœˆå·®_å£²ä¸Š",
                "gross_profit_diff_mom": "å‰æœˆå·®_ç²—åˆ©",
            }, inplace=True)
            st.dataframe(show, use_container_width=True, height=520)
        else:
            st.info("ãƒ‡ãƒ¼ã‚¿ãªã—")

    st.divider()
    st.subheader("C) å½“æœˆ YoYï¼ˆå‰å¹´æ¯”è¼ƒï¼‰")

    t1, t2, t3 = st.tabs(["ä¸‹è½ï¼ˆYoY validï¼‰", "ä¼¸é•·ï¼ˆYoY validï¼‰", "æ¯”è¼ƒä¸èƒ½ï¼ˆYoY invalidï¼‰"])

    with t1:
        yoy_bottom = qdf(
            name="sales_customer_yoy_bottom_current_month",
            sql=f"""
                SELECT * FROM {V_YOY_BOTTOM}
                WHERE login_email=@email
                LIMIT 200
            """,
            params={"email": user_email},
            prefer_storage_api=prefer_storage_api,
            show_check=show_checks,
        )
        st.dataframe(yoy_bottom, use_container_width=True, height=520)

    with t2:
        yoy_top = qdf(
            name="sales_customer_yoy_top_current_month",
            sql=f"""
                SELECT * FROM {V_YOY_TOP}
                WHERE login_email=@email
                LIMIT 200
            """,
            params={"email": user_email},
            prefer_storage_api=prefer_storage_api,
            show_check=show_checks,
        )
        st.dataframe(yoy_top, use_container_width=True, height=520)

    with t3:
        yoy_inv = qdf(
            name="sales_customer_yoy_uncomparable_current_month",
            sql=f"""
                SELECT * FROM {V_YOY_INVALID}
                WHERE login_email=@email
                LIMIT 200
            """,
            params={"email": user_email},
            prefer_storage_api=prefer_storage_api,
            show_check=show_checks,
        )
        st.dataframe(yoy_inv, use_container_width=True, height=520)

# ============================================================
# ãƒ‰ãƒªãƒ«ï¼ˆæ˜ç´°ï¼‰
#   â€» reruné€£ç™ºã‚’é¿ã‘ã‚‹ãŸã‚ form + submit æ–¹å¼
# ============================================================
with tab_drill:
    st.subheader("å¾—æ„å…ˆ â†’ å½“æœˆ æ—¥æ¬¡æ˜ç´°ï¼ˆJANç²’åº¦ï¼‰")

    with st.form("drill_form", clear_on_submit=False):
        kw = st.text_input("å¾—æ„å…ˆåï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", value="")
        limit_candidates = st.slider("å€™è£œä»¶æ•°", 10, 200, 50)
        run = st.form_submit_button("æ¤œç´¢ â†’ å€™è£œè¡¨ç¤º")

    if run and kw.strip():
        # å€™è£œæ¤œç´¢ã¯ã€Œå½“æœˆå›ºå®šã€ï¼‹ã€Œlogin_emailå›ºå®šã€ã§ã‚¹ã‚­ãƒ£ãƒ³ã‚’æ¸›ã‚‰ã™
        # ã•ã‚‰ã« DISTINCT ã®åˆ—ã‚‚æœ€å°é™ã«
        cand = qdf(
            name="drill_candidates",
            sql=f"""
                SELECT DISTINCT customer_code, customer_name
                FROM {V_FACT}
                WHERE login_email=@email
                  AND month=DATE(@m)
                  AND customer_name LIKE CONCAT('%', @kw, '%')
                LIMIT {int(limit_candidates)}
            """,
            params={"email": user_email, "m": current_month, "kw": kw.strip()},
            prefer_storage_api=prefer_storage_api,
            show_check=show_checks,
        )

        if cand.empty:
            st.info("å€™è£œãªã—")
        else:
            labels = cand.apply(lambda r: f"{r['customer_name']} ({r['customer_code']})", axis=1).tolist()
            pick = st.selectbox("å¾—æ„å…ˆé¸æŠ", labels)

            code = parse_code_from_label(pick)

            with st.form("detail_form", clear_on_submit=False):
                limit_rows = st.slider("è¡¨ç¤ºè¡Œæ•°", 100, 5000, 800)
                run_detail = st.form_submit_button("å½“æœˆã®æ˜ç´°ã‚’è¡¨ç¤º")

            if run_detail:
                detail = qdf(
                    name="drill_detail_daily",
                    sql=f"""
                        SELECT
                          sales_date AS æ—¥ä»˜,
                          item_name  AS å•†å“å,
                          pack_unit  AS åŒ…è£…,
                          jan        AS JAN,
                          yj_code    AS YJ,
                          quantity   AS æ•°é‡,
                          sales_amount AS å£²ä¸Š,
                          gross_profit AS ç²—åˆ©
                        FROM {V_FACT}
                        WHERE login_email=@email
                          AND customer_code=@code
                          AND month=DATE(@m)
                        ORDER BY sales_date DESC
                        LIMIT {int(limit_rows)}
                    """,
                    params={"email": user_email, "code": code, "m": current_month},
                    prefer_storage_api=prefer_storage_api,
                    show_check=show_checks,
                )
                st.dataframe(detail, use_container_width=True, height=640)

# ============================================================
# è¨ˆæ¸¬ãƒ­ã‚°ï¼ˆé…ã„åŸå› ã®ç‰¹å®šï¼‰
# ============================================================
with tab_perf:
    st.subheader("ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§å®Ÿè¡Œã•ã‚ŒãŸã‚¯ã‚¨ãƒªè¨ˆæ¸¬ãƒ­ã‚°")

    logs = st.session_state.perf_logs
    if not logs:
        st.info("ã¾ã è¨ˆæ¸¬ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å·¦ã§ã€Œãƒã‚§ãƒƒã‚¯è¡¨ç¤ºã€ã‚’ONã«ã—ã¦æ“ä½œã—ã¦ãã ã•ã„ã€‚")
    else:
        df_log = pd.DataFrame([{
            "name": x.name,
            "ok": x.ok,
            "query_sec": round(x.query_sec, 2),
            "df_sec": round(x.df_sec, 2),
            "total_sec": round(x.total_sec, 2),
            "bytes_gb": round(x.bytes_gb, 3),
            "rows": x.rows,
            "job_id": x.job_id,
            "note": x.note,
        } for x in logs])

        # é…ã„é †ã«ä¸¦ã¹ã‚‹
        df_log = df_log.sort_values(["total_sec", "bytes_gb"], ascending=[False, False])

        st.dataframe(df_log, use_container_width=True, height=520)

        st.markdown("### åˆ¤å®šã‚¬ã‚¤ãƒ‰ï¼ˆçŠ¯äººã®è¦‹åˆ†ã‘æ–¹ï¼‰")
        st.write(
            "- **query_sec ãŒé•·ã„** â†’ BigQueryå´ï¼ˆVIEWã®JOIN/é›†è¨ˆ/ã‚¹ã‚­ãƒ£ãƒ³ï¼‰ãŒé‡ã„\n"
            "- **df_sec ãŒé•·ã„** â†’ è»¢é€ãŒé‡ã„ï¼ˆStorage APIæœªä½¿ç”¨ã®å¯èƒ½æ€§å¤§ / çµæœãŒå¤§ãã™ãã‚‹ï¼‰\n"
            "- **bytes_gb ãŒå¤§ãã„** â†’ SELECT * / monthå›ºå®šãªã— / ä¸è¦åˆ— / ä¸è¦JOIN ã®å¯èƒ½æ€§\n"
            "- **åŒã˜nameãŒä½•åº¦ã‚‚å‡ºã‚‹** â†’ rerunã§åŒã˜ã‚¯ã‚¨ãƒªã‚’é€£ç™ºï¼ˆformåŒ–/ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¦‹ç›´ã—ï¼‰"
        )
        st.markdown("### ã™ãåŠ¹ãæ”¹å–„ï¼ˆå„ªå…ˆé †ï¼‰")
        st.write(
            "1) requirements.txt ã« `google-cloud-bigquery-storage` ã‚’è¿½åŠ ã—ã¦ dfè»¢é€é«˜é€ŸåŒ–\n"
            "2) `SELECT *` ã‚’ã‚„ã‚ã¦å¿…è¦åˆ—ã ã‘\n"
            "3) ãƒ‰ãƒªãƒ«å€™è£œã¯ month/login_email ã§å¿…ãšçµã‚‹ï¼ˆã“ã®ã‚³ãƒ¼ãƒ‰ã¯å¯¾å¿œæ¸ˆã¿ï¼‰\n"
            "4) ç®¡ç†è€…ãƒ©ãƒ³ã‚­ãƒ³ã‚°/ã‚µãƒãƒªãƒ¼ã¯ materializeï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«åŒ–ï¼‰ã—ã¦è–„ã„VIEWã‚’å©ã"
        )
