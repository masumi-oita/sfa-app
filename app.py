# app.py
# -*- coding: utf-8 -*-
"""
SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - OS v1.9.3 (Drill-Down Update)

ã€æ›´æ–°å±¥æ­´ v1.9.3ã€‘
- [New] å•†å“ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‹ã‚‰ã®3æ®µéšãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³åˆ†ææ©Ÿèƒ½ã‚’å®Ÿè£…
  (ãƒ©ãƒ³ã‚­ãƒ³ã‚° -> å¾—æ„å…ˆåˆ¥å¢—æ¸› -> å¾—æ„å…ˆåˆ¥å•†å“æ§‹æˆ)
- [Update] å…¨ç¤¾çŠ¶æ³ã‚¿ãƒ–ã®UIã‚’æ•´ç†ã—ã€åˆ†ææ©Ÿèƒ½ã‚’å¼·åŒ–
"""

from __future__ import annotations

import json
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st
from pandas.api.types import is_numeric_dtype

from google.cloud import bigquery
from google.oauth2 import service_account


# -----------------------------
# 1. Configuration & Constants
# -----------------------------
APP_TITLE = "SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"
DEFAULT_LOCATION = "asia-northeast1"
CACHE_TTL_SEC = 300

# â˜…QRã‚³ãƒ¼ãƒ‰ã®é£›ã³å…ˆ
APP_URL = "https://sfa-premium-app-2.streamlit.app/"

PROJECT_DEFAULT = "salesdb-479915"
DATASET_DEFAULT = "sales_data"

# BigQuery Views (FQN)
VIEW_ROLE = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_dim_staff_role_dedup"
VIEW_FYTD_ORG = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_admin_org_fytd_summary_scoped"
VIEW_WORST_RANK = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_admin_product_yoy_worst_ranking"
VIEW_BEST_RANK = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_admin_product_yoy_best_ranking"
VIEW_FYTD_ME = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_staff_fytd_summary_scoped"
VIEW_YOY_TOP = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_top_current_month_named"
VIEW_YOY_BOTTOM = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_bottom_current_month_named"
VIEW_YOY_UNCOMP = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_uncomparable_current_month_named"
VIEW_RECOMMEND = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_recommendation_engine"
VIEW_FACT_DAILY = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_login_jan_daily"
# â˜…Drill-downç”¨ (Raw Fact View)
VIEW_UNIFIED = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_unified"


# -----------------------------
# 2. Display Mappings
# -----------------------------
JP_COLS_FYTD = {
    "viewer_email": "é–²è¦§è€…ãƒ¡ãƒ¼ãƒ«",
    "login_email": "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«",
    "display_name": "æ‹…å½“è€…å",
    "role_tier": "ãƒ­ãƒ¼ãƒ«",
    "area_name": "ã‚¨ãƒªã‚¢",
    "current_month": "åŸºæº–æ—¥",
    "fy_start": "å¹´åº¦é–‹å§‹",
    "sales_amount_fytd": "å£²ä¸Šï¼ˆFYTDï¼‰",
    "gross_profit_fytd": "ç²—åˆ©ï¼ˆFYTDï¼‰",
    "gross_profit_rate_fytd": "ç²—åˆ©ç‡ï¼ˆFYTDï¼‰",
    "sales_amount_py_fytd": "å£²ä¸Šï¼ˆå‰å¹´FYTDï¼‰",
    "gross_profit_py_fytd": "ç²—åˆ©ï¼ˆå‰å¹´FYTDï¼‰",
    "sales_diff_fytd": "å‰å¹´å·®ï¼ˆå£²ä¸Šï¼‰",
    "gp_diff_fytd": "å‰å¹´å·®ï¼ˆç²—åˆ©ï¼‰",
    "sales_forecast_total": "å£²ä¸Šç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰",
    "pacing_rate": "å£²ä¸Šå¯¾å‰å¹´ãƒšãƒ¼ã‚¹",
    "sales_amount_py_total": "å‰å¹´å£²ä¸Šå®Ÿç¸¾ï¼ˆå¹´ï¼‰",
    "gp_forecast_total": "ç²—åˆ©ç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰",
    "gp_pacing_rate": "ç²—åˆ©å¯¾å‰å¹´ãƒšãƒ¼ã‚¹",
    "gross_profit_py_total": "å‰å¹´ç²—åˆ©å®Ÿç¸¾ï¼ˆå¹´ï¼‰",
}

JP_COLS_YOY = {
    "login_email": "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«",
    "display_name": "æ‹…å½“è€…å",
    "month": "å¯¾è±¡æœˆï¼ˆæœˆåˆï¼‰",
    "customer_code": "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰",
    "customer_name": "å¾—æ„å…ˆå",
    "sales_amount": "å£²ä¸Šï¼ˆå½“æœˆï¼‰",
    "gross_profit": "ç²—åˆ©ï¼ˆå½“æœˆï¼‰",
    "gross_profit_rate": "ç²—åˆ©ç‡ï¼ˆå½“æœˆï¼‰",
    "sales_amount_py": "å£²ä¸Šï¼ˆå‰å¹´åŒæœˆï¼‰",
    "gross_profit_py": "ç²—åˆ©ï¼ˆå‰å¹´åŒæœˆï¼‰",
    "gross_profit_rate_py": "ç²—åˆ©ç‡ï¼ˆå‰å¹´åŒæœˆï¼‰",
    "sales_diff_yoy": "å‰å¹´å·®ï¼ˆå£²ä¸Šï¼‰",
    "gp_diff_yoy": "å‰å¹´å·®ï¼ˆç²—åˆ©ï¼‰",
    "sales_yoy_rate": "å‰å¹´åŒæœˆæ¯”ï¼ˆå£²ä¸Šï¼‰",
    "gp_yoy_rate": "å‰å¹´åŒæœˆæ¯”ï¼ˆç²—åˆ©ï¼‰",
}


# -----------------------------
# 3. Helper Functions
# -----------------------------
def set_page():
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)
    st.caption("OS v1.9.3 (Drill-Down Update)ï½œæˆ¦ç•¥ææ¡ˆï½œ3æ®µéšãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³åˆ†æï½œç€åœ°äºˆæ¸¬")

def get_qr_code_url(url: str) -> str:
    return f"https://api.qrserver.com/v1/create-qr-code/?size=150x150&data={url}"

def rename_columns_for_display(df: pd.DataFrame, mapping: Dict[str, str]) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    cols = {c: mapping.get(c, c) for c in df.columns}
    return df.rename(columns=cols)

def append_total_row(df: pd.DataFrame, label_col: str = None) -> pd.DataFrame:
    if df.empty: return df
    num_cols = df.select_dtypes(include=['number']).columns
    total_data = {}
    for col in df.columns:
        if col in num_cols:
            if any(k in col for k in ["ç‡", "æ¯”", "ãƒšãƒ¼ã‚¹", "rate", "pace"]):
                total_data[col] = None
            else:
                total_data[col] = df[col].sum()
        else:
            total_data[col] = ""
    target_label = label_col if label_col and label_col in df.columns else df.columns[0]
    total_data[target_label] = "=== åˆè¨ˆ ==="
    return pd.concat([df, pd.DataFrame([total_data])], ignore_index=True)

def create_default_column_config(df: pd.DataFrame) -> Dict[str, st.column_config.Column]:
    config = {}
    for col in df.columns:
        if any(k in col for k in ["å£²ä¸Š", "ç²—åˆ©", "é‡‘é¡", "å·®", "å®Ÿç¸¾", "äºˆæ¸¬", "GAP", "amount", "profit", "diff", "cur", "prev"]):
            config[col] = st.column_config.NumberColumn(col, format="Â¥%d")
        elif any(k in col for k in ["ç‡", "æ¯”", "ãƒšãƒ¼ã‚¹", "rate", "pace"]):
            config[col] = st.column_config.NumberColumn(col, format="%.1f%%")
        elif is_numeric_dtype(df[col]):
            config[col] = st.column_config.NumberColumn(col, format="%d")
        else:
            config[col] = st.column_config.TextColumn(col)
    return config

def get_safe_float(row: pd.Series, key: str) -> float:
    val = row.get(key)
    if pd.isna(val):
        return 0.0
    return float(val)


# -----------------------------
# 4. Role & Auth
# -----------------------------
@dataclass(frozen=True)
class RoleInfo:
    login_email: str
    role_key: str = "SALES"
    role_admin_view: bool = False
    role_admin_edit: bool = False
    role_sales_view: bool = True
    area_name: str = "æœªè¨­å®š"

def normalize_role_key(role_key: str) -> str:
    rk = (role_key or "").strip().upper()
    if rk in ("HQ_ADMIN", "AREA_MANAGER", "SALES"):
        return rk
    return "SALES"

def _secrets_has_bigquery() -> bool:
    if "bigquery" not in st.secrets: return False
    bq = st.secrets.get("bigquery", {})
    return bool(bq.get("project_id")) and bool(bq.get("service_account"))

def _get_bq_from_secrets() -> Tuple[str, str, Dict[str, Any]]:
    bq = st.secrets["bigquery"]
    return str(bq.get("project_id")), str(bq.get("location") or DEFAULT_LOCATION), dict(bq.get("service_account"))

def setup_bigquery_client() -> Tuple[bigquery.Client, str, str, str]:
    if not _secrets_has_bigquery():
        st.error("âŒ Secretsè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()
    project_id, location, sa = _get_bq_from_secrets()
    sa_json = json.dumps(sa)
    creds = service_account.Credentials.from_service_account_info(sa)
    client = bigquery.Client(project=project_id, credentials=creds, location=location)
    return client, project_id, location, sa_json


# -----------------------------
# 5. Query Execution
# -----------------------------
def _build_query_parameters(params: Optional[Dict[str, Any]]) -> List[bigquery.ScalarQueryParameter]:
    qparams = []
    if not params: return qparams
    for k, v in params.items():
        if isinstance(v, bool): qparams.append(bigquery.ScalarQueryParameter(k, "BOOL", v))
        elif isinstance(v, int): qparams.append(bigquery.ScalarQueryParameter(k, "INT64", v))
        elif isinstance(v, float): qparams.append(bigquery.ScalarQueryParameter(k, "FLOAT64", v))
        elif v is None: qparams.append(bigquery.ScalarQueryParameter(k, "STRING", ""))
        else: qparams.append(bigquery.ScalarQueryParameter(k, "STRING", str(v)))
    return qparams

@st.cache_data(show_spinner=False, ttl=CACHE_TTL_SEC)
def cached_query_df(project_id: str, location: str, sa_json: str, sql: str, params_json: str, use_bqstorage: bool, timeout_sec: int) -> pd.DataFrame:
    sa = json.loads(sa_json)
    creds = service_account.Credentials.from_service_account_info(sa)
    client = bigquery.Client(project=project_id, credentials=creds, location=location)
    params = json.loads(params_json) if params_json else {}
    job_config = bigquery.QueryJobConfig()
    qparams = _build_query_parameters(params)
    if qparams: job_config.query_parameters = qparams
    job = client.query(sql, job_config=job_config)
    job.result(timeout=timeout_sec)
    return job.to_dataframe(create_bqstorage_client=use_bqstorage)

def query_df_safe(client: bigquery.Client, sql: str, params: Optional[Dict[str, Any]] = None, label: str = "", use_bqstorage: bool = True, timeout_sec: int = 60, cache_key: Optional[Tuple[str, str, str]] = None) -> pd.DataFrame:
    params_json = json.dumps(params or {}, ensure_ascii=False, sort_keys=True)
    try:
        if cache_key:
            project_id, location, sa_json = cache_key
            return cached_query_df(project_id, location, sa_json, sql, params_json, use_bqstorage, timeout_sec)
        else:
            job_config = bigquery.QueryJobConfig()
            qparams = _build_query_parameters(params or {})
            if qparams: job_config.query_parameters = qparams
            job = client.query(sql, job_config=job_config)
            job.result(timeout=timeout_sec)
            return job.to_dataframe(create_bqstorage_client=use_bqstorage)
    except Exception as e:
        st.error(f"Query Failed: {label}\n{e}")
        return pd.DataFrame()

def resolve_role(client, cache_key, login_email, opts) -> RoleInfo:
    sql = f"SELECT login_email, role_tier, role_admin_view, area_name FROM `{VIEW_ROLE}` WHERE login_email = @login_email LIMIT 1"
    df = query_df_safe(client, sql, {"login_email": login_email}, "Role Check", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    if df.empty: return RoleInfo(login_email=login_email)
    r = df.iloc[0]
    return RoleInfo(login_email=login_email, role_key=normalize_role_key(str(r.get("role_tier"))), role_admin_view=bool(r.get("role_admin_view")), area_name=str(r.get("area_name", "æœªè¨­å®š")))

def run_scoped_query(client, cache_key, sql_template, scope_col, login_email, opts, allow_fallback=False):
    sql = sql_template.replace("__WHERE__", f"WHERE {scope_col} = @login_email")
    if opts["show_sql"]: st.code(sql, language="sql")
    df = query_df_safe(client, sql, {"login_email": login_email}, "Scoped Query", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    if not df.empty: return df
    if allow_fallback:
        sql_all = sql_template.replace("__WHERE__", f'WHERE {scope_col} = "all" OR {scope_col} IS NULL')
        if opts["show_sql"]: st.code(sql_all, language="sql")
        return query_df_safe(client, sql_all, None, "Fallback Query", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    return pd.DataFrame()

# --- Drill-Down Queries ---
def get_product_drilldown(client, cache_key, product_name: str, is_worst: bool, opts) -> pd.DataFrame:
    """å•†å“ -> å¾—æ„å…ˆåˆ¥å¢—æ¸›å†…è¨³"""
    sort_order = "ASC" if is_worst else "DESC"
    sql = f"""
        SELECT 
            customer_name AS `å¾—æ„å…ˆå`,
            SUM(CASE WHEN fiscal_year = 2025 THEN sales_amount ELSE 0 END) as `ä»Šå¹´å£²ä¸Š`,
            SUM(CASE WHEN fiscal_year = 2024 THEN sales_amount ELSE 0 END) as `å‰å¹´å£²ä¸Š`,
            SUM(CASE WHEN fiscal_year = 2025 THEN sales_amount ELSE 0 END) - 
            SUM(CASE WHEN fiscal_year = 2024 THEN sales_amount ELSE 0 END) as `å£²ä¸Šå·®é¡`,
            SUM(CASE WHEN fiscal_year = 2025 THEN gross_profit ELSE 0 END) as `ä»Šå¹´ç²—åˆ©`,
            SUM(CASE WHEN fiscal_year = 2025 THEN gross_profit ELSE 0 END) - 
            SUM(CASE WHEN fiscal_year = 2024 THEN gross_profit ELSE 0 END) as `ç²—åˆ©å·®é¡`
        FROM `{VIEW_UNIFIED}`
        WHERE product_name = @product_name
        GROUP BY 1
        ORDER BY `å£²ä¸Šå·®é¡` {sort_order}
        LIMIT 500
    """
    return query_df_safe(client, sql, {"product_name": product_name}, "Drill: Product->Cust", opts["use_bqstorage"], opts["timeout_sec"], cache_key)

def get_customer_portfolio(client, cache_key, customer_name: str, opts) -> pd.DataFrame:
    """å¾—æ„å…ˆ -> å•†å“æ§‹æˆ"""
    sql = f"""
        SELECT 
            product_name AS `å•†å“å`,
            SUM(CASE WHEN fiscal_year = 2025 THEN sales_amount ELSE 0 END) as `ä»Šå¹´å£²ä¸Š`,
            SUM(CASE WHEN fiscal_year = 2025 THEN sales_amount ELSE 0 END) - 
            SUM(CASE WHEN fiscal_year = 2024 THEN sales_amount ELSE 0 END) as `å£²ä¸Šå·®é¡`,
            SUM(CASE WHEN fiscal_year = 2025 THEN gross_profit ELSE 0 END) as `ä»Šå¹´ç²—åˆ©`
        FROM `{VIEW_UNIFIED}`
        WHERE customer_name = @customer_name
        GROUP BY 1
        ORDER BY `ä»Šå¹´å£²ä¸Š` DESC
        LIMIT 500
    """
    return query_df_safe(client, sql, {"customer_name": customer_name}, "Drill: Cust->Portfolio", opts["use_bqstorage"], opts["timeout_sec"], cache_key)


# -----------------------------
# 6. Sidebar
# -----------------------------
def sidebar_controls() -> Dict[str, Any]:
    qr_url = get_qr_code_url(APP_URL)
    st.sidebar.image(qr_url, caption="ğŸ“±ã‚¹ãƒãƒ›ã§ã‚¢ã‚¯ã‚»ã‚¹", width=150)
    st.sidebar.divider()
    st.sidebar.header("System Settings")
    use_bqstorage = st.sidebar.toggle("Use Storage API (Fast)", value=True)
    timeout_sec = st.sidebar.slider("Query Timeout (sec)", 10, 300, 60, 10)
    show_sql = st.sidebar.toggle("Show SQL (Debug)", value=False)
    if st.sidebar.button("Clear Cache"):
        st.cache_data.clear()
        st.sidebar.success("Cache Cleared.")
    return {"use_bqstorage": use_bqstorage, "timeout_sec": timeout_sec, "show_sql": show_sql}

def get_login_email_ui() -> str:
    st.sidebar.header("Login Simulation")
    default_email = st.secrets.get("default_login_email", "") if "default_login_email" in st.secrets else ""
    login_email = st.sidebar.text_input("Login Email", value=default_email).strip()
    if not login_email: st.stop()
    return login_email


# -----------------------------
# 7. Render Functions
# -----------------------------

def render_interactive_ranking_flow(client, cache_key, ranking_type: str, opts):
    """3æ®µéšãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³æ©Ÿèƒ½ä»˜ããƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º (Worst/Bestå…±é€š)"""
    is_worst = (ranking_type == "worst")
    view_name = VIEW_WORST_RANK if is_worst else VIEW_BEST_RANK
    
    # Session State keys for this specific tab
    key_prefix = f"drill_{ranking_type}"
    
    # 1. ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å–å¾— (SQL Viewã§ãƒã‚¤ã‚ºé™¤å»ãƒ»ã‚½ãƒ¼ãƒˆæ¸ˆã¿)
    sql_rank = f"SELECT * FROM `{view_name}` LIMIT 1000"
    df_rank = query_df_safe(client, sql_rank, None, f"Ranking {ranking_type}", opts["use_bqstorage"], opts["timeout_sec"], cache_key)

    if df_rank.empty:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # è¡¨ç¤ºç”¨ã‚«ãƒ©ãƒ èª¿æ•´
    df_disp = df_rank.rename(columns={
        "product_name": "å•†å“å",
        "sales_cur": "ä»Šå¹´å£²ä¸Š",
        "sales_prev": "å‰å¹´å£²ä¸Š",
        "sales_diff": "å£²ä¸Šå·®é¡",
        "gp_cur": "ä»Šå¹´ç²—åˆ©",
        "gp_diff": "ç²—åˆ©å·®é¡"
    })
    
    # ã‚«ãƒ©ãƒ é †åº
    cols = ["å•†å“å", "å£²ä¸Šå·®é¡", "ä»Šå¹´å£²ä¸Š", "å‰å¹´å£²ä¸Š", "ç²—åˆ©å·®é¡", "ä»Šå¹´ç²—åˆ©"]
    
    st.markdown("##### â‘  å•†å“ã‚’é¸æŠã—ã¦ãã ã•ã„ (ã‚¯ãƒªãƒƒã‚¯ã§è©³ç´°åˆ†æ)")
    st.caption("â€»é€æ–™ãƒ»å€¤å¼•ç­‰ã®ç®¡ç†ã‚³ãƒ¼ãƒ‰ã¯è‡ªå‹•çš„ã«é™¤å¤–ã•ã‚Œã¦ã„ã¾ã™ã€‚")

    # Selection API
    event = st.dataframe(
        df_disp[cols],
        use_container_width=True,
        hide_index=True,
        column_config={
            "å•†å“å": st.column_config.TextColumn("å•†å“å", width="medium"),
            "å£²ä¸Šå·®é¡": st.column_config.NumberColumn("å£²ä¸Šå·®é¡", format="Â¥%d"),
            "ä»Šå¹´å£²ä¸Š": st.column_config.NumberColumn("ä»Šå¹´å£²ä¸Š", format="Â¥%d"),
            "å‰å¹´å£²ä¸Š": st.column_config.NumberColumn("å‰å¹´å£²ä¸Š", format="Â¥%d"),
            "ç²—åˆ©å·®é¡": st.column_config.NumberColumn("ç²—åˆ©å·®é¡", format="Â¥%d"),
            "ä»Šå¹´ç²—åˆ©": st.column_config.NumberColumn("ä»Šå¹´ç²—åˆ©", format="Â¥%d"),
        },
        height=400,
        on_select="rerun",
        selection_mode="single-row",
        key=f"{key_prefix}_table_1"
    )

    # Level 2: Product Selected -> Show Customer Breakdown
    if len(event.selection["rows"]) > 0:
        idx = event.selection["rows"][0]
        selected_product = df_disp.iloc[idx]["å•†å“å"]
        
        st.divider()
        st.subheader(f"ğŸ” è©³ç´°åˆ†æ: {selected_product}")
        st.info(f"ã“ã®å•†å“ã¯ã€ã©ã®å¾—æ„å…ˆã§æ•°å­—ãŒå¤‰å‹•ã—ãŸã®ã‹ï¼Ÿ ({'æ¸›å°‘' if is_worst else 'å¢—åŠ '}è¦å› )")

        df_cust = get_product_drilldown(client, cache_key, selected_product, is_worst, opts)
        
        if df_cust.empty:
            st.warning("è©³ç´°ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            event_cust = st.dataframe(
                df_cust,
                use_container_width=True,
                hide_index=True,
                column_config=create_default_column_config(df_cust),
                on_select="rerun",
                selection_mode="single-row",
                key=f"{key_prefix}_table_2"
            )

            # Level 3: Customer Selected -> Show Portfolio
            if len(event_cust.selection["rows"]) > 0:
                c_idx = event_cust.selection["rows"][0]
                selected_customer = df_cust.iloc[c_idx]["å¾—æ„å…ˆå"]
                
                st.divider()
                st.subheader(f"ğŸ¥ å¾—æ„å…ˆåˆ†æ: {selected_customer}")
                st.success(f"{selected_customer} ã®ç¾åœ¨ã®è³¼å…¥å•†å“ä¸€è¦§")
                
                df_portfolio = get_customer_portfolio(client, cache_key, selected_customer, opts)
                st.dataframe(
                    df_portfolio,
                    use_container_width=True,
                    hide_index=True,
                    column_config=create_default_column_config(df_portfolio),
                    key=f"{key_prefix}_table_3"
                )

def render_fytd_org_section(client, cache_key, login_email, opts):
    st.subheader("ğŸ¢ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå…¨ç¤¾")
    
    if st.button("å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_org_load", use_container_width=True):
        st.session_state.org_data_loaded = True
    
    if st.session_state.org_data_loaded:
        # KPI Cards
        sql_kpi = f"SELECT * FROM `{VIEW_FYTD_ORG}` __WHERE__ LIMIT 100"
        df_org = run_scoped_query(client, cache_key, sql_kpi, "viewer_email", login_email, opts, allow_fallback=True)
        
        if not df_org.empty:
            row = df_org.iloc[0]
            s_cur = get_safe_float(row, 'sales_amount_fytd')
            s_py = get_safe_float(row, 'sales_amount_py_total')
            s_fc = get_safe_float(row, 'sales_forecast_total')
            gp_cur = get_safe_float(row, 'gross_profit_fytd')
            gp_py = get_safe_float(row, 'gross_profit_py_total')
            gp_fc = get_safe_float(row, 'gp_forecast_total')

            st.markdown("##### â–  å£²ä¸Š (Sales)")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("â‘  ç¾çŠ¶ (FYTD)", f"Â¥{s_cur:,.0f}")
            c2.metric("â‘¡ æ˜¨å¹´åº¦å®Ÿç¸¾", f"Â¥{s_py:,.0f}")
            c3.metric("â‘¢ ç€åœ°äºˆæ¸¬", f"Â¥{s_fc:,.0f}", delta_color="normal")
            c4.metric("â‘£ GAP", f"Â¥{s_fc - s_py:,.0f}", delta=None, delta_color="off")

            st.markdown("##### â–  ç²—åˆ© (Gross Profit)")
            c5, c6, c7, c8 = st.columns(4)
            c5.metric("â‘  ç¾çŠ¶ (FYTD)", f"Â¥{gp_cur:,.0f}")
            c6.metric("â‘¡ æ˜¨å¹´åº¦å®Ÿç¸¾", f"Â¥{gp_py:,.0f}")
            c7.metric("â‘¢ ç€åœ°äºˆæ¸¬", f"Â¥{gp_fc:,.0f}", delta_color="normal")
            c8.metric("â‘£ GAP", f"Â¥{gp_fc - gp_py:,.0f}", delta=None, delta_color="off")
            
            st.divider()

        # Interactive Ranking Tabs
        st.subheader("ğŸ“Š å¢—æ¸›è¦å› åˆ†æ (ãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³)")
        tab_worst, tab_best = st.tabs(["ğŸ“‰ ãƒ¯ãƒ¼ã‚¹ãƒˆ (å£²ä¸Šæ¸›)", "ğŸ“ˆ ãƒ™ã‚¹ãƒˆ (å£²ä¸Šå¢—)"])
        
        with tab_worst:
            render_interactive_ranking_flow(client, cache_key, "worst", opts)
        
        with tab_best:
            render_interactive_ranking_flow(client, cache_key, "best", opts)

    else:
        st.info("ğŸ‘† ä¸Šã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")

def render_fytd_me_section(client, cache_key, login_email, opts):
    st.subheader("ğŸ‘¤ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œè‡ªåˆ†")
    if st.button("è‡ªåˆ†ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_me", use_container_width=True):
        sql = f"SELECT * FROM `{VIEW_FYTD_ME}` __WHERE__ LIMIT 100"
        df_me = run_scoped_query(client, cache_key, sql, "login_email", login_email, opts)
        if df_me.empty:
            st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        row = df_me.iloc[0]
        s_cur = get_safe_float(row, 'sales_amount_fytd')
        s_fc = get_safe_float(row, 'sales_forecast_total')
        s_py = get_safe_float(row, 'sales_amount_py_total')
        gp_cur = get_safe_float(row, 'gross_profit_fytd')
        gp_fc = get_safe_float(row, 'gp_forecast_total')
        gp_py = get_safe_float(row, 'gross_profit_py_total')

        st.markdown("##### â–  å£²ä¸Š (Sales)")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("â‘  ç¾çŠ¶", f"Â¥{s_cur:,.0f}")
        c2.metric("â‘¡ æ˜¨å¹´", f"Â¥{s_py:,.0f}")
        c3.metric("â‘¢ äºˆæ¸¬", f"Â¥{s_fc:,.0f}")
        c4.metric("â‘£ GAP", f"Â¥{s_fc - s_py:,.0f}", delta_color="off")

        st.markdown("##### â–  ç²—åˆ© (Gross Profit)")
        c5, c6, c7, c8 = st.columns(4)
        c5.metric("â‘  ç¾çŠ¶", f"Â¥{gp_cur:,.0f}")
        c6.metric("â‘¡ æ˜¨å¹´", f"Â¥{gp_py:,.0f}")
        c7.metric("â‘¢ äºˆæ¸¬", f"Â¥{gp_fc:,.0f}")
        c8.metric("â‘£ GAP", f"Â¥{gp_fc - gp_py:,.0f}", delta_color="off")
        st.divider()
        
        df_disp = rename_columns_for_display(df_me, JP_COLS_FYTD)
        cols = list(df_disp.columns)
        if "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«" in cols: cols.remove("ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«")
        if "é–²è¦§è€…ãƒ¡ãƒ¼ãƒ«" in cols: cols.remove("é–²è¦§è€…ãƒ¡ãƒ¼ãƒ«")
        if "æ‹…å½“è€…å" in cols:
            cols.remove("æ‹…å½“è€…å")
            cols.insert(0, "æ‹…å½“è€…å")
        
        col_cfg = create_default_column_config(df_disp[cols])
        st.dataframe(df_disp[cols], use_container_width=True, hide_index=True, column_config=col_cfg)

def render_yoy_section(client, cache_key, login_email, allow_fallback, opts):
    st.subheader("ğŸ“Š å½“æœˆYoYï¼ˆå¾—æ„å…ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰")
    c1, c2, c3 = st.columns(3)
    
    def _show_table(title, view_name, key):
        if st.button(title, key=key, use_container_width=True):
            sql = f"SELECT * FROM `{view_name}` __WHERE__ LIMIT 200"
            df = run_scoped_query(client, cache_key, sql, "login_email", login_email, opts, allow_fallback)
            if not df.empty:
                df_disp = rename_columns_for_display(df, JP_COLS_YOY)
                cols = list(df_disp.columns)
                if "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«" in cols: cols.remove("ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«")
                if "æ‹…å½“è€…å" in cols:
                    cols.remove("æ‹…å½“è€…å")
                    cols.insert(0, "æ‹…å½“è€…å")
                
                df_final = append_total_row(df_disp[cols], label_col="æ‹…å½“è€…å")
                col_cfg = create_default_column_config(df_final)
                st.dataframe(df_final, use_container_width=True, hide_index=True, column_config=col_cfg)
            else:
                st.info("0ä»¶ã§ã™ã€‚")

    with c1: _show_table("YoY Top (ä¼¸ã³)", VIEW_YOY_TOP, "btn_top")
    with c2: _show_table("YoY Bottom (è½ã¡)", VIEW_YOY_BOTTOM, "btn_btm")
    with c3: _show_table("æ–°è¦/æ¯”è¼ƒä¸èƒ½", VIEW_YOY_UNCOMP, "btn_unc")

def render_customer_drilldown(client, cache_key, login_email, opts):
    st.subheader("ğŸ¯ å¾—æ„å…ˆåˆ¥ãƒ»æˆ¦ç•¥ææ¡ˆï¼ˆAI Gap Analysisï¼‰")
    
    sql_cust = f"SELECT DISTINCT customer_code, customer_name FROM `{VIEW_FACT_DAILY}` WHERE login_email = @login_email ORDER BY customer_code"
    df_cust = query_df_safe(client, sql_cust, {"login_email": login_email}, "Cust List", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    
    if df_cust.empty:
        st.info("æ‹…å½“å¾—æ„å…ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆã¾ãŸã¯ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«ä¸ä¸€è‡´ï¼‰ã€‚")
        return

    cust_options = {row["customer_code"]: f"{row['customer_code']} : {row['customer_name']}" for _, row in df_cust.iterrows()}
    selected_code = st.selectbox("åˆ†æã™ã‚‹å¾—æ„å…ˆã‚’é¸æŠã—ã¦ãã ã•ã„", options=cust_options.keys(), format_func=lambda x: cust_options[x])
    if not selected_code: return

    st.divider()
    sql_rec = f"SELECT * FROM `{VIEW_RECOMMEND}` WHERE customer_code = @cust_code ORDER BY priority_rank ASC"
    df_rec = query_df_safe(client, sql_rec, {"cust_code": selected_code}, "Recommendation", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    
    c1, c2 = st.columns([1, 2])
    with c1:
        st.markdown("#### ğŸ¥ å¾—æ„å…ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«")
        if not df_rec.empty:
            strong_cat = df_rec.iloc[0].get("strong_category", "-")
            st.info(f"ã“ã®å¾—æ„å…ˆã®ä¸»åŠ›é ˜åŸŸ(ãƒ¡ãƒ¼ã‚«ãƒ¼): **{strong_cat}**")
            st.caption("â€»è³¼å…¥å®Ÿç¸¾ã‚·ã‚§ã‚¢No.1ã®ãƒ¡ãƒ¼ã‚«ãƒ¼")
        else:
            st.warning("ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆã¾ãŸã¯ä¸»è¦å“å®Œç´æ¸ˆã¿ï¼‰")
            strong_cat = "(ä¸æ˜)"

    with c2:
        st.markdown("#### ğŸ’¡ AIææ¡ˆãƒªã‚¹ãƒˆï¼ˆæœªæ¡ç”¨ã®ãƒãƒ£ãƒ³ã‚¹å•†å“ï¼‰")
        st.caption(f"å…¨ç¤¾ã® **{strong_cat}** å£²ä¸ŠTOP10ã®ã†ã¡ã€**æœªæ¡ç”¨**ã®å•†å“")
        
        if df_rec.empty:
            st.success("ğŸ‰ ã“ã®é ˜åŸŸã®ä¸»è¦å•†å“ã¯ã™ã¹ã¦æ¡ç”¨æ¸ˆã¿ã§ã™ã€‚")
        else:
            disp_df = df_rec[["priority_rank", "recommend_product", "manufacturer", "market_scale"]].rename(columns={"priority_rank": "å„ªå…ˆé †ä½", "recommend_product": "æ¨å¥¨å•†å“å", "manufacturer": "ãƒ¡ãƒ¼ã‚«ãƒ¼", "market_scale": "å…¨ç¤¾å£²ä¸Šè¦æ¨¡"})
            col_cfg = create_default_column_config(disp_df)
            st.dataframe(disp_df, use_container_width=True, hide_index=True, column_config=col_cfg)
            
    with st.expander("å‚è€ƒ: ç¾åœ¨ã®æ¡ç”¨å“ãƒªã‚¹ãƒˆã‚’è¦‹ã‚‹"):
        sql_adopted = f"""
        SELECT 
            m.product_name, 
            SUM(t.sales_amount) as sales_fytd,
            SUM(t.gross_profit) as gp_fytd
        FROM `{VIEW_FACT_DAILY}` t
        LEFT JOIN `{PROJECT_DEFAULT}.{DATASET_DEFAULT}.vw_item_master_norm` m 
            ON CAST(t.jan AS STRING) = CAST(m.jan_code AS STRING)
        WHERE t.customer_code = @cust_code AND t.fiscal_year = 2025
        GROUP BY 1 ORDER BY 2 DESC LIMIT 100
        """
        df_adopted = query_df_safe(client, sql_adopted, {"cust_code": selected_code}, "Adopted List", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
        
        renamed_df = df_adopted.rename(columns={"product_name": "å•†å“å", "sales_fytd": "å£²ä¸Š(FYTD)", "gp_fytd": "ç²—åˆ©(FYTD)"})
        col_cfg = create_default_column_config(renamed_df)
        st.dataframe(renamed_df, use_container_width=True, column_config=col_cfg)


# -----------------------------
# 8. Main
# -----------------------------
def main():
    if 'org_data_loaded' not in st.session_state: st.session_state.org_data_loaded = False

    set_page()
    
    client, project_id, location, sa_json = setup_bigquery_client()
    cache_key = (project_id, location, sa_json)
    
    opts = sidebar_controls()
    login_email = get_login_email_ui()
    st.divider()

    role = resolve_role(client, cache_key, login_email, opts)
    st.write(f"**Login:** {role.login_email} / **Role:** {role.role_key} ({role.area_name})")
    is_admin = role.role_key in ("HQ_ADMIN", "AREA_MANAGER")
    st.divider()
    
    if is_admin:
        t1, t2, t3 = st.tabs(["ğŸ¢ å…¨ç¤¾çŠ¶æ³", "ğŸ‘¤ ã‚¨ãƒªã‚¢/å€‹äºº", "ğŸ¯ æˆ¦ç•¥ææ¡ˆ(Beta)"])
        with t1: render_fytd_org_section(client, cache_key, login_email, opts)
        with t2:
            render_fytd_me_section(client, cache_key, login_email, opts)
            st.divider()
            render_yoy_section(client, cache_key, login_email, is_admin, opts)
        with t3: render_customer_drilldown(client, cache_key, login_email, opts)
    else:
        t1, t2, t3 = st.tabs(["ğŸ‘¤ ä»Šå¹´ã®æˆç¸¾", "ğŸ“Š å¾—æ„å…ˆåˆ†æ", "ğŸ¯ ææ¡ˆã‚’ä½œã‚‹"])
        with t1: render_fytd_me_section(client, cache_key, login_email, opts)
        with t2: render_yoy_section(client, cache_key, login_email, is_admin, opts)
        with t3: render_customer_drilldown(client, cache_key, login_email, opts)

    st.caption("Updated: v1.9.3 (Drill-Down Update)")

if __name__ == "__main__":
    main()
