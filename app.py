# app.py
# -*- coding: utf-8 -*-
"""
SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - OS v1.9.8 (Master Integrated / High Performance)

ã€æ›´æ–°å±¥æ­´ v1.9.8ã€‘
- [Integration] æ‹…å½“è€…å°å¸³(sales_staff_master)ã‚’ãƒã‚¹ã‚¿ãƒ¼ã¨ã—ã¦çµ±åˆã€‚
- [Feature] ãƒ­ã‚°ã‚¤ãƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œé›»è©±ç•ªå·ã€è¡¨ç¤ºãŠã‚ˆã³ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãƒ™ãƒ¼ã‚¹ã®æ¨©é™åˆ¤å®šã‚’å®Ÿè£…ã€‚
- [Structure] v1.9.7ã®å‹•çš„SQLã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å®Œå…¨è¸è¥²ã€‚

â˜…ä»Šå›ã®æ›´æ–°ææ¡ˆï¼ˆè¸è¥²ã®ã†ãˆã§ã®ç¢ºå®šã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆï¼‰
- [Security] ãƒ©ãƒ³ã‚­ãƒ³ã‚°/ãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ï¼ˆVIEW_UNIFIEDç›´é›†è¨ˆï¼‰ã«ã‚‚æ¨©é™ã‚¹ã‚³ãƒ¼ãƒ—ã‚’å¼·åˆ¶æ³¨å…¥ï¼ˆæ¼æ´©é˜²æ­¢ï¼‰
- [Stability] fiscal_year ã®å›ºå®šå€¤ï¼ˆ2025/2024ï¼‰ã‚’å…¨å»ƒã—ã€MAX(fiscal_year) ã‹ã‚‰å‹•çš„ã«è¨ˆç®—
- [Master] sales_staff_master ã« area_name åˆ—ãŒç„¡ã„å ´åˆã§ã‚‚å‹•ä½œã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆroleæ–‡å­—åˆ—â†’ã‚¨ãƒªã‚¢æ¨å®šã¯ä»»æ„ï¼‰
- [Recommendation] v_sales_recommendation_engine ã®åˆ—åå·®ç•°ã«è€ãˆã‚‹ï¼ˆå­˜åœ¨åˆ—ã ã‘è¡¨ç¤ºï¼‰
"""

from __future__ import annotations

import json
from dataclasses import dataclass
from typing import Any, Dict, Optional, Tuple, List

import pandas as pd
import streamlit as st
from pandas.api.types import is_numeric_dtype

from google.cloud import bigquery
from google.oauth2 import service_account
from google.api_core.exceptions import BadRequest, GoogleAPICallError

# -----------------------------
# 1. Configuration
# -----------------------------
APP_TITLE = "SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"
DEFAULT_LOCATION = "asia-northeast1"
CACHE_TTL_SEC = 300

APP_URL = "https://sfa-premium-app-2.streamlit.app/"
PROJECT_DEFAULT = "salesdb-479915"
DATASET_DEFAULT = "sales_data"

# çµ±åˆViewï¼ˆåˆ†æã®åœŸå°ï¼‰
VIEW_UNIFIED = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_unified"

# KPI/ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ—¢å­˜View
VIEW_FYTD_ORG = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_admin_org_fytd_summary_scoped"
VIEW_FYTD_ME = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_staff_fytd_summary_scoped"
VIEW_YOY_TOP = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_top_current_month_named"
VIEW_YOY_BOTTOM = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_bottom_current_month_named"
VIEW_YOY_UNCOMP = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_uncomparable_current_month_named"

# æˆ¦ç•¥ææ¡ˆ
VIEW_RECOMMEND = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_recommendation_engine"
VIEW_FACT_DAILY = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_login_jan_daily"
VIEW_ITEM_MASTER = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.vw_item_master_norm"

# æ‹…å½“è€…å°å¸³ï¼ˆã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆé€£æºãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰
VIEW_ROLE = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.sales_staff_master"

# é™¤å¤–JAN
NOISE_JAN_SQL = "('0', '22221', '99998', '33334')"

# -----------------------------
# 2. Helpers (Display)
# -----------------------------
def set_page():
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)
    st.caption("OS v1.9.8 (Master Integrated)ï½œBigQueryé›†è¨ˆãƒ»å‹•çš„SQLç‰ˆï½œRBACæ³¨å…¥æ¸ˆã¿")

def get_qr_code_url(url: str) -> str:
    return f"https://api.qrserver.com/v1/create-qr-code/?size=150x150&data={url}"

def rename_columns_for_display(df: pd.DataFrame, mapping: Dict[str, str]) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    cols = {c: mapping.get(c, c) for c in df.columns}
    return df.rename(columns=cols)

def create_default_column_config(df: pd.DataFrame) -> Dict[str, st.column_config.Column]:
    config: Dict[str, st.column_config.Column] = {}
    for col in df.columns:
        if any(k in col for k in ["å£²ä¸Š", "ç²—åˆ©", "é‡‘é¡", "å·®", "å®Ÿç¸¾", "äºˆæ¸¬", "GAP"]):
            config[col] = st.column_config.NumberColumn(col, format="Â¥%d")
        elif any(k in col for k in ["ç‡", "æ¯”", "ãƒšãƒ¼ã‚¹"]):
            config[col] = st.column_config.NumberColumn(col, format="%.1f%%")
        elif is_numeric_dtype(df[col]):
            config[col] = st.column_config.NumberColumn(col, format="%d")
        else:
            config[col] = st.column_config.TextColumn(col)
    return config

def get_safe_float(row: pd.Series, key: str) -> float:
    val = row.get(key)
    if pd.isna(val):
        return 0.0
    try:
        return float(val)
    except Exception:
        return 0.0

JP_COLS_FYTD = {
    "login_email": "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«",
    "display_name": "æ‹…å½“è€…å",
    "sales_amount_fytd": "å£²ä¸Šï¼ˆFYTDï¼‰",
    "gross_profit_fytd": "ç²—åˆ©ï¼ˆFYTDï¼‰",
    "sales_amount_py_total": "å‰å¹´å£²ä¸Šå®Ÿç¸¾ï¼ˆå¹´ï¼‰",
    "sales_forecast_total": "å£²ä¸Šç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰",
    "gross_profit_py_total": "å‰å¹´ç²—åˆ©å®Ÿç¸¾ï¼ˆå¹´ï¼‰",
    "gp_forecast_total": "ç²—åˆ©ç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰",
}
JP_COLS_YOY = {
    "customer_code": "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰",
    "customer_name": "å¾—æ„å…ˆå",
    "sales_amount": "å£²ä¸Šï¼ˆå½“æœˆï¼‰",
    "gross_profit": "ç²—åˆ©ï¼ˆå½“æœˆï¼‰",
    "sales_amount_py": "å£²ä¸Šï¼ˆå‰å¹´åŒæœˆï¼‰",
    "sales_diff_yoy": "å‰å¹´å·®ï¼ˆå£²ä¸Šï¼‰",
}

# -----------------------------
# 3. BigQuery Connection
# -----------------------------
def setup_bigquery_client() -> Tuple[bigquery.Client, str, str, str]:
    if "bigquery" not in st.secrets:
        st.error("âŒ Secretsè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()
    bq = st.secrets["bigquery"]
    project_id = str(bq.get("project_id"))
    location = str(bq.get("location") or DEFAULT_LOCATION)
    sa = dict(bq.get("service_account"))
    creds = service_account.Credentials.from_service_account_info(sa)
    client = bigquery.Client(project=project_id, credentials=creds, location=location)
    return client, project_id, location, json.dumps(sa, ensure_ascii=False, sort_keys=True)

def _build_query_parameters(params: Optional[Dict[str, Any]]) -> List[bigquery.ScalarQueryParameter]:
    qparams: List[bigquery.ScalarQueryParameter] = []
    if not params:
        return qparams
    for k, v in params.items():
        if isinstance(v, bool):
            qparams.append(bigquery.ScalarQueryParameter(k, "BOOL", v))
        elif isinstance(v, int):
            qparams.append(bigquery.ScalarQueryParameter(k, "INT64", v))
        elif isinstance(v, float):
            qparams.append(bigquery.ScalarQueryParameter(k, "FLOAT64", v))
        elif v is None:
            qparams.append(bigquery.ScalarQueryParameter(k, "STRING", ""))
        else:
            qparams.append(bigquery.ScalarQueryParameter(k, "STRING", str(v)))
    return qparams

@st.cache_data(show_spinner=False, ttl=CACHE_TTL_SEC)
def cached_query_df(project_id: str, location: str, sa_json: str, sql: str, params_json: str, use_bqstorage: bool, timeout_sec: int) -> pd.DataFrame:
    sa = json.loads(sa_json)
    creds = service_account.Credentials.from_service_account_info(sa)
    client = bigquery.Client(project=project_id, credentials=creds, location=location)

    params = json.loads(params_json) if params_json else {}
    job_config = bigquery.QueryJobConfig()
    qparams = _build_query_parameters(params)
    if qparams:
        job_config.query_parameters = qparams

    job = client.query(sql, job_config=job_config)
    job.result(timeout=timeout_sec)
    return job.to_dataframe(create_bqstorage_client=use_bqstorage)

def query_df_safe(
    client: bigquery.Client,
    sql: str,
    params: Optional[Dict[str, Any]] = None,
    label: str = "",
    use_bqstorage: bool = True,
    timeout_sec: int = 60,
    cache_key: Optional[Tuple[str, str, str]] = None,
) -> pd.DataFrame:
    params_json = json.dumps(params or {}, ensure_ascii=False, sort_keys=True)

    try:
        if cache_key is None:
            job_config = bigquery.QueryJobConfig()
            qparams = _build_query_parameters(params)
            if qparams:
                job_config.query_parameters = qparams
            job = client.query(sql, job_config=job_config)
            job.result(timeout=timeout_sec)
            return job.to_dataframe(create_bqstorage_client=use_bqstorage)

        project_id, location, sa_json = cache_key
        return cached_query_df(project_id, location, sa_json, sql, params_json, use_bqstorage, timeout_sec)

    except (BadRequest, GoogleAPICallError) as e:
        st.error(f"Query Failed: {label}\n{e}")
        st.code(sql, language="sql")
        if params:
            st.code(json.dumps(params, ensure_ascii=False, indent=2), language="json")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"Query Failed: {label}\n{e}")
        st.code(sql, language="sql")
        if params:
            st.code(json.dumps(params, ensure_ascii=False, indent=2), language="json")
        return pd.DataFrame()

# -----------------------------
# 3.5 Role / RBAC
# -----------------------------
@dataclass(frozen=True)
class RoleInfo:
    login_email: str
    staff_name: str = "ã‚²ã‚¹ãƒˆ"
    role_key: str = "SALES"          # HQ_ADMIN / SALES ï¼ˆæœ€å°ï¼‰
    role_admin_view: bool = False    # Trueãªã‚‰å…¨ç¤¾/ã‚¨ãƒªã‚¢ã®é–²è¦§ã‚’è¨±å¯
    phone: str = "-"
    area_name: str = "æœªè¨­å®š"        # æœ¬æ¥ã¯å°å¸³ã® area_name åˆ—ã‚’æ­£ã¨ã™ã‚‹

def _normalize_role_key(role_key: str) -> str:
    rk = (role_key or "").strip().upper()
    if rk in ("HQ_ADMIN", "AREA_MANAGER", "SALES"):
        return rk
    return "SALES"

def _infer_area_from_role_text(raw_role: str) -> str:
    """
    ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼šroleæ–‡å­—åˆ—ã«ã€Œç†Šæœ¬ã€ã€Œå¤§åˆ†ã€ç­‰ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°æ‹¾ã†ã€‚
    â€» æ­£æœ¬ã¯ sales_staff_master ã® area_name åˆ—ã€‚
    """
    r = (raw_role or "").upper()
    for a in ["ç†Šæœ¬", "å¤§åˆ†", "ç¦å²¡", "ä¹…ç•™ç±³", "å…«å¥³", "æŸ³å·", "å¤§ç‰Ÿç”°", "ã¿ã‚„ã¾", "æœ¬ç¤¾", "HQ"]:
        if a.upper() in r:
            return a
    return "æœªè¨­å®š"

def resolve_role(client: bigquery.Client, cache_key: Tuple[str, str, str], login_email: str, use_bqstorage: bool, timeout_sec: int) -> RoleInfo:
    # area_name åˆ—ãŒå­˜åœ¨ã—ãªã„å¯èƒ½æ€§ã«å‚™ãˆã€ã¾ãš INFORMATION_SCHEMA ã§åˆ—å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    sql_cols = f"""
    SELECT column_name
    FROM `{PROJECT_DEFAULT}.{DATASET_DEFAULT}.INFORMATION_SCHEMA.COLUMNS`
    WHERE table_name = 'sales_staff_master'
    """
    df_cols = query_df_safe(client, sql_cols, None, "Role Columns", use_bqstorage, timeout_sec, cache_key)
    colset = set(df_cols["column_name"].astype(str).tolist()) if not df_cols.empty else set()

    has_area = "area_name" in colset
    has_role_key = "role_key" in colset  # ã‚‚ã—å°å¸³ã« role_key ã‚’æŒãŸã›ãŸå ´åˆ

    select_cols = ["email", "staff_name", "role", "phone"]
    if has_area:
        select_cols.append("area_name")
    if has_role_key:
        select_cols.append("role_key")

    sql = f"""
    SELECT {", ".join(select_cols)}
    FROM `{VIEW_ROLE}`
    WHERE email = @login_email
    LIMIT 1
    """
    df = query_df_safe(
        client,
        sql,
        {"login_email": login_email},
        "Role Check",
        use_bqstorage=use_bqstorage,
        timeout_sec=timeout_sec,
        cache_key=cache_key,
    )

    if df.empty:
        return RoleInfo(login_email=login_email)

    r = df.iloc[0].to_dict()
    raw_role = str(r.get("role", "")).strip()
    raw_role_up = raw_role.upper()

    # ç®¡ç†è€…åˆ¤å®šï¼ˆã‚ãªãŸã®ç¾è¡Œãƒ­ã‚¸ãƒƒã‚¯è¸è¥²ï¼‰
    is_admin = any(x in raw_role_up for x in ["ADMIN", "MANAGER", "HQ", "çµ±æ‹¬", "æœ¬ç¤¾"])
    role_key = _normalize_role_key(str(r.get("role_key", "HQ_ADMIN" if is_admin else "SALES")))

    # area_name ã¯å°å¸³ã®åˆ—ã‚’æ­£ã¨ã™ã‚‹ã€‚ç„¡ã‘ã‚Œã° roleæ–‡å­—åˆ—ã‹ã‚‰æ¨å®šï¼ˆæš«å®šï¼‰
    area_name = str(r.get("area_name", "")).strip() if has_area else ""
    if not area_name:
        area_name = _infer_area_from_role_text(raw_role)

    return RoleInfo(
        login_email=login_email,
        staff_name=str(r.get("staff_name", "ä¸æ˜")),
        role_key=role_key,
        role_admin_view=bool(is_admin),
        phone=str(r.get("phone", "-")),
        area_name=area_name or "æœªè¨­å®š",
    )

def get_scope_filter_sql(role: RoleInfo) -> Tuple[str, Dict[str, Any]]:
    """
    â˜…é‡è¦ï¼šVIEW_UNIFIEDï¼ˆç›´é›†è¨ˆï¼‰ã¸æ³¨å…¥ã™ã‚‹RBACæ¡ä»¶
    - HQ_ADMIN: å…¨ç¤¾
    - ãã‚Œä»¥å¤–: åŸå‰‡ login_email
    - ã‚‚ã— VIEW_UNIFIED ã« area_name åˆ—ãŒã‚ã‚Šã€role.area_name ãŒæœ‰åŠ¹ãªã‚‰ã‚¨ãƒªã‚¢ã‚¹ã‚³ãƒ¼ãƒ—ã‚‚å¯èƒ½
      ï¼ˆåˆ—æœ‰ç„¡ã¯ã“ã“ã§ã¯åˆ¤å®šã›ãšSQLå´ã§ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã®ã§ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ login_email ã‚’æ¨å¥¨ï¼‰
    """
    if role.role_key == "HQ_ADMIN" or role.role_admin_view:
        return "1=1", {}
    return "login_email = @login_email", {"login_email": role.login_email}

# -----------------------------
# 4. BigQuery Calculation Logic (RBACæ³¨å…¥)
# -----------------------------
def fetch_ranking_from_bq(
    client: bigquery.Client,
    cache_key: Tuple[str, str, str],
    role: RoleInfo,
    ranking_type: str,
    axis_mode: str,
    is_sales_mode: bool,
    use_bqstorage: bool,
    timeout_sec: int,
) -> pd.DataFrame:
    is_worst = (ranking_type == "worst")
    is_product = (axis_mode == "product")
    group_col = "product_name" if is_product else "customer_name"
    target_val = "sales_amount" if is_sales_mode else "gross_profit"
    order_dir = "ASC" if is_worst else "DESC"

    scope_sql, scope_params = get_scope_filter_sql(role)

    sql = f"""
    WITH base_stats AS (
        SELECT MAX(fiscal_year) AS current_fy FROM `{VIEW_UNIFIED}`
    )
    SELECT
        {group_col} AS name,
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN sales_amount ELSE 0 END) AS sales_cur,
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN gross_profit ELSE 0 END) AS gp_cur,
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) - 1 THEN sales_amount ELSE 0 END) AS sales_prev,
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN {target_val} ELSE 0 END) -
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) - 1 THEN {target_val} ELSE 0 END) AS diff_val,
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN sales_amount ELSE 0 END) -
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) - 1 THEN sales_amount ELSE 0 END) AS sales_diff,
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN gross_profit ELSE 0 END) -
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) - 1 THEN gross_profit ELSE 0 END) AS gp_diff
    FROM `{VIEW_UNIFIED}`
    WHERE
        ({scope_sql})
        AND jan_code NOT IN {NOISE_JAN_SQL}
        AND jan_code NOT LIKE '999%'
        AND LENGTH(jan_code) > 5
    GROUP BY {group_col}
    HAVING (sales_cur > 0 OR sales_prev > 0)
    ORDER BY diff_val {order_dir}
    LIMIT 1000
    """
    return query_df_safe(
        client,
        sql,
        scope_params,
        "Ranking Query",
        use_bqstorage=use_bqstorage,
        timeout_sec=timeout_sec,
        cache_key=cache_key,
    )

def fetch_drilldown_from_bq(
    client: bigquery.Client,
    cache_key: Tuple[str, str, str],
    role: RoleInfo,
    key_col: str,
    key_val: str,
    target_col: str,
    is_worst: bool,
    is_sales_mode: bool,
    use_bqstorage: bool,
    timeout_sec: int,
) -> pd.DataFrame:
    order_dir = "ASC" if is_worst else "DESC"
    sort_col_alias = "å£²ä¸Šå·®é¡" if is_sales_mode else "ç²—åˆ©å·®é¡"
    target_label = "å¾—æ„å…ˆå" if target_col == "customer_name" else "å•†å“å"

    scope_sql, scope_params = get_scope_filter_sql(role)

    sql = f"""
    WITH base_stats AS (
        SELECT MAX(fiscal_year) AS current_fy FROM `{VIEW_UNIFIED}`
    )
    SELECT
        {target_col} AS `{target_label}`,
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN sales_amount ELSE 0 END) AS `ä»Šå¹´å£²ä¸Š`,
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) - 1 THEN sales_amount ELSE 0 END) AS `å‰å¹´å£²ä¸Š`,
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN sales_amount ELSE 0 END) -
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) - 1 THEN sales_amount ELSE 0 END) AS `å£²ä¸Šå·®é¡`,
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN gross_profit ELSE 0 END) AS `ä»Šå¹´ç²—åˆ©`,
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN gross_profit ELSE 0 END) -
        SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) - 1 THEN gross_profit ELSE 0 END) AS `ç²—åˆ©å·®é¡`
    FROM `{VIEW_UNIFIED}`
    WHERE
        ({scope_sql})
        AND {key_col} = @key_val
    GROUP BY 1
    ORDER BY `{sort_col_alias}` {order_dir}
    LIMIT 500
    """
    params = dict(scope_params)
    params["key_val"] = key_val

    return query_df_safe(
        client,
        sql,
        params,
        "Drilldown Query",
        use_bqstorage=use_bqstorage,
        timeout_sec=timeout_sec,
        cache_key=cache_key,
    )

def run_scoped_query(
    client: bigquery.Client,
    cache_key: Tuple[str, str, str],
    sql_template: str,
    scope_col: str,
    login_email: str,
    allow_fallback: bool,
    use_bqstorage: bool,
    timeout_sec: int,
    label: str,
):
    sql = sql_template.replace("__WHERE__", f"WHERE {scope_col} = @login_email")
    df = query_df_safe(
        client, sql, {"login_email": login_email},
        label, use_bqstorage, timeout_sec, cache_key
    )
    if not df.empty:
        return df

    if allow_fallback:
        sql_all = sql_template.replace("__WHERE__", f'WHERE {scope_col} = "all" OR {scope_col} IS NULL')
        return query_df_safe(
            client, sql_all, None,
            label + "ï¼ˆfallbackï¼‰", use_bqstorage, timeout_sec, cache_key
        )
    return pd.DataFrame()

# -----------------------------
# 5. UI Layout
# -----------------------------
def sidebar_controls() -> Dict[str, Any]:
    st.sidebar.image(get_qr_code_url(APP_URL), caption="ğŸ“±ã‚¹ãƒãƒ›ã§ã‚¢ã‚¯ã‚»ã‚¹", width=150)
    st.sidebar.divider()

    use_bqstorage = st.sidebar.toggle("BigQuery Storage APIï¼ˆé«˜é€Ÿï¼‰", value=True)
    timeout_sec = st.sidebar.slider("ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰", 10, 300, 60, 10)
    show_sql = st.sidebar.toggle("SQLè¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰", value=False)

    if st.sidebar.button("Clear Cache"):
        st.cache_data.clear()
        st.sidebar.success("Cache Cleared.")
    return {"use_bqstorage": use_bqstorage, "timeout_sec": timeout_sec, "show_sql": show_sql}

def get_login_email_ui() -> str:
    st.sidebar.header("Login Simulation")
    default = st.secrets.get("default_login_email", "") if "default_login_email" in st.secrets else ""
    return st.sidebar.text_input("Login Email", value=default).strip()

def render_interactive_ranking_matrix(
    client: bigquery.Client,
    cache_key: Tuple[str, str, str],
    role: RoleInfo,
    ranking_type: str,
    axis_mode: str,
    is_sales_mode: bool,
    opts: Dict[str, Any],
):
    is_worst = (ranking_type == "worst")
    is_product = (axis_mode == "product")
    label_col = "å•†å“å" if is_product else "å¾—æ„å…ˆå"
    mode_label = "å£²ä¸Š" if is_sales_mode else "ç²—åˆ©"

    df_rank = fetch_ranking_from_bq(
        client=client,
        cache_key=cache_key,
        role=role,
        ranking_type=ranking_type,
        axis_mode=axis_mode,
        is_sales_mode=is_sales_mode,
        use_bqstorage=opts["use_bqstorage"],
        timeout_sec=opts["timeout_sec"],
    )
    if df_rank.empty:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df_disp = df_rank.rename(
        columns={
            "name": label_col,
            "sales_cur": "ä»Šå¹´å£²ä¸Š",
            "sales_prev": "å‰å¹´å£²ä¸Š",
            "sales_diff": "å£²ä¸Šå·®é¡",
            "gp_cur": "ä»Šå¹´ç²—åˆ©",
            "gp_diff": "ç²—åˆ©å·®é¡",
        }
    )

    if is_sales_mode:
        cols = [label_col, "å£²ä¸Šå·®é¡", "ä»Šå¹´å£²ä¸Š", "å‰å¹´å£²ä¸Š", "ç²—åˆ©å·®é¡", "ä»Šå¹´ç²—åˆ©"]
    else:
        cols = [label_col, "ç²—åˆ©å·®é¡", "ä»Šå¹´ç²—åˆ©", "å£²ä¸Šå·®é¡", "ä»Šå¹´å£²ä¸Š", "å‰å¹´å£²ä¸Š"]

    st.markdown(f"##### â‘  {label_col}ã‚’é¸æŠ ({mode_label}ãƒ™ãƒ¼ã‚¹)")
    st.caption(f"â€»{mode_label}ã®å¢—æ¸›é¡ãŒå¤§ãã„é †ï¼ˆè¨ˆç®—: BigQuery / RBACæ³¨å…¥æ¸ˆã¿ï¼‰")

    key_suffix = f"{ranking_type}_{axis_mode}_{mode_label}"
    event = st.dataframe(
        df_disp[cols],
        use_container_width=True,
        hide_index=True,
        column_config=create_default_column_config(df_disp),
        height=400,
        on_select="rerun",
        selection_mode="single-row",
        key=f"t1_{key_suffix}",
    )

    if len(event.selection["rows"]) > 0:
        idx = event.selection["rows"][0]
        selected_val = df_disp.iloc[idx][label_col]

        st.divider()
        st.subheader(f"ğŸ” å†…è¨³åˆ†æ: {selected_val}")

        key_col = "product_name" if is_product else "customer_name"
        target_col = "customer_name" if is_product else "product_name"

        df_drill = fetch_drilldown_from_bq(
            client=client,
            cache_key=cache_key,
            role=role,
            key_col=key_col,
            key_val=str(selected_val),
            target_col=target_col,
            is_worst=is_worst,
            is_sales_mode=is_sales_mode,
            use_bqstorage=opts["use_bqstorage"],
            timeout_sec=opts["timeout_sec"],
        )
        if df_drill.empty:
            st.warning("è©³ç´°ãƒ‡ãƒ¼ã‚¿ãªã—")
        else:
            drill_label = "å¾—æ„å…ˆå" if is_product else "å•†å“å"
            if is_sales_mode:
                d_cols = [drill_label, "å£²ä¸Šå·®é¡", "ä»Šå¹´å£²ä¸Š", "å‰å¹´å£²ä¸Š", "ç²—åˆ©å·®é¡", "ä»Šå¹´ç²—åˆ©"]
            else:
                d_cols = [drill_label, "ç²—åˆ©å·®é¡", "ä»Šå¹´ç²—åˆ©", "å£²ä¸Šå·®é¡", "ä»Šå¹´å£²ä¸Š", "å‰å¹´å£²ä¸Š"]

            st.dataframe(
                df_drill[d_cols],
                use_container_width=True,
                hide_index=True,
                column_config=create_default_column_config(df_drill),
                key=f"t2_{key_suffix}",
            )

def render_fytd_org_section(
    client: bigquery.Client,
    cache_key: Tuple[str, str, str],
    role: RoleInfo,
    opts: Dict[str, Any],
):
    st.subheader("ğŸ¢ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå…¨ç¤¾")

    if st.button("å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_org_load", use_container_width=True):
        st.session_state.org_data_loaded = True

    if not st.session_state.org_data_loaded:
        st.info("ğŸ‘† ä¸Šã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")
        return

    sql_kpi = f"SELECT * FROM `{VIEW_FYTD_ORG}` __WHERE__ LIMIT 100"
    df_org = run_scoped_query(
        client=client,
        cache_key=cache_key,
        sql_template=sql_kpi,
        scope_col="viewer_email",
        login_email=role.login_email,
        allow_fallback=True,
        use_bqstorage=opts["use_bqstorage"],
        timeout_sec=opts["timeout_sec"],
        label="ORG KPI",
    )

    if not df_org.empty:
        row = df_org.iloc[0]
        s_cur = get_safe_float(row, "sales_amount_fytd")
        s_py = get_safe_float(row, "sales_amount_py_total")
        s_fc = get_safe_float(row, "sales_forecast_total")
        gp_cur = get_safe_float(row, "gross_profit_fytd")
        gp_py = get_safe_float(row, "gross_profit_py_total")
        gp_fc = get_safe_float(row, "gp_forecast_total")

        st.markdown("##### â–  å£²ä¸Š (Sales)")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("â‘  ç¾çŠ¶", f"Â¥{s_cur:,.0f}")
        c2.metric("â‘¡ æ˜¨å¹´", f"Â¥{s_py:,.0f}")
        c3.metric("â‘¢ äºˆæ¸¬", f"Â¥{s_fc:,.0f}")
        c4.metric("â‘£ GAP", f"Â¥{s_fc - s_py:,.0f}", delta_color="off")

        st.markdown("##### â–  ç²—åˆ© (Gross Profit)")
        c5, c6, c7, c8 = st.columns(4)
        c5.metric("â‘  ç¾çŠ¶", f"Â¥{gp_cur:,.0f}")
        c6.metric("â‘¡ æ˜¨å¹´", f"Â¥{gp_py:,.0f}")
        c7.metric("â‘¢ äºˆæ¸¬", f"Â¥{gp_fc:,.0f}")
        c8.metric("â‘£ GAP", f"Â¥{gp_fc - gp_py:,.0f}", delta_color="off")
        st.divider()

    st.subheader("ğŸ“Š å¢—æ¸›è¦å› åˆ†æ (å¤šæ¬¡å…ƒ)")
    c_axis, c_val = st.columns(2)
    with c_axis:
        axis_sel = st.radio("é›†è¨ˆè»¸:", ["ğŸ“¦ å•†å“è»¸", "ğŸ¥ å¾—æ„å…ˆè»¸"], horizontal=True)
        axis_mode = "product" if "å•†å“" in axis_sel else "customer"
    with c_val:
        val_sel = st.radio("è©•ä¾¡æŒ‡æ¨™:", ["ğŸ’° å£²ä¸Šé‡‘é¡", "ğŸ’¹ ç²—åˆ©é‡‘é¡"], horizontal=True)
        is_sales_mode = "å£²ä¸Š" in val_sel

    tab_worst, tab_best = st.tabs(["ğŸ“‰ ãƒ¯ãƒ¼ã‚¹ãƒˆ (æ¸›)", "ğŸ“ˆ ãƒ™ã‚¹ãƒˆ (å¢—)"])
    with tab_worst:
        render_interactive_ranking_matrix(client, cache_key, role, "worst", axis_mode, is_sales_mode, opts)
    with tab_best:
        render_interactive_ranking_matrix(client, cache_key, role, "best", axis_mode, is_sales_mode, opts)

def render_fytd_me_section(
    client: bigquery.Client,
    cache_key: Tuple[str, str, str],
    role: RoleInfo,
    opts: Dict[str, Any],
):
    st.subheader("ğŸ‘¤ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œè‡ªåˆ†")
    if st.button("è‡ªåˆ†ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_me", use_container_width=True):
        sql = f"SELECT * FROM `{VIEW_FYTD_ME}` __WHERE__ LIMIT 100"
        df_me = run_scoped_query(
            client=client,
            cache_key=cache_key,
            sql_template=sql,
            scope_col="login_email",
            login_email=role.login_email,
            allow_fallback=False,
            use_bqstorage=opts["use_bqstorage"],
            timeout_sec=opts["timeout_sec"],
            label="ME KPI",
        )
        if df_me.empty:
            st.info("0ä»¶ã§ã™ã€‚")
            return

        df_disp = rename_columns_for_display(df_me, JP_COLS_FYTD)
        cols = list(df_disp.columns)
        if "æ‹…å½“è€…å" in cols:
            cols.remove("æ‹…å½“è€…å")
            cols.insert(0, "æ‹…å½“è€…å")
        st.dataframe(
            df_disp[cols],
            use_container_width=True,
            hide_index=True,
            column_config=create_default_column_config(df_disp[cols]),
        )

def render_yoy_section(
    client: bigquery.Client,
    cache_key: Tuple[str, str, str],
    role: RoleInfo,
    allow_fallback: bool,
    opts: Dict[str, Any],
):
    st.subheader("ğŸ“Š å½“æœˆYoYï¼ˆå¾—æ„å…ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰")
    c1, c2, c3 = st.columns(3)

    def _show_table(title: str, view_name: str, key: str):
        if st.button(title, key=key, use_container_width=True):
            sql = f"SELECT * FROM `{view_name}` __WHERE__ LIMIT 200"
            df = run_scoped_query(
                client=client,
                cache_key=cache_key,
                sql_template=sql,
                scope_col="login_email",
                login_email=role.login_email,
                allow_fallback=allow_fallback,
                use_bqstorage=opts["use_bqstorage"],
                timeout_sec=opts["timeout_sec"],
                label=title,
            )
            if df.empty:
                st.info("0ä»¶ã§ã™ã€‚")
                return
            df_disp = rename_columns_for_display(df, JP_COLS_YOY)
            st.dataframe(df_disp, use_container_width=True, hide_index=True)

    with c1:
        _show_table("YoY Top (ä¼¸ã³)", VIEW_YOY_TOP, "btn_top")
    with c2:
        _show_table("YoY Bottom (è½ã¡)", VIEW_YOY_BOTTOM, "btn_btm")
    with c3:
        _show_table("æ–°è¦/æ¯”è¼ƒä¸èƒ½", VIEW_YOY_UNCOMP, "btn_unc")

def _pick_first_existing_column(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    for c in candidates:
        if c in df.columns:
            return c
    return None

def render_customer_drilldown(
    client: bigquery.Client,
    cache_key: Tuple[str, str, str],
    role: RoleInfo,
    opts: Dict[str, Any],
):
    st.subheader("ğŸ¯ å¾—æ„å…ˆåˆ¥ãƒ»æˆ¦ç•¥ææ¡ˆ")

    # SALES: è‡ªåˆ†ã®å¾—æ„å…ˆã®ã¿ / ADMIN: ã¾ãšè‡ªåˆ†ã®å¾—æ„å…ˆï¼ˆå¿…è¦ãªã‚‰å°†æ¥ã‚¹ã‚³ãƒ¼ãƒ—æ‹¡å¼µï¼‰
    sql_cust = f"""
    SELECT DISTINCT customer_code, customer_name
    FROM `{VIEW_FACT_DAILY}`
    WHERE login_email = @login_email
    ORDER BY customer_code
    """
    df_cust = query_df_safe(
        client, sql_cust, {"login_email": role.login_email},
        "Cust List",
        use_bqstorage=opts["use_bqstorage"],
        timeout_sec=opts["timeout_sec"],
        cache_key=cache_key,
    )
    if df_cust.empty:
        st.info("å¾—æ„å…ˆãƒªã‚¹ãƒˆãŒ0ä»¶ã§ã™ã€‚")
        return

    cust_options = {row["customer_code"]: f"{row['customer_code']} : {row['customer_name']}" for _, row in df_cust.iterrows()}
    selected_code = st.selectbox(
        "åˆ†æã™ã‚‹å¾—æ„å…ˆã‚’é¸æŠã—ã¦ãã ã•ã„",
        options=list(cust_options.keys()),
        format_func=lambda x: cust_options[x],
    )
    if not selected_code:
        return

    st.divider()

    # æ¨å¥¨ãƒ“ãƒ¥ãƒ¼ï¼ˆåˆ—åå·®ç•°ã«è€ãˆã‚‹ï¼‰
    sql_rec = f"SELECT * FROM `{VIEW_RECOMMEND}` WHERE customer_code = @cust_code"
    df_rec = query_df_safe(
        client, sql_rec, {"cust_code": selected_code},
        "Recommendation",
        use_bqstorage=opts["use_bqstorage"],
        timeout_sec=opts["timeout_sec"],
        cache_key=cache_key,
    )
    # ä¸¦ã³é †ï¼ˆpriorityãŒç„¡ã‘ã‚Œã°ãã®ã¾ã¾ï¼‰
    pr_col = _pick_first_existing_column(df_rec, ["priority_rank", "category_rank", "rank", "priority"])
    if df_rec is not None and not df_rec.empty and pr_col:
        df_rec = df_rec.sort_values(pr_col, ascending=True)

    c1, c2 = st.columns([1, 2])

    with c1:
        st.markdown("#### ğŸ¥ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«")
        strong_col = _pick_first_existing_column(df_rec, ["strong_category", "targeted_category", "main_category", "target_category"])
        strong = "-"
        if df_rec is not None and not df_rec.empty and strong_col:
            strong = str(df_rec.iloc[0].get(strong_col, "-"))
        st.info(f"ä¸»åŠ›é ˜åŸŸ: **{strong}**")

    with c2:
        st.markdown("#### ğŸ’¡ AIææ¡ˆãƒªã‚¹ãƒˆ")

        if df_rec is None or df_rec.empty:
            st.info("ææ¡ˆãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            # è¡¨ç¤ºåˆ—ã‚’å®‰å…¨ã«é¸ã¶
            col_rank = _pick_first_existing_column(df_rec, ["priority_rank", "category_rank", "rank", "priority"])
            col_prod = _pick_first_existing_column(df_rec, ["recommend_product", "product_name", "recommend_name"])
            col_manu = _pick_first_existing_column(df_rec, ["manufacturer", "maker_name", "maker", "maker"])
            col_scale = _pick_first_existing_column(df_rec, ["market_scale", "total_sales", "total_sales_amount", "total_sales_yen"])

            disp_cols = [c for c in [col_rank, col_prod, col_manu, col_scale] if c]
            disp = df_rec[disp_cols].copy()

            rename_map = {}
            if col_rank: rename_map[col_rank] = "é †ä½"
            if col_prod: rename_map[col_prod] = "å•†å“"
            if col_manu: rename_map[col_manu] = "ãƒ¡ãƒ¼ã‚«ãƒ¼"
            if col_scale: rename_map[col_scale] = "è¦æ¨¡"
            disp = disp.rename(columns=rename_map)

            st.dataframe(disp, use_container_width=True, hide_index=True, column_config=create_default_column_config(disp))

    with st.expander("å‚è€ƒ: ç¾åœ¨ã®æ¡ç”¨å“ãƒªã‚¹ãƒˆã‚’è¦‹ã‚‹"):
        # FYã¯å‹•çš„ï¼ˆMAX fiscal_yearï¼‰
        sql_adopted = f"""
        WITH base_stats AS (SELECT MAX(fiscal_year) AS current_fy FROM `{VIEW_FACT_DAILY}`)
        SELECT
          m.product_name,
          SUM(CASE WHEN t.fiscal_year = (SELECT current_fy FROM base_stats) THEN t.sales_amount ELSE 0 END) AS sales_fytd,
          SUM(CASE WHEN t.fiscal_year = (SELECT current_fy FROM base_stats) THEN t.gross_profit ELSE 0 END) AS gp_fytd
        FROM `{VIEW_FACT_DAILY}` t
        LEFT JOIN `{VIEW_ITEM_MASTER}` m
          ON CAST(t.jan AS STRING) = CAST(m.jan_code AS STRING)
        WHERE t.customer_code = @cust_code
        GROUP BY 1
        ORDER BY 2 DESC
        LIMIT 100
        """
        df_adopted = query_df_safe(
            client, sql_adopted, {"cust_code": selected_code},
            "Adopted List",
            use_bqstorage=opts["use_bqstorage"],
            timeout_sec=opts["timeout_sec"],
            cache_key=cache_key,
        )
        if df_adopted.empty:
            st.info("æ¡ç”¨å“ãŒ0ä»¶ã§ã™ã€‚")
        else:
            renamed = df_adopted.rename(columns={"product_name": "å•†å“å", "sales_fytd": "å£²ä¸Š(FY)", "gp_fytd": "ç²—åˆ©(FY)"})
            st.dataframe(renamed, use_container_width=True, hide_index=True, column_config=create_default_column_config(renamed))

# -----------------------------
# 6. Main
# -----------------------------
def main():
    if "org_data_loaded" not in st.session_state:
        st.session_state.org_data_loaded = False

    set_page()

    client, project_id, location, sa_json = setup_bigquery_client()
    cache_key = (project_id, location, sa_json)

    opts = sidebar_controls()
    login_email = get_login_email_ui()

    if not login_email:
        st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã« Login Email ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    st.divider()

    # æ¨©é™è§£æ±ºï¼ˆsales_staff_masterï¼‰
    role = resolve_role(
        client=client,
        cache_key=cache_key,
        login_email=login_email,
        use_bqstorage=opts["use_bqstorage"],
        timeout_sec=opts["timeout_sec"],
    )

    # ãƒ­ã‚°ã‚¤ãƒ³è¡¨ç¤ºï¼ˆåå‰ãƒ»é›»è©±ãƒ»æ¨©é™ï¼‰
    st.write(f"ğŸ‘¤ **æ‹…å½“:** {role.staff_name}")
    st.write(f"ğŸ“§ **Email:** {role.login_email}")
    st.write(f"ğŸ›¡ï¸ **Role:** {role.role_key}")
    st.write(f"ğŸ—ºï¸ **Area:** {role.area_name}")
    phone_tail = str(role.phone).replace("-", "").strip()[-4:] if role.phone else "----"
    st.write(f"ğŸ“ **Phone:** ***-****-{phone_tail}")
    st.divider()

    allow_org_fallback = bool(role.role_admin_view or role.role_key == "HQ_ADMIN")

    if allow_org_fallback:
        tabs = st.tabs(["ğŸ¢ çµ„ç¹”/ã‚¨ãƒªã‚¢çŠ¶æ³", "ğŸ‘¤ å€‹äººæˆç¸¾", "ğŸ¯ æˆ¦ç•¥ææ¡ˆ"])
        with tabs[0]:
            render_fytd_org_section(client, cache_key, role, opts)
        with tabs[1]:
            render_fytd_me_section(client, cache_key, role, opts)
            st.divider()
            render_yoy_section(client, cache_key, role, allow_fallback=True, opts=opts)
        with tabs[2]:
            render_customer_drilldown(client, cache_key, role, opts)
    else:
        tabs = st.tabs(["ğŸ‘¤ ä»Šå¹´ã®æˆç¸¾", "ğŸ“Š å¾—æ„å…ˆåˆ†æ", "ğŸ¯ ææ¡ˆã‚’ä½œã‚‹"])
        with tabs[0]:
            render_fytd_me_section(client, cache_key, role, opts)
        with tabs[1]:
            render_yoy_section(client, cache_key, role, allow_fallback=False, opts=opts)
        with tabs[2]:
            render_customer_drilldown(client, cache_key, role, opts)

    st.caption("â€» VIEWå·®ã—æ›¿ãˆç›´å¾Œã«ã‚ºãƒ¬ã‚‹å ´åˆï¼šClear Cache â†’ å†èª­è¾¼")

if __name__ == "__main__":
    main()
