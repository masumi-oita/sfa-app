# -*- coding: utf-8 -*-
"""
SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - OS v1.4.9 (v1.4.8è¸è¥² + ColMapçµ±åˆãƒ‘ãƒƒãƒ + å®Œå…¨è¸è¥²ç›£æŸ»)

ã€v1.4.8 è¸è¥²ã€‘
- YoYï¼šVIEW_UNIFIED ã‹ã‚‰å‹•çš„é›†è¨ˆã«çµ±ä¸€ï¼ˆYJåŒä¸€ã§å•†å“åãŒ2è¡Œå•é¡Œã‚’æŠ‘æ­¢ï¼‰
- YoYï¼šç¬¬ä¸€éšå±¤ã‚’ã€Œã‚¯ãƒªãƒƒã‚¯é¸æŠã€å¯¾å¿œï¼ˆãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿ã§ã‚‚é¸æŠä¿æŒï¼‰
- ã‚¹ã‚³ãƒ¼ãƒ—ï¼šå¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ—åˆ—å€™è£œã‚’ VIEW_UNIFIED ã®ã‚¹ã‚­ãƒ¼ãƒã‹ã‚‰è‡ªå‹•åˆ¤å®š
- Group Display: officialå…ˆé ­ + rawä½µè¨˜
- æ–°æ©Ÿèƒ½ï¼šå¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ— / å¾—æ„å…ˆå˜ä½“ã®åˆ‡æ›¿ ï¼† å•†å“è¦å› ãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ï¼ˆå…¨ä»¶è¡¨ç¤ºï¼‰
- æ–°æ©Ÿèƒ½ï¼šé †ä½ã‚¢ã‚¤ã‚³ãƒ³ã®è¿½åŠ ã¨ã€ä¸è¦ãªYJã‚³ãƒ¼ãƒ‰åˆ—ã®éè¡¨ç¤º
- ä¿®æ­£ï¼šWHEREäºŒé‡ã‚¨ãƒ©ãƒ¼è§£æ¶ˆ ï¼† é¸æŠçŠ¶æ…‹ã®æ¶ˆå¤±ãƒã‚°è§£æ¶ˆ ï¼† è¡¨ç¤ºé †åºã®æœ€é©åŒ–
- ä¿®æ­£ï¼šRecoï¼ˆVIEW_RECOMMENDï¼‰ã® customer_code ãŒ INT64 ã®ãŸã‚ã€STRINGã‚­ãƒ¼ï¼ˆVIEW_UNIFIEDï¼‰ã¨ç…§åˆã§ãã‚‹ã‚ˆã† CAST å¯¾å¿œ

ã€v1.4.9 è¿½åŠ ã€‘
- ColMapï¼ˆåˆ—åå¸åï¼‰ã‚’å°å…¥ï¼šjan/jan_codeã€pack_unit/package_unit ç­‰ã®å·®ç•°ã‚’è‡ªå‹•è§£æ±º
- å…¨SQLã§ colmap ã‚’è²«é€šï¼šåˆ—åæºã‚Œèµ·å› ã® "Unrecognized name" ã‚’æ ¹çµ¶
- å¿…é ˆåˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€èµ·å‹•ç›´å¾Œã«ã€Œä¸è¶³åˆ—ä¸€è¦§ã€ã‚’æ˜ç¤ºã—ã¦åœæ­¢ï¼ˆæ²ˆé»™ã—ãªã„ï¼‰
- NewDeliveryï¼šVIEW_NEW_DELIVERY ã« customer_name/product_name ãŒç„¡ãã¦ã‚‚ cust_dim/item_dim ã§è£œå®Œã—ç¶™ç¶š
- â˜… å®Œå…¨è¸è¥²ç›£æŸ»ï¼šFeature Manifest + self_auditï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€/æ¬ è½ã‚’èµ·å‹•æ™‚ã«åœæ­¢ï¼‰
"""

from __future__ import annotations

from dataclasses import dataclass
import re
from typing import Any, Dict, Optional, Tuple, Iterable, List

import pandas as pd
import streamlit as st
from google.cloud import bigquery
from google.oauth2 import service_account
from pandas.api.types import is_numeric_dtype


# -----------------------------
# 0. Feature Manifestï¼ˆå®Œå…¨è¸è¥²ã®â€œä»•æ§˜â€ï¼‰
# -----------------------------
FEATURE_MANIFEST = {
    "render_fytd_org_section": {"must_exist": True},
    "render_fytd_me_section": {"must_exist": True},
    "render_scope_filters": {"must_exist": True},
    "render_group_underperformance_section": {"must_exist": True},
    "render_yoy_section": {"must_exist": True},
    "render_new_deliveries_section": {"must_exist": True},
    "render_adoption_alerts_section": {"must_exist": True},
    "render_customer_drilldown": {"must_exist": True},
}

# ã“ã“ã«è©²å½“æ–‡å­—åˆ—ãŒå«ã¾ã‚Œã‚‹é–¢æ•°ã¯ã€Œæœªå®Ÿè£…ï¼è¸è¥²æ¼ã‚Œã€ã¨ã¿ãªã—ã¦åœæ­¢
FORBIDDEN_PLACEHOLDER_SNIPPETS = [
    "ãã®ã¾ã¾é…ç½®ã—ã¦ãã ã•ã„",
    "æœ¬ä½“ã¯çœç•¥",
    "çœç•¥ã›ãšé‹ç”¨ã‚³ãƒ¼ãƒ‰å´ã«å­˜åœ¨ã•ã›ã‚‹",
    "st.info(\"render_",
    "st.info('render_",
]


def self_audit() -> None:
    missing = []
    placeholder = []
    g = globals()

    for fname, rule in FEATURE_MANIFEST.items():
        if rule.get("must_exist") and fname not in g:
            missing.append(fname)
            continue
        fn = g.get(fname)
        if not callable(fn):
            missing.append(fname)
            continue

        # ã‚½ãƒ¼ã‚¹æ¤œæŸ»ï¼ˆStreamlit Cloud ã§ã‚‚å‹•ãç¯„å›²ã§ï¼‰
        try:
            import inspect
            src = inspect.getsource(fn)
            if any(s in src for s in FORBIDDEN_PLACEHOLDER_SNIPPETS):
                placeholder.append(fname)
        except Exception:
            # å–å¾—ä¸èƒ½ã§ã‚‚æ­¢ã‚ãªã„ï¼ˆãŸã ã— missing ã¯æ­¢ã‚ã‚‹ï¼‰
            pass

    if missing:
        st.error("âŒ å®Œå…¨è¸è¥²ç›£æŸ»ï¼šå¿…é ˆé–¢æ•°ãŒæ¬ è½ã—ã¦ã„ã¾ã™ï¼ˆæ©Ÿèƒ½å‰Šé™¤æ‰±ã„ï¼‰")
        st.code("\n".join(missing))
        st.stop()

    if placeholder:
        st.error("âŒ å®Œå…¨è¸è¥²ç›£æŸ»ï¼šãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€å®Ÿè£…ãŒæ®‹ã£ã¦ã„ã¾ã™ï¼ˆè¸è¥²æ¼ã‚Œï¼‰")
        st.code("\n".join(placeholder))
        st.stop()


# -----------------------------
# 1. Configuration (è¨­å®š)
# -----------------------------
APP_TITLE = "SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"
DEFAULT_LOCATION = "asia-northeast1"
PROJECT_DEFAULT = "salesdb-479915"
DATASET_DEFAULT = "sales_data"

VIEW_UNIFIED = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_unified_grouped"
VIEW_ROLE_CLEAN = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.dim_staff_role_clean"
VIEW_NEW_DELIVERY = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_new_deliveries_realized_daily_fact_all_months"
VIEW_RECOMMEND = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_recommendation_engine"
VIEW_ADOPTION = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_customer_adoption_status"

CUSTOMER_GROUP_COLUMN_CANDIDATES = (
    "customer_group_display",
    "customer_group_official",
    "customer_group_raw",
    "sales_group_name",
)


# -----------------------------
# 2. Helpers (è¡¨ç¤ºç”¨)
# -----------------------------
def set_page() -> None:
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)
    st.caption("OS v1.4.9ï½œv1.4.8è¸è¥² + ColMapçµ±åˆ + NewDeliveryåˆ—ä¸è¶³æ ¹æ²» + å®Œå…¨è¸è¥²ç›£æŸ»")


def create_default_column_config(df: pd.DataFrame) -> Dict[str, st.column_config.Column]:
    config: Dict[str, st.column_config.Column] = {}
    for col in df.columns:
        if any(k in col for k in ["å£²ä¸Š", "ç²—åˆ©", "é‡‘é¡", "å·®é¡", "å®Ÿç¸¾", "äºˆæ¸¬", "GAP"]):
            config[col] = st.column_config.NumberColumn(col, format="Â¥%d")
        elif any(k in col for k in ["ç‡", "æ¯”", "ãƒšãƒ¼ã‚¹"]):
            config[col] = st.column_config.NumberColumn(col, format="%.1f%%")
        elif "æ—¥" in col or pd.api.types.is_datetime64_any_dtype(df[col]):
            config[col] = st.column_config.DateColumn(col, format="YYYY-MM-DD")
        elif is_numeric_dtype(df[col]):
            config[col] = st.column_config.NumberColumn(col, format="%d")
        else:
            config[col] = st.column_config.TextColumn(col)
    return config


def get_safe_float(row: pd.Series, key: str) -> float:
    val = row.get(key)
    return float(val) if not pd.isna(val) else 0.0


def normalize_product_display_name(name: Any) -> str:
    if pd.isna(name):
        return ""
    text = str(name).strip()
    text = re.sub(r"[/ï¼].*$", "", text)
    return text.strip()


def _safe_fill_for_display(df: pd.DataFrame, money_cols: Optional[List[str]] = None) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    df = df.copy()
    money_cols = money_cols or []
    for c0 in money_cols:
        if c0 in df.columns:
            df[c0] = pd.to_numeric(df[c0], errors="coerce").fillna(0)
    # æ–‡å­—åˆ—ã ã‘åŸ‹ã‚ã‚‹
    for coln in df.columns:
        if coln in money_cols:
            continue
        if pd.api.types.is_datetime64_any_dtype(df[coln]):
            continue
        if df[coln].dtype == object or pd.api.types.is_string_dtype(df[coln]):
            df[coln] = df[coln].fillna("")
    return df


# -----------------------------
# 3. BigQuery Connection & Auth
# -----------------------------
@st.cache_resource
def setup_bigquery_client() -> bigquery.Client:
    bq = st.secrets["bigquery"]
    sa_info = dict(bq["service_account"])
    scopes = [
        "https://www.googleapis.com/auth/bigquery",
        "https://www.googleapis.com/auth/drive",
        "https://www.googleapis.com/auth/spreadsheets",
    ]
    creds = service_account.Credentials.from_service_account_info(sa_info, scopes=scopes)
    return bigquery.Client(project=PROJECT_DEFAULT, credentials=creds, location=DEFAULT_LOCATION)


def _build_query_parameter(key: str, value: Any) -> bigquery.QueryParameter:
    if isinstance(value, tuple) and len(value) == 2:
        p_type, p_value = value
        p_type = str(p_type).upper()
        if p_type.startswith("ARRAY<") and isinstance(p_value, (list, tuple)):
            return bigquery.ArrayQueryParameter(key, "STRING", list(p_value))
        return bigquery.ScalarQueryParameter(key, p_type, p_value)

    if isinstance(value, (list, tuple)):
        return bigquery.ArrayQueryParameter(key, "STRING", [None if v is None else str(v) for v in value])

    if value is None:
        return bigquery.ScalarQueryParameter(key, "STRING", None)
    if isinstance(value, bool):
        return bigquery.ScalarQueryParameter(key, "BOOL", value)
    if isinstance(value, int):
        return bigquery.ScalarQueryParameter(key, "INT64", value)
    if isinstance(value, float):
        return bigquery.ScalarQueryParameter(key, "FLOAT64", value)
    if isinstance(value, pd.Timestamp):
        return bigquery.ScalarQueryParameter(key, "TIMESTAMP", value.to_pydatetime())

    return bigquery.ScalarQueryParameter(key, "STRING", str(value))


def query_df_safe(
    client: bigquery.Client,
    sql: str,
    params: Optional[Dict[str, Any]] = None,
    label: str = "",
    timeout_sec: int = 60,
) -> pd.DataFrame:
    use_bqstorage = st.session_state.get("use_bqstorage", True)
    try:
        job_config = bigquery.QueryJobConfig()
        if params:
            job_config.query_parameters = [_build_query_parameter(k, v) for k, v in params.items()]
        job = client.query(sql, job_config=job_config)
        job.result(timeout=timeout_sec)
        return job.to_dataframe(create_bqstorage_client=use_bqstorage)
    except Exception as e:
        st.error(f"ã‚¯ã‚¨ãƒªã‚¨ãƒ©ãƒ¼ ({label}):\n{e}")
        return pd.DataFrame()


@dataclass(frozen=True)
class RoleInfo:
    is_authenticated: bool = False
    login_email: str = ""
    staff_name: str = "ã‚²ã‚¹ãƒˆ"
    role_key: str = "GUEST"
    role_admin_view: bool = False
    phone: str = "-"


@dataclass(frozen=True)
class ScopeFilter:
    predicates: tuple[str, ...] = ()
    params: Dict[str, Any] | None = None

    def where_clause(self) -> str:
        if not self.predicates:
            return ""
        return " AND ".join(self.predicates)


def _compose_where(*parts: str) -> str:
    clauses = [p.strip() for p in parts if p and p.strip()]
    if not clauses:
        return ""
    return "WHERE " + " AND ".join(clauses)


def _split_table_fqn(table_fqn: str) -> Tuple[str, str, str]:
    parts = table_fqn.split(".")
    if len(parts) != 3:
        raise ValueError(f"Invalid table FQN: {table_fqn}")
    return parts[0], parts[1], parts[2]


@st.cache_data(ttl=3600)
def role_table_has_login_code(_client: bigquery.Client) -> bool:
    project_id, dataset_id, table_name = _split_table_fqn(VIEW_ROLE_CLEAN)
    sql = f"""
        SELECT 1
        FROM `{project_id}.{dataset_id}.INFORMATION_SCHEMA.COLUMNS`
        WHERE table_name = @table_name
          AND column_name = 'login_code'
        LIMIT 1
    """
    df = query_df_safe(_client, sql, {"table_name": table_name}, "Role Schema Check")
    return not df.empty


# -----------------------------
# â˜… ColMapæ±ç”¨ï¼ˆä»»æ„VIEWã®åˆ—åæºã‚Œå¸åï¼‰
# -----------------------------
@st.cache_data(ttl=3600)
def get_view_columns(_client: bigquery.Client, view_fqn: str) -> set[str]:
    project_id, dataset_id, table_name = _split_table_fqn(view_fqn)
    sql = f"""
        SELECT column_name
        FROM `{project_id}.{dataset_id}.INFORMATION_SCHEMA.COLUMNS`
        WHERE table_name = @table_name
    """
    df = query_df_safe(_client, sql, {"table_name": table_name}, f"Schema Check: {view_fqn}")
    if df.empty or "column_name" not in df.columns:
        return set()
    return {str(c).lower() for c in df["column_name"].dropna().tolist()}


def _pick_from(cols: set[str], *cands: str) -> Optional[str]:
    for c0 in cands:
        if c0 and c0.lower() in cols:
            return c0.lower()
    return None


def resolve_view_colmap(
    _client: bigquery.Client,
    view_fqn: str,
    mapping: Dict[str, Iterable[str]],
    required_keys: Iterable[str],
    optional_mapping: Optional[Dict[str, Iterable[str]]] = None,
) -> Dict[str, str]:
    cols = get_view_columns(_client, view_fqn)
    colmap: Dict[str, Optional[str]] = {}

    for logical_key, cands in mapping.items():
        colmap[logical_key] = _pick_from(cols, *list(cands))

    if optional_mapping:
        for logical_key, cands in optional_mapping.items():
            v = _pick_from(cols, *list(cands))
            if v:
                colmap[logical_key] = v

    missing = [k for k in required_keys if not colmap.get(k)]
    if missing:
        colmap["_missing_required"] = ",".join(missing)

    return {k: v for k, v in colmap.items() if v is not None}


def c(colmap: Dict[str, str], key: str) -> str:
    return colmap.get(key, key)


@st.cache_data(ttl=3600)
def get_unified_columns(_client: bigquery.Client) -> set[str]:
    return get_view_columns(_client, VIEW_UNIFIED)


def get_available_customer_group_columns(_client: bigquery.Client) -> list[str]:
    columns = get_unified_columns(_client)
    return [col for col in CUSTOMER_GROUP_COLUMN_CANDIDATES if col in columns]


def resolve_customer_group_sql_expr(_client: bigquery.Client) -> Tuple[Optional[str], Optional[str]]:
    cols = get_unified_columns(_client)

    has_display = "customer_group_display" in cols
    has_official = "customer_group_official" in cols
    has_raw = "customer_group_raw" in cols
    has_old = "sales_group_name" in cols

    if has_display:
        expr = "COALESCE(NULLIF(CAST(customer_group_display AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.customer_group_display"

    if has_official and has_raw:
        official = "NULLIF(CAST(customer_group_official AS STRING), '')"
        raw = "NULLIF(CAST(customer_group_raw AS STRING), '')"
        expr = f"""
          COALESCE(
            CASE
              WHEN {official} IS NOT NULL AND {raw} IS NOT NULL AND {official} != {raw}
                THEN CONCAT({official}, 'ï¼ˆ', {raw}, 'ï¼‰')
              WHEN {official} IS NOT NULL THEN {official}
              WHEN {raw} IS NOT NULL THEN {raw}
              ELSE NULL
            END,
            'æœªè¨­å®š'
          )
        """
        return " ".join(expr.split()), f"{VIEW_UNIFIED}.customer_group_official + customer_group_raw"

    if has_official:
        expr = "COALESCE(NULLIF(CAST(customer_group_official AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.customer_group_official"

    if has_raw:
        expr = "COALESCE(NULLIF(CAST(customer_group_raw AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.customer_group_raw"

    if has_old:
        expr = "COALESCE(NULLIF(CAST(sales_group_name AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.sales_group_name"

    return None, None


# -----------------------------
# â˜… v1.4.9 ColMap: VIEW_UNIFIED
# -----------------------------
@st.cache_data(ttl=3600)
def resolve_unified_colmap(_client: bigquery.Client) -> Dict[str, str]:
    mapping = {
        "customer_code": ("customer_code", "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", "å¾—æ„å…ˆcd", "å¾—æ„å…ˆCD"),
        "customer_name": ("customer_name", "å¾—æ„å…ˆå"),
        "login_email": ("login_email", "email", "æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«", "æ‹…å½“ãƒ¡ãƒ¼ãƒ«", "login"),
        "sales_date": ("sales_date", "è²©å£²æ—¥", "date"),
        "fiscal_year": ("fiscal_year", "å¹´åº¦", "fy"),
        "sales_amount": ("sales_amount", "å£²ä¸Š", "åˆè¨ˆä¾¡æ ¼", "sales"),
        "gross_profit": ("gross_profit", "ç²—åˆ©", "gp"),
        "product_name": ("product_name", "å•†å“å", "å•†å“åç§°", "item_name"),
        "yj_code": ("yj_code", "yjcode", "yj", "yjcode", "yj_code", "YJCode"),
        "jan_code": ("jan_code", "jan", "JAN"),
        "package_unit": ("package_unit", "pack_unit", "åŒ…è£…å˜ä½", "åŒ…è£…"),
    }
    optional = {"staff_name": ("staff_name", "æ‹…å½“è€…å", "æ‹…å½“ç¤¾å“¡å", "æ‹…å½“ç¤¾å“¡æ°", "æ‹…å½“")}
    required = ("customer_code", "customer_name", "sales_date", "fiscal_year", "sales_amount", "gross_profit", "product_name")
    return resolve_view_colmap(_client, VIEW_UNIFIED, mapping, required, optional)


# -----------------------------
# â˜… v1.4.9 ColMap: VIEW_NEW_DELIVERY
# -----------------------------
@st.cache_data(ttl=3600)
def resolve_new_delivery_colmap(_client: bigquery.Client) -> Dict[str, str]:
    mapping = {
        "first_sales_date": ("first_sales_date", "åˆå›ç´å“æ—¥", "first_date", "date"),
        "customer_code": ("customer_code", "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", "å¾—æ„å…ˆcd", "å¾—æ„å…ˆCD"),
        "customer_name": ("customer_name", "å¾—æ„å…ˆå", "cust_name", "customer"),
        "jan_code": ("jan_code", "jan", "JAN"),
        "product_name": ("product_name", "item_name", "å•†å“å", "å•†å“åç§°", "å“ç›®å", "drug_name"),
        "sales_amount": ("sales_amount", "å£²ä¸Š", "sales"),
        "gross_profit": ("gross_profit", "ç²—åˆ©", "gp"),
        "login_email": ("login_email", "email", "æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«", "æ‹…å½“ãƒ¡ãƒ¼ãƒ«"),
        "staff_name": ("staff_name", "æ‹…å½“è€…å", "æ‹…å½“ç¤¾å“¡å", "æ‹…å½“"),
    }
    required = ("first_sales_date", "customer_code", "jan_code", "sales_amount", "gross_profit")
    optional = {
        "customer_name": ("customer_name", "å¾—æ„å…ˆå", "cust_name", "customer"),
        "product_name": ("product_name", "item_name", "å•†å“å", "å•†å“åç§°", "å“ç›®å", "drug_name"),
        "login_email": ("login_email", "email", "æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«", "æ‹…å½“ãƒ¡ãƒ¼ãƒ«"),
        "staff_name": ("staff_name", "æ‹…å½“è€…å", "æ‹…å½“ç¤¾å“¡å", "æ‹…å½“"),
    }
    return resolve_view_colmap(_client, VIEW_NEW_DELIVERY, mapping, required, optional)


# -----------------------------
# ã‚¹ã‚³ãƒ¼ãƒ—
# -----------------------------
def render_scope_filters(client: bigquery.Client, role: RoleInfo) -> ScopeFilter:
    st.markdown("### ğŸ” åˆ†æã‚¹ã‚³ãƒ¼ãƒ—è¨­å®š")
    predicates: list[str] = []
    params: Dict[str, Any] = {}

    with st.expander("è©³ç´°çµã‚Šè¾¼ã¿ï¼ˆå¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ—ãƒ»å¾—æ„å…ˆåï¼‰", expanded=False):
        c1, c2 = st.columns(2)

        group_expr, group_src = resolve_customer_group_sql_expr(client)
        if group_expr:
            role_where = ""
            role_params: Dict[str, Any] = {}
            if not role.role_admin_view:
                role_where = "WHERE login_email = @login_email"
                role_params["login_email"] = role.login_email

            sql_group = f"""
                SELECT DISTINCT {group_expr} AS group_name
                FROM `{VIEW_UNIFIED}`
                {role_where}
                ORDER BY group_name
                LIMIT 500
            """
            df_group = query_df_safe(client, sql_group, role_params, "Scope Group Options")
            group_opts = ["æŒ‡å®šãªã—"] + (df_group["group_name"].tolist() if not df_group.empty else [])
            selected_group = c1.selectbox("å¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ—", options=group_opts, key="scope_group_select")
            if selected_group != "æŒ‡å®šãªã—":
                predicates.append(f"{group_expr} = @scope_group")
                params["scope_group"] = selected_group

            if group_src:
                c1.caption(f"æŠ½å‡ºå…ƒ: `{group_src}`")
        else:
            c1.caption("ã‚°ãƒ«ãƒ¼ãƒ—åˆ—ãªã—ï¼ˆVIEW_UNIFIEDã«è©²å½“åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼‰")

        keyword = c2.text_input("å¾—æ„å…ˆåï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", placeholder="ä¾‹ï¼šå¤è³€ç—…é™¢", key="scope_customer_kw")
        if keyword.strip():
            # â€»ã“ã“ã¯VIEW_UNIFIEDå‰æï¼ˆå¾Œæ®µã§ colmap ç½®æ›ã—ã¦å®‰å…¨åŒ–ï¼‰
            predicates.append("customer_name LIKE @scope_customer_name")
            params["scope_customer_name"] = f"%{keyword.strip()}%"

    return ScopeFilter(predicates=tuple(predicates), params=params)


def resolve_role(client: bigquery.Client, login_email: str, login_code: str) -> RoleInfo:
    if not login_email or not login_code:
        return RoleInfo()

    has_login_code = role_table_has_login_code(client)

    if has_login_code:
        sql = f"""
            SELECT login_email, role_tier
            FROM `{VIEW_ROLE_CLEAN}`
            WHERE login_email = @login_email
              AND CAST(login_code AS STRING) = @login_code
            LIMIT 1
        """
        params: Dict[str, Any] = {"login_email": login_email, "login_code": login_code}
    else:
        sql = f"""
            SELECT login_email, role_tier
            FROM `{VIEW_ROLE_CLEAN}`
            WHERE login_email = @login_email
            LIMIT 1
        """
        params = {"login_email": login_email}

    df = query_df_safe(client, sql, params, "Auth Check")
    if df.empty:
        return RoleInfo(login_email=login_email)

    row = df.iloc[0]
    raw_role = str(row["role_tier"]).strip().upper()
    is_admin = any(x in raw_role for x in ["ADMIN", "MANAGER", "HQ"])

    return RoleInfo(
        is_authenticated=True,
        login_email=login_email,
        staff_name=login_email.split("@")[0],
        role_key="HQ_ADMIN" if is_admin else "SALES",
        role_admin_view=is_admin,
        phone="-",
    )


# -----------------------------
# 4. FYTD
# -----------------------------
def render_summary_metrics(row: pd.Series) -> None:
    s_cur = get_safe_float(row, "sales_amount_fytd")
    s_py_ytd = get_safe_float(row, "sales_amount_py_ytd")
    s_py_total = get_safe_float(row, "sales_amount_py_total")
    s_fc = s_cur * (s_py_total / s_py_ytd) if s_py_ytd > 0 else s_cur

    gp_cur = get_safe_float(row, "gross_profit_fytd")
    gp_py_ytd = get_safe_float(row, "gross_profit_py_ytd")
    gp_py_total = get_safe_float(row, "gross_profit_py_total")
    gp_fc = gp_cur * (gp_py_total / gp_py_ytd) if gp_py_ytd > 0 else gp_cur

    st.caption("â€» ã€ä»ŠæœŸäºˆæ¸¬ã€‘ã¯ã€Œä»ŠæœŸå®Ÿç¸¾ Ã— (æ˜¨å¹´åº¦ç€åœ° Ã· å‰å¹´åŒæœŸ)ã€ã«ã‚ˆã‚‹å­£ç¯€å¤‰å‹•ã‚’åŠ å‘³ã—ãŸæ¨ç§»ãƒšãƒ¼ã‚¹ï¼ˆç€åœ°è¦‹è¾¼ï¼‰ã§ã™ã€‚")

    st.markdown("##### â–  å£²ä¸Š")
    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("â‘  ä»ŠæœŸç´¯è¨ˆ", f"Â¥{s_cur:,.0f}")
    c2.metric("â‘¡ å‰å¹´åŒæœŸ", f"Â¥{s_py_ytd:,.0f}", delta=f"{int(s_cur - s_py_ytd):,}" if s_py_ytd > 0 else None)
    c3.metric("â‘¢ æ˜¨å¹´åº¦ç€åœ°", f"Â¥{s_py_total:,.0f}")
    c4.metric("â‘£ ä»ŠæœŸäºˆæ¸¬", f"Â¥{s_fc:,.0f}")
    c5.metric("â‘¤ ç€åœ°GAP", f"Â¥{s_fc - s_py_total:,.0f}", delta=f"{int(s_fc - s_py_total):,}")

    st.markdown("##### â–  ç²—åˆ©")
    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("â‘  ä»ŠæœŸç´¯è¨ˆ", f"Â¥{gp_cur:,.0f}")
    c2.metric("â‘¡ å‰å¹´åŒæœŸ", f"Â¥{gp_py_ytd:,.0f}", delta=f"{int(gp_cur - gp_py_ytd):,}" if gp_py_ytd > 0 else None)
    c3.metric("â‘¢ æ˜¨å¹´åº¦ç€åœ°", f"Â¥{gp_py_total:,.0f}")
    c4.metric("â‘£ ä»ŠæœŸäºˆæ¸¬", f"Â¥{gp_fc:,.0f}")
    c5.metric("â‘¤ ç€åœ°GAP", f"Â¥{gp_fc - gp_py_total:,.0f}", delta=f"{int(gp_fc - gp_py_total):,}")


def render_fytd_org_section(client: bigquery.Client, colmap: Dict[str, str]) -> None:
    st.subheader("ğŸ¢ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå…¨ç¤¾ã‚µãƒãƒªãƒ¼")

    if "org_data_loaded" not in st.session_state:
        st.session_state.org_data_loaded = False

    if st.button("å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_org_load"):
        st.session_state.org_data_loaded = True

    if st.session_state.get("org_data_loaded"):
        sql = f"""
            WITH today_info AS (
              SELECT
                CURRENT_DATE('Asia/Tokyo') AS today,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today,
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                    - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
            )
            SELECT
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_fytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_fytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_py_ytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_py_ytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_py_total,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_py_total
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN today_info
        """
        df_org = query_df_safe(client, sql, None, "Org Summary")
        if not df_org.empty:
            render_summary_metrics(df_org.iloc[0])


def render_fytd_me_section(client: bigquery.Client, login_email: str, colmap: Dict[str, str]) -> None:
    st.subheader("ğŸ‘¤ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå€‹äººã‚µãƒãƒªãƒ¼")
    if st.button("è‡ªåˆ†ã®æˆç¸¾ã‚’èª­ã¿è¾¼ã‚€", key="btn_me_load"):
        sql = f"""
            WITH today_info AS (
              SELECT
                CURRENT_DATE('Asia/Tokyo') AS today,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today,
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                    - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
            )
            SELECT
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_fytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_fytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_py_ytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_py_ytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_py_total,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_py_total
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN today_info
            WHERE {c(colmap,'login_email')} = @login_email
        """
        df_me = query_df_safe(client, sql, {"login_email": login_email}, "Me Summary")
        if not df_me.empty:
            render_summary_metrics(df_me.iloc[0])


# -----------------------------
# å¾—æ„å…ˆãƒ»ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ï¼† è¦å› åˆ†æï¼ˆäº‹æ•…æ··å…¥ã‚’æ ¹æ²»ï¼‰
# -----------------------------
def render_group_underperformance_section(
    client: bigquery.Client,
    role: RoleInfo,
    scope: ScopeFilter,
    colmap: Dict[str, str],
) -> None:
    st.subheader("ğŸ¢ å¾—æ„å…ˆãƒ»ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ï¼† è¦å› åˆ†æ")

    c1_, c2_ = st.columns(2)
    view_choice = c1_.radio("ğŸ“Š åˆ†æã®å˜ä½", ["ğŸ¢ ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥", "ğŸ¥ å¾—æ„å…ˆå˜ä½“"], horizontal=True, key="gp_view_choice")
    mode_choice = c2_.radio("ğŸ† ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŸºæº–", ["ğŸ“‰ ä¸‹è½å¹…ãƒ¯ãƒ¼ã‚¹ãƒˆ", "ğŸ“ˆ ä¸Šæ˜‡å¹…ãƒ™ã‚¹ãƒˆ"], horizontal=True, key="gp_mode_choice")

    perf_view = "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" if "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" in view_choice else "å¾—æ„å…ˆåˆ¥"
    perf_mode = "ãƒ¯ãƒ¼ã‚¹ãƒˆ" if "ãƒ¯ãƒ¼ã‚¹ãƒˆ" in mode_choice else "ãƒ™ã‚¹ãƒˆ"
    sort_order = "ASC" if perf_mode == "ãƒ¯ãƒ¼ã‚¹ãƒˆ" else "DESC"

    group_expr, group_src = resolve_customer_group_sql_expr(client)
    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" and not group_expr:
        st.info("ã‚°ãƒ«ãƒ¼ãƒ—åˆ†æã«åˆ©ç”¨ã§ãã‚‹åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆVIEW_UNIFIEDã«ã‚°ãƒ«ãƒ¼ãƒ—åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚")
        return

    role_filter = "" if role.role_admin_view else f"{c(colmap,'login_email')} = @login_email"
    scope_filter_clause = scope.where_clause().replace("customer_name", c(colmap, "customer_name"))
    filter_sql = _compose_where(role_filter, scope_filter_clause)

    params: Dict[str, Any] = dict(scope.params or {})
    if not role.role_admin_view:
        params["login_email"] = role.login_email

    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥":
        sql_parent = f"""
            WITH fy AS (
              SELECT
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                 - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
            )
            SELECT
              {group_expr} AS name_key,
              {group_expr} AS `åç§°`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS `ä»ŠæœŸå£²ä¸Š`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'sales_amount')} ELSE 0 END) AS `å‰å¹´åŒæœŸå£²ä¸Š`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'gross_profit')} ELSE 0 END) AS `ä»ŠæœŸç²—åˆ©`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'gross_profit')} ELSE 0 END) AS `å‰å¹´åŒæœŸç²—åˆ©`
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN fy
            {filter_sql}
            GROUP BY name_key, `åç§°`
            HAVING `å‰å¹´åŒæœŸå£²ä¸Š` > 0 OR `ä»ŠæœŸå£²ä¸Š` > 0
            ORDER BY (`ä»ŠæœŸå£²ä¸Š` - `å‰å¹´åŒæœŸå£²ä¸Š`) {sort_order}
            LIMIT 50
        """
    else:
        sql_parent = f"""
            WITH fy AS (
              SELECT
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                 - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
            )
            SELECT
              CAST({c(colmap,'customer_code')} AS STRING) AS name_key,
              CAST({c(colmap,'customer_code')} AS STRING) AS `ã‚³ãƒ¼ãƒ‰`,
              ANY_VALUE({c(colmap,'customer_name')}) AS `åç§°`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS `ä»ŠæœŸå£²ä¸Š`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'sales_amount')} ELSE 0 END) AS `å‰å¹´åŒæœŸå£²ä¸Š`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'gross_profit')} ELSE 0 END) AS `ä»ŠæœŸç²—åˆ©`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'gross_profit')} ELSE 0 END) AS `å‰å¹´åŒæœŸç²—åˆ©`
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN fy
            {filter_sql}
            GROUP BY name_key, `ã‚³ãƒ¼ãƒ‰`
            HAVING `å‰å¹´åŒæœŸå£²ä¸Š` > 0 OR `ä»ŠæœŸå£²ä¸Š` > 0
            ORDER BY (`ä»ŠæœŸå£²ä¸Š` - `å‰å¹´åŒæœŸå£²ä¸Š`) {sort_order}
            LIMIT 50
        """

    df_parent = query_df_safe(client, sql_parent, params, f"Parent Perf {perf_view}")
    if df_parent.empty:
        st.info("è¡¨ç¤ºã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df_parent = df_parent.copy()
    df_parent["å£²ä¸Šå·®é¡"] = df_parent["ä»ŠæœŸå£²ä¸Š"] - df_parent["å‰å¹´åŒæœŸå£²ä¸Š"]
    df_parent["å£²ä¸Šæˆé•·ç‡"] = df_parent.apply(
        lambda r: ((r["ä»ŠæœŸå£²ä¸Š"] / r["å‰å¹´åŒæœŸå£²ä¸Š"] - 1) * 100) if r["å‰å¹´åŒæœŸå£²ä¸Š"] else 0,
        axis=1,
    )
    df_parent["ç²—åˆ©å·®é¡"] = df_parent["ä»ŠæœŸç²—åˆ©"] - df_parent["å‰å¹´åŒæœŸç²—åˆ©"]

    def rank_icon(rank: int, mode: str) -> str:
        if mode == "ãƒ™ã‚¹ãƒˆ":
            return "ğŸ¥‡ 1ä½" if rank == 1 else ("ğŸ¥ˆ 2ä½" if rank == 2 else ("ğŸ¥‰ 3ä½" if rank == 3 else f"ğŸŒŸ {rank}ä½"))
        return "ğŸš¨ 1ä½" if rank == 1 else ("âš ï¸ 2ä½" if rank == 2 else ("âš¡ 3ä½" if rank == 3 else f"ğŸ“‰ {rank}ä½"))

    df_parent.insert(0, "é †ä½", [rank_icon(i + 1, perf_mode) for i in range(len(df_parent))])

    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" and group_src:
        st.caption(f"æŠ½å‡ºå…ƒã‚°ãƒ«ãƒ¼ãƒ—åˆ—: `{group_src}`")

    # --- è¦ªãƒ†ãƒ¼ãƒ–ãƒ«ï¼šâ˜‘ã§è¦å› æ˜ç´°
    show_cols = ["é †ä½", "åç§°", "ä»ŠæœŸå£²ä¸Š", "å‰å¹´åŒæœŸå£²ä¸Š", "å£²ä¸Šå·®é¡", "å£²ä¸Šæˆé•·ç‡", "ä»ŠæœŸç²—åˆ©", "å‰å¹´åŒæœŸç²—åˆ©", "ç²—åˆ©å·®é¡"]
    if perf_view != "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥":
        show_cols = ["é †ä½", "ã‚³ãƒ¼ãƒ‰"] + show_cols  # å¾—æ„å…ˆå˜ä½“ã¯ã‚³ãƒ¼ãƒ‰ä»˜ã

    df_show = df_parent.copy()
    df_show.insert(0, "â˜‘", False)

    edited = st.data_editor(
        _safe_fill_for_display(df_show[["â˜‘"] + show_cols], money_cols=["ä»ŠæœŸå£²ä¸Š", "å‰å¹´åŒæœŸå£²ä¸Š", "å£²ä¸Šå·®é¡", "ä»ŠæœŸç²—åˆ©", "å‰å¹´åŒæœŸç²—åˆ©", "ç²—åˆ©å·®é¡"]),
        use_container_width=True,
        hide_index=True,
        disabled=[c0 for c0 in (["â˜‘"] + show_cols) if c0 != "â˜‘"],
        column_config={"â˜‘": st.column_config.CheckboxColumn("è¦å› è¡¨ç¤º", help="è¦å› ï¼ˆå•†å“ï¼‰ãƒ‰ãƒªãƒ«ã‚’è¡¨ç¤ºã—ãŸã„è¡Œã‚’é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰")},
        key=f"gp_parent_editor_{perf_view}_{perf_mode}",
    )

    sel = edited[edited["â˜‘"] == True]
    if sel.empty:
        st.caption("â˜‘ã«ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã¨ã€ä¸‹ã«ã€å•†å“è¦å› ãƒ‰ãƒªãƒ«ã€ãŒå‡ºã¾ã™ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰ã€‚")
        return

    selected_keys = sel["åç§°"].astype(str).tolist() if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" else sel["ã‚³ãƒ¼ãƒ‰"].astype(str).tolist()

    st.divider()
    st.markdown("#### ğŸ§© å•†å“è¦å› ãƒ‰ãƒªãƒ«ï¼ˆå£²ä¸ŠYoYå·®é¡ï¼‰")

    # ãƒ‰ãƒªãƒ«ç”¨WHERE
    base_role = "" if role.role_admin_view else f"{c(colmap,'login_email')} = @login_email"
    base_scope = scope.where_clause().replace("customer_name", c(colmap, "customer_name"))
    base_where = _compose_where(base_role, base_scope)

    drill_params: Dict[str, Any] = dict(scope.params or {})
    if not role.role_admin_view:
        drill_params["login_email"] = role.login_email

    # è¦ªã‚­ãƒ¼æ¡ä»¶
    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥":
        drill_params["parent_keys"] = selected_keys
        parent_filter = f"AND {group_expr} IN UNNEST(@parent_keys)"
    else:
        drill_params["parent_keys"] = selected_keys
        parent_filter = f"AND CAST({c(colmap,'customer_code')} AS STRING) IN UNNEST(@parent_keys)"

    sql_drill = f"""
        WITH fy AS (
          SELECT (
            EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
            - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END
          ) AS current_fy,
          DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
        ),
        base_raw AS (
          SELECT
            COALESCE(
              NULLIF(NULLIF(TRIM(CAST({c(colmap,'yj_code')} AS STRING)), ''), '0'),
              NULLIF(NULLIF(TRIM(CAST({c(colmap,'jan_code')} AS STRING)), ''), '0'),
              TRIM(CAST({c(colmap,'product_name')} AS STRING))
            ) AS yj_key,
            REGEXP_REPLACE(CAST({c(colmap,'product_name')} AS STRING), r"[/ï¼].*$", "") AS product_base,
            SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS ty_sales,
            SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'sales_amount')} ELSE 0 END) AS py_sales
          FROM `{VIEW_UNIFIED}`
          CROSS JOIN fy
          {base_where}
          {parent_filter}
          GROUP BY yj_key, product_base
        ),
        base AS (
          SELECT
            yj_key AS yj_code,
            ARRAY_AGG(product_base ORDER BY ty_sales DESC LIMIT 1)[OFFSET(0)] AS product_name,
            SUM(ty_sales) AS ty_sales,
            SUM(py_sales) AS py_sales
          FROM base_raw
          GROUP BY yj_code
        )
        SELECT
          yj_code,
          product_name,
          ty_sales AS sales_amount,
          py_sales AS py_sales_amount,
          (ty_sales - py_sales) AS sales_diff_yoy
        FROM base
        WHERE ty_sales > 0 OR py_sales > 0
        ORDER BY sales_diff_yoy {sort_order}
        LIMIT 500
    """
    df_drill = query_df_safe(client, sql_drill, drill_params, "Parent Drilldown")
    if df_drill.empty:
        st.info("è¦å› ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    df_drill = df_drill.copy()
    df_drill["product_name"] = df_drill["product_name"].apply(normalize_product_display_name)
    df_drill.insert(0, "è¦å› é †ä½", [rank_icon(i + 1, perf_mode) for i in range(len(df_drill))])

    st.dataframe(
        _safe_fill_for_display(
            df_drill[["è¦å› é †ä½", "product_name", "sales_amount", "py_sales_amount", "sales_diff_yoy"]].rename(
                columns={
                    "product_name": "ä»£è¡¨å•†å“å(æˆåˆ†)",
                    "sales_amount": "ä»ŠæœŸå£²ä¸Š",
                    "py_sales_amount": "å‰å¹´åŒæœŸå£²ä¸Š",
                    "sales_diff_yoy": "å‰å¹´æ¯”å·®é¡",
                }
            ),
            money_cols=["ä»ŠæœŸå£²ä¸Š", "å‰å¹´åŒæœŸå£²ä¸Š", "å‰å¹´æ¯”å·®é¡"],
        ).style.format({"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´åŒæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´æ¯”å·®é¡": "Â¥{:,.0f}"}),
        use_container_width=True,
        hide_index=True,
    )


# -----------------------------
# YoYï¼ˆæœ€ä½é™ã§ã‚‚â€œå‹•ãâ€ï¼è¸è¥²æ¼ã‚Œåœæ­¢ã‚’å›é¿ï¼‰
# -----------------------------
def render_yoy_section(client: bigquery.Client, login_email: str, is_admin: bool, scope: ScopeFilter, colmap: Dict[str, str]) -> None:
    st.subheader("ğŸ“‰ YoY ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä»ŠæœŸ vs å‰å¹´åŒæœŸï¼‰")

    c1, c2, c3 = st.columns(3)
    unit = c1.radio("é›†è¨ˆå˜ä½", ["ğŸ’Š å•†å“ï¼ˆæˆåˆ†ï¼‰", "ğŸ¥ å¾—æ„å…ˆ"], horizontal=True, key="yoy_unit")
    metric = c2.radio("æŒ‡æ¨™", ["å£²ä¸Š", "ç²—åˆ©"], horizontal=True, key="yoy_metric")
    topk = c3.slider("è¡¨ç¤ºä»¶æ•°", 10, 200, 50, 10, key="yoy_topk")

    sort_order = "ASC" if st.toggle("ãƒ¯ãƒ¼ã‚¹ãƒˆï¼ˆä¸‹è½ï¼‰ã‚’å„ªå…ˆ", value=True, key="yoy_worst") else "DESC"
    val_col = c(colmap, "sales_amount") if metric == "å£²ä¸Š" else c(colmap, "gross_profit")

    role_filter = "" if is_admin else f"{c(colmap,'login_email')} = @login_email"
    scope_filter_clause = scope.where_clause().replace("customer_name", c(colmap, "customer_name"))
    where_sql = _compose_where(role_filter, scope_filter_clause)

    params: Dict[str, Any] = dict(scope.params or {})
    if not is_admin:
        params["login_email"] = login_email

    if unit.startswith("ğŸ’Š"):
        key_expr = f"""
          COALESCE(
            NULLIF(NULLIF(TRIM(CAST({c(colmap,'yj_code')} AS STRING)), ''), '0'),
            NULLIF(NULLIF(TRIM(CAST({c(colmap,'jan_code')} AS STRING)), ''), '0'),
            TRIM(CAST({c(colmap,'product_name')} AS STRING))
          )
        """
        name_expr = f"REGEXP_REPLACE(CAST({c(colmap,'product_name')} AS STRING), r\"[/ï¼].*$\", \"\")"
        group_by = "yj_key"
        select_key = "yj_key"
        select_name = "product_name"
        extra_cols = ""
    else:
        key_expr = f"CAST({c(colmap,'customer_code')} AS STRING)"
        name_expr = f"ANY_VALUE(CAST({c(colmap,'customer_name')} AS STRING))"
        group_by = "customer_code"
        select_key = "customer_code"
        select_name = "customer_name"
        extra_cols = ""

    sql = f"""
      WITH fy AS (
        SELECT
          (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
            - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy,
          DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
      ),
      base AS (
        SELECT
          {key_expr} AS {select_key},
          {name_expr} AS {select_name},
          SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {val_col} ELSE 0 END) AS ty_value,
          SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {val_col} ELSE 0 END) AS py_value
        FROM `{VIEW_UNIFIED}`
        CROSS JOIN fy
        {where_sql}
        GROUP BY {group_by}
      )
      SELECT
        {select_key} AS key_id,
        {select_name} AS name,
        ty_value AS ty,
        py_value AS py,
        (ty_value - py_value) AS diff
      FROM base
      WHERE ty_value > 0 OR py_value > 0
      ORDER BY diff {sort_order}
      LIMIT {topk}
    """
    df = query_df_safe(client, sql, params, "YoY")
    if df.empty:
        st.info("è©²å½“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df = df.copy()
    df["name"] = df["name"].apply(normalize_product_display_name) if unit.startswith("ğŸ’Š") else df["name"]
    df.insert(0, "é †ä½", [f"{i+1}" for i in range(len(df))])

    show = df.rename(columns={"name": "åç§°", "ty": "ä»ŠæœŸ", "py": "å‰å¹´åŒæœŸ", "diff": "å·®é¡"})
    money_cols = ["ä»ŠæœŸ", "å‰å¹´åŒæœŸ", "å·®é¡"]

    st.dataframe(
        _safe_fill_for_display(show[["é †ä½", "åç§°", "ä»ŠæœŸ", "å‰å¹´åŒæœŸ", "å·®é¡"]], money_cols=money_cols).style.format(
            {"ä»ŠæœŸ": "Â¥{:,.0f}", "å‰å¹´åŒæœŸ": "Â¥{:,.0f}", "å·®é¡": "Â¥{:,.0f}"}
        ),
        use_container_width=True,
        hide_index=True,
    )


# -----------------------------
# â˜… New Delivery Trendsï¼ˆã‚ãªãŸã®æ ¹æ²»ç‰ˆã‚’è¸è¥²ï¼‰
# -----------------------------
def render_new_delivery_trends(
    client: bigquery.Client,
    login_email: str,
    is_admin: bool,
    nd_colmap: Dict[str, str],
    unified_colmap: Dict[str, str],
) -> None:
    st.markdown("##### ğŸ“ˆ æ–°è¦ç´å“ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆã‚°ãƒ«ãƒ¼ãƒ— / å¾—æ„å…ˆ / å•†å“ï¼‰")

    missing_required = nd_colmap.get("_missing_required")
    if missing_required:
        st.error("VIEW_NEW_DELIVERY ã®å¿…é ˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚VIEWå®šç¾©ï¼ˆåˆ—åï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.code(f"ä¸è¶³ã‚­ãƒ¼: {missing_required}")
        st.stop()

    if (not is_admin) and (c(nd_colmap, "login_email") == "login_email"):
        st.error("VIEW_NEW_DELIVERY ã« login_email åˆ—ãŒç„¡ã„ãŸã‚ã€æ‹…å½“è€…ã‚¹ã‚³ãƒ¼ãƒ—çµã‚Šè¾¼ã¿ãŒã§ãã¾ã›ã‚“ã€‚")
        st.stop()

    if "nd_trend_days" not in st.session_state:
        st.session_state.nd_trend_days = 60
    if "nd_trend_mode" not in st.session_state:
        st.session_state.nd_trend_mode = "ğŸ¢ ã‚°ãƒ«ãƒ¼ãƒ—"

    days = st.slider("å¯¾è±¡æœŸé–“ï¼ˆæ—¥ï¼‰", 7, 180, st.session_state.nd_trend_days, 1, key="nd_trend_days")
    mode = st.radio("è¡¨ç¤ºå˜ä½", ["ğŸ¢ ã‚°ãƒ«ãƒ¼ãƒ—", "ğŸ¥ å¾—æ„å…ˆ", "ğŸ’Š å•†å“"], horizontal=True, key="nd_trend_mode")

    where_ext = "" if is_admin else f"AND nd.{c(nd_colmap,'login_email')} = @login_email"
    base_params = None if is_admin else {"login_email": login_email}

    group_expr, _ = resolve_customer_group_sql_expr(client)

    if group_expr:
        cust_dim_sql = f"""
          SELECT
            CAST({c(unified_colmap,'customer_code')} AS STRING) AS customer_code,
            ANY_VALUE(CAST({c(unified_colmap,'customer_name')} AS STRING)) AS customer_name,
            ANY_VALUE({group_expr}) AS group_name
          FROM `{VIEW_UNIFIED}`
          GROUP BY customer_code
        """
    else:
        cust_dim_sql = f"""
          SELECT
            CAST({c(unified_colmap,'customer_code')} AS STRING) AS customer_code,
            ANY_VALUE(CAST({c(unified_colmap,'customer_name')} AS STRING)) AS customer_name,
            'æœªè¨­å®š' AS group_name
          FROM `{VIEW_UNIFIED}`
          GROUP BY customer_code
        """

    unified_has_jan = c(unified_colmap, "jan_code") != "jan_code"
    nd_has_pname = c(nd_colmap, "product_name") != "product_name"

    if unified_has_jan:
        item_dim_sql = f"""
          SELECT
            CAST({c(unified_colmap,'jan_code')} AS STRING) AS jan_code,
            ANY_VALUE(REGEXP_REPLACE(CAST({c(unified_colmap,'product_name')} AS STRING), r"[/ï¼].*$", "")) AS product_name
          FROM `{VIEW_UNIFIED}`
          GROUP BY jan_code
        """
    elif nd_has_pname:
        item_dim_sql = f"""
          SELECT
            CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) AS jan_code,
            ANY_VALUE(REGEXP_REPLACE(CAST(nd.{c(nd_colmap,'product_name')} AS STRING), r"[/ï¼].*$", "")) AS product_name
          FROM `{VIEW_NEW_DELIVERY}` nd
          GROUP BY jan_code
        """
    else:
        item_dim_sql = f"""
          SELECT
            CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) AS jan_code,
            'ä¸æ˜' AS product_name
          FROM `{VIEW_NEW_DELIVERY}` nd
          GROUP BY jan_code
        """

    if mode.startswith("ğŸ¢"):
        sql_parent = f"""
          WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today),
          cust_dim AS ({cust_dim_sql})
          SELECT
            COALESCE(cd.group_name, 'æœªè¨­å®š') AS group_name,
            COUNT(DISTINCT CAST(nd.{c(nd_colmap,'customer_code')} AS STRING)) AS customer_cnt,
            COUNT(DISTINCT CAST(nd.{c(nd_colmap,'jan_code')} AS STRING)) AS item_cnt,
            SUM(nd.{c(nd_colmap,'sales_amount')}) AS sales_amount,
            SUM(nd.{c(nd_colmap,'gross_profit')}) AS gross_profit
          FROM `{VIEW_NEW_DELIVERY}` nd
          CROSS JOIN td
          LEFT JOIN cust_dim cd
            ON CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) = cd.customer_code
          WHERE nd.{c(nd_colmap,'first_sales_date')} >= DATE_SUB(today, INTERVAL {days} DAY)
            {where_ext}
          GROUP BY group_name
          ORDER BY sales_amount DESC
          LIMIT 200
        """
        df_parent = query_df_safe(client, sql_parent, base_params, label="New Delivery Trend Groups")
        key_col = "group_name"
        title = "ğŸ¢ ã‚°ãƒ«ãƒ¼ãƒ—ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæ–°è¦ç´å“ï¼‰"

    elif mode.startswith("ğŸ¥"):
        sql_parent = f"""
          WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today),
          cust_dim AS ({cust_dim_sql})
          SELECT
            CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) AS customer_code,
            ANY_VALUE(cd.customer_name) AS customer_name,
            ANY_VALUE(COALESCE(cd.group_name, 'æœªè¨­å®š')) AS group_name,
            COUNT(DISTINCT CAST(nd.{c(nd_colmap,'jan_code')} AS STRING)) AS item_cnt,
            SUM(nd.{c(nd_colmap,'sales_amount')}) AS sales_amount,
            SUM(nd.{c(nd_colmap,'gross_profit')}) AS gross_profit
          FROM `{VIEW_NEW_DELIVERY}` nd
          CROSS JOIN td
          LEFT JOIN cust_dim cd
            ON CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) = cd.customer_code
          WHERE nd.{c(nd_colmap,'first_sales_date')} >= DATE_SUB(today, INTERVAL {days} DAY)
            {where_ext}
          GROUP BY customer_code
          ORDER BY sales_amount DESC
          LIMIT 200
        """
        df_parent = query_df_safe(client, sql_parent, base_params, label="New Delivery Trend Customers")
        key_col = "customer_code"
        title = "ğŸ¥ å¾—æ„å…ˆãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæ–°è¦ç´å“ï¼‰"

    else:
        sql_parent = f"""
          WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today),
          item_dim AS ({item_dim_sql})
          SELECT
            CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) AS jan_code,
            ANY_VALUE(id.product_name) AS product_name,
            COUNT(DISTINCT CAST(nd.{c(nd_colmap,'customer_code')} AS STRING)) AS customer_cnt,
            SUM(nd.{c(nd_colmap,'sales_amount')}) AS sales_amount,
            SUM(nd.{c(nd_colmap,'gross_profit')}) AS gross_profit
          FROM `{VIEW_NEW_DELIVERY}` nd
          CROSS JOIN td
          LEFT JOIN item_dim id
            ON CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) = id.jan_code
          WHERE nd.{c(nd_colmap,'first_sales_date')} >= DATE_SUB(today, INTERVAL {days} DAY)
            {where_ext}
          GROUP BY jan_code
          ORDER BY sales_amount DESC
          LIMIT 200
        """
        df_parent = query_df_safe(client, sql_parent, base_params, label="New Delivery Trend Products")
        key_col = "jan_code"
        title = "ğŸ’Š å•†å“ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæ–°è¦ç´å“ï¼‰"

    st.markdown(f"**{title}**")
    if df_parent.empty:
        st.info("è©²å½“æœŸé–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df_show = df_parent.copy()
    df_show.insert(0, "â˜‘", False)

    if key_col == "group_name":
        df_show = df_show.rename(columns={"group_name": "ã‚°ãƒ«ãƒ¼ãƒ—", "customer_cnt": "å¾—æ„å…ˆæ•°", "item_cnt": "å“ç›®æ•°", "sales_amount": "å£²ä¸Š", "gross_profit": "ç²—åˆ©"})
        display_cols = ["â˜‘", "ã‚°ãƒ«ãƒ¼ãƒ—", "å¾—æ„å…ˆæ•°", "å“ç›®æ•°", "å£²ä¸Š", "ç²—åˆ©"]
        pick_col = "ã‚°ãƒ«ãƒ¼ãƒ—"
    elif key_col == "customer_code":
        df_show = df_show.rename(columns={"customer_code": "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", "customer_name": "å¾—æ„å…ˆå", "group_name": "ã‚°ãƒ«ãƒ¼ãƒ—", "item_cnt": "å“ç›®æ•°", "sales_amount": "å£²ä¸Š", "gross_profit": "ç²—åˆ©"})
        display_cols = ["â˜‘", "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", "å¾—æ„å…ˆå", "ã‚°ãƒ«ãƒ¼ãƒ—", "å“ç›®æ•°", "å£²ä¸Š", "ç²—åˆ©"]
        pick_col = "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰"
    else:
        df_show = df_show.rename(columns={"jan_code": "JAN", "product_name": "ä»£è¡¨å•†å“å", "customer_cnt": "å¾—æ„å…ˆæ•°", "sales_amount": "å£²ä¸Š", "gross_profit": "ç²—åˆ©"})
        display_cols = ["â˜‘", "JAN", "ä»£è¡¨å•†å“å", "å¾—æ„å…ˆæ•°", "å£²ä¸Š", "ç²—åˆ©"]
        pick_col = "JAN"

    edited = st.data_editor(
        _safe_fill_for_display(df_show[display_cols], money_cols=["å£²ä¸Š", "ç²—åˆ©"]),
        use_container_width=True,
        hide_index=True,
        disabled=[c_ for c_ in display_cols if c_ != "â˜‘"],
        column_config={"â˜‘": st.column_config.CheckboxColumn("é¸æŠ", help="æ˜ç´°ã‚’è¡¨ç¤ºã—ãŸã„è¡Œã«ãƒã‚§ãƒƒã‚¯ï¼ˆè¤‡æ•°å¯ï¼‰")},
        key=f"nd_trend_editor_{key_col}",
    )

    sel_df = edited[edited["â˜‘"] == True]
    if sel_df.empty:
        st.caption("â˜‘ã«ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã¨ä¸‹ã«æ˜ç´°ãŒå‡ºã¾ã™ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰ã€‚")
        return

    selected_keys = sel_df[pick_col].astype(str).tolist()

    st.divider()
    st.markdown("#### ğŸ§¾ æ˜ç´°ï¼ˆæ–°è¦ç´å“ Realizedï¼‰")

    base_where = f"nd.{c(nd_colmap,'first_sales_date')} >= DATE_SUB(today, INTERVAL {days} DAY) {where_ext}"

    # å…±é€šDIM
    cust_dim_cte = f"cust_dim AS ({cust_dim_sql})"
    item_dim_cte = f"item_dim AS ({item_dim_sql})"

    if key_col == "group_name":
        params2 = {} if is_admin else {"login_email": login_email}
        params2["group_keys"] = selected_keys
        sql_detail = f"""
          WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today),
          {cust_dim_cte},
          {item_dim_cte}
          SELECT
            CAST(nd.{c(nd_colmap,'first_sales_date')} AS DATE) AS first_sales_date,
            COALESCE(cd.group_name, 'æœªè¨­å®š') AS group_name,
            CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) AS customer_code,
            ANY_VALUE(cd.customer_name) AS customer_name,
            CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) AS jan_code,
            ANY_VALUE(id.product_name) AS product_name,
            SUM(nd.{c(nd_colmap,'sales_amount')}) AS sales_amount,
            SUM(nd.{c(nd_colmap,'gross_profit')}) AS gross_profit
          FROM `{VIEW_NEW_DELIVERY}` nd
          CROSS JOIN td
          LEFT JOIN cust_dim cd ON CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) = cd.customer_code
          LEFT JOIN item_dim id ON CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) = id.jan_code
          WHERE {base_where}
            AND COALESCE(cd.group_name, 'æœªè¨­å®š') IN UNNEST(@group_keys)
          GROUP BY first_sales_date, group_name, customer_code, jan_code
          ORDER BY first_sales_date DESC, sales_amount DESC
          LIMIT 2000
        """
        df_detail = query_df_safe(client, sql_detail, params2, label="New Delivery Trend Group Details")

    elif key_col == "customer_code":
        params2 = {} if is_admin else {"login_email": login_email}
        params2["customer_keys"] = selected_keys
        sql_detail = f"""
          WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today),
          {cust_dim_cte},
          {item_dim_cte}
          SELECT
            CAST(nd.{c(nd_colmap,'first_sales_date')} AS DATE) AS first_sales_date,
            COALESCE(cd.group_name, 'æœªè¨­å®š') AS group_name,
            CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) AS customer_code,
            ANY_VALUE(cd.customer_name) AS customer_name,
            CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) AS jan_code,
            ANY_VALUE(id.product_name) AS product_name,
            SUM(nd.{c(nd_colmap,'sales_amount')}) AS sales_amount,
            SUM(nd.{c(nd_colmap,'gross_profit')}) AS gross_profit
          FROM `{VIEW_NEW_DELIVERY}` nd
          CROSS JOIN td
          LEFT JOIN cust_dim cd ON CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) = cd.customer_code
          LEFT JOIN item_dim id ON CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) = id.jan_code
          WHERE {base_where}
            AND CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) IN UNNEST(@customer_keys)
          GROUP BY first_sales_date, group_name, customer_code, jan_code
          ORDER BY first_sales_date DESC, sales_amount DESC
          LIMIT 2000
        """
        df_detail = query_df_safe(client, sql_detail, params2, label="New Delivery Trend Customer Details")

    else:
        params2 = {} if is_admin else {"login_email": login_email}
        params2["jan_keys"] = selected_keys
        sql_detail = f"""
          WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today),
          {cust_dim_cte},
          {item_dim_cte}
          SELECT
            CAST(nd.{c(nd_colmap,'first_sales_date')} AS DATE) AS first_sales_date,
            COALESCE(cd.group_name, 'æœªè¨­å®š') AS group_name,
            CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) AS customer_code,
            ANY_VALUE(cd.customer_name) AS customer_name,
            CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) AS jan_code,
            ANY_VALUE(id.product_name) AS product_name,
            SUM(nd.{c(nd_colmap,'sales_amount')}) AS sales_amount,
            SUM(nd.{c(nd_colmap,'gross_profit')}) AS gross_profit
          FROM `{VIEW_NEW_DELIVERY}` nd
          CROSS JOIN td
          LEFT JOIN cust_dim cd ON CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) = cd.customer_code
          LEFT JOIN item_dim id ON CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) = id.jan_code
          WHERE {base_where}
            AND CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) IN UNNEST(@jan_keys)
          GROUP BY first_sales_date, group_name, customer_code, jan_code
          ORDER BY first_sales_date DESC, sales_amount DESC
          LIMIT 2000
        """
        df_detail = query_df_safe(client, sql_detail, params2, label="New Delivery Trend Product Details")

    if df_detail.empty:
        st.info("æ˜ç´°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df_detail = df_detail.rename(
        columns={
            "first_sales_date": "åˆå›ç´å“æ—¥",
            "group_name": "ã‚°ãƒ«ãƒ¼ãƒ—",
            "customer_code": "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰",
            "customer_name": "å¾—æ„å…ˆå",
            "jan_code": "JAN",
            "product_name": "å•†å“å",
            "sales_amount": "å£²ä¸Š",
            "gross_profit": "ç²—åˆ©",
        }
    )

    st.dataframe(
        _safe_fill_for_display(df_detail, money_cols=["å£²ä¸Š", "ç²—åˆ©"]).style.format({"å£²ä¸Š": "Â¥{:,.0f}", "ç²—åˆ©": "Â¥{:,.0f}"}),
        use_container_width=True,
        hide_index=True,
    )


def render_new_deliveries_section(client: bigquery.Client, login_email: str, is_admin: bool, colmap: Dict[str, str]) -> None:
    st.subheader("ğŸ‰ æ–°è¦ç´å“ã‚µãƒãƒªãƒ¼ï¼ˆRealized / å®Ÿç¸¾ï¼‰")

    nd_colmap = resolve_new_delivery_colmap(client)
    missing = nd_colmap.get("_missing_required")
    if missing:
        st.error("VIEW_NEW_DELIVERY ã®å¿…é ˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚VIEWå®šç¾©ï¼ˆåˆ—åï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.code(f"ä¸è¶³ã‚­ãƒ¼: {missing}")
        st.stop()

    if (not is_admin) and (c(nd_colmap, "login_email") == "login_email"):
        st.error("VIEW_NEW_DELIVERY ã« login_email åˆ—ãŒç„¡ã„ãŸã‚ã€æ‹…å½“è€…ã‚¹ã‚³ãƒ¼ãƒ—çµã‚Šè¾¼ã¿ãŒã§ãã¾ã›ã‚“ã€‚")
        st.stop()

    if "nd_summary_loaded" not in st.session_state:
        st.session_state.nd_summary_loaded = False
    if "nd_summary_df" not in st.session_state:
        st.session_state.nd_summary_df = pd.DataFrame()

    if st.button("æ–°è¦ç´å“å®Ÿç¸¾ã‚’èª­ã¿è¾¼ã‚€", key="btn_new_deliv"):
        where_ext = "" if is_admin else f"AND {c(nd_colmap,'login_email')} = @login_email"
        params = None if is_admin else {"login_email": login_email}

        sql = f"""
        WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today)
        SELECT
          'â‘  æ˜¨æ—¥' AS `æœŸé–“`,
          COUNT(DISTINCT CAST({c(nd_colmap,'customer_code')} AS STRING)) AS `å¾—æ„å…ˆæ•°`,
          COUNT(DISTINCT CAST({c(nd_colmap,'jan_code')} AS STRING)) AS `å“ç›®æ•°`,
          SUM({c(nd_colmap,'sales_amount')}) AS `å£²ä¸Š`,
          SUM({c(nd_colmap,'gross_profit')}) AS `ç²—åˆ©`
        FROM `{VIEW_NEW_DELIVERY}` CROSS JOIN td
        WHERE {c(nd_colmap,'first_sales_date')} = DATE_SUB(today, INTERVAL 1 DAY) {where_ext}
        UNION ALL
        SELECT
          'â‘¡ ç›´è¿‘7æ—¥',
          COUNT(DISTINCT CAST({c(nd_colmap,'customer_code')} AS STRING)),
          COUNT(DISTINCT CAST({c(nd_colmap,'jan_code')} AS STRING)),
          SUM({c(nd_colmap,'sales_amount')}),
          SUM({c(nd_colmap,'gross_profit')})
        FROM `{VIEW_NEW_DELIVERY}` CROSS JOIN td
        WHERE {c(nd_colmap,'first_sales_date')} >= DATE_SUB(today, INTERVAL 7 DAY) {where_ext}
        UNION ALL
        SELECT
          'â‘¢ å½“æœˆ',
          COUNT(DISTINCT CAST({c(nd_colmap,'customer_code')} AS STRING)),
          COUNT(DISTINCT CAST({c(nd_colmap,'jan_code')} AS STRING)),
          SUM({c(nd_colmap,'sales_amount')}),
          SUM({c(nd_colmap,'gross_profit')})
        FROM `{VIEW_NEW_DELIVERY}` CROSS JOIN td
        WHERE DATE_TRUNC({c(nd_colmap,'first_sales_date')}, MONTH) = DATE_TRUNC(today, MONTH) {where_ext}
        ORDER BY `æœŸé–“`
        """

        df_new = query_df_safe(client, sql, params, label="New Deliveries")
        st.session_state.nd_summary_df = df_new.copy()
        st.session_state.nd_summary_loaded = True

    if not st.session_state.nd_summary_loaded:
        st.info("ä¸Šã®ãƒœã‚¿ãƒ³ã§æ–°è¦ç´å“å®Ÿç¸¾ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚")
        return

    df_new = st.session_state.nd_summary_df
    if df_new is None or df_new.empty:
        st.info("æ–°è¦ç´å“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.dataframe(
            _safe_fill_for_display(df_new, money_cols=["å£²ä¸Š", "ç²—åˆ©"]).style.format({"å£²ä¸Š": "Â¥{:,.0f}", "ç²—åˆ©": "Â¥{:,.0f}"}),
            use_container_width=True,
            hide_index=True,
        )

    st.divider()
    render_new_delivery_trends(client, login_email, is_admin, nd_colmap, colmap)


# -----------------------------
# Adoptionï¼ˆæœ€ä½é™ã§ã‚‚å‹•ãï¼‰
# -----------------------------
def render_adoption_alerts_section(client: bigquery.Client, login_email: str, is_admin: bool) -> None:
    st.subheader("ğŸ§­ Adoptionï¼ˆæ¡ç”¨çŠ¶æ³ï¼‰ã‚µãƒãƒªãƒ¼")

    role_where = "" if is_admin else "WHERE login_email = @login_email"
    params = None if is_admin else {"login_email": login_email}

    sql = f"""
      SELECT
        COUNT(*) AS rows,
        COUNTIF(CAST(status AS STRING) = 'æœªæ¡ç”¨') AS not_adopted,
        COUNTIF(CAST(status AS STRING) = 'æ¡ç”¨') AS adopted
      FROM `{VIEW_ADOPTION}`
      {role_where}
    """
    df = query_df_safe(client, sql, params, "Adoption Summary")
    if df.empty:
        st.info("Adoptionãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    r = df.iloc[0]
    c1, c2, c3 = st.columns(3)
    c1.metric("è¡Œæ•°", int(r["rows"]))
    c2.metric("æœªæ¡ç”¨", int(r["not_adopted"]))
    c3.metric("æ¡ç”¨", int(r["adopted"]))

    with st.expander("æœªæ¡ç”¨ ä¸Šä½ï¼ˆä¾‹ï¼šç›´è¿‘æ›´æ–°ï¼‰", expanded=False):
        sql2 = f"""
          SELECT *
          FROM `{VIEW_ADOPTION}`
          {role_where}
          WHERE CAST(status AS STRING) = 'æœªæ¡ç”¨'
          ORDER BY updated_at DESC
          LIMIT 200
        """
        df2 = query_df_safe(client, sql2, params, "Adoption Not Adopted")
        if df2.empty:
            st.info("æœªæ¡ç”¨ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.dataframe(_safe_fill_for_display(df2), use_container_width=True, hide_index=True)


# -----------------------------
# Customer Drilldownï¼ˆæœ€ä½é™ã§ã‚‚å‹•ãï¼‰
# -----------------------------
def render_customer_drilldown(client: bigquery.Client, login_email: str, is_admin: bool, scope: ScopeFilter, colmap: Dict[str, str]) -> None:
    st.subheader("ğŸ” å¾—æ„å…ˆãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ï¼ˆæ˜ç´°é›†è¨ˆï¼‰")

    role_filter = "" if is_admin else f"{c(colmap,'login_email')} = @login_email"
    scope_filter_clause = scope.where_clause().replace("customer_name", c(colmap, "customer_name"))
    where_sql = _compose_where(role_filter, scope_filter_clause)

    params: Dict[str, Any] = dict(scope.params or {})
    if not is_admin:
        params["login_email"] = login_email

    sql = f"""
      SELECT
        CAST({c(colmap,'customer_code')} AS STRING) AS customer_code,
        ANY_VALUE(CAST({c(colmap,'customer_name')} AS STRING)) AS customer_name,
        COUNT(*) AS rows,
        SUM({c(colmap,'sales_amount')}) AS sales_amount,
        SUM({c(colmap,'gross_profit')}) AS gross_profit,
        MAX({c(colmap,'sales_date')}) AS last_sales_date
      FROM `{VIEW_UNIFIED}`
      {where_sql}
      GROUP BY customer_code
      ORDER BY sales_amount DESC
      LIMIT 200
    """
    df = query_df_safe(client, sql, params, "Customer Drilldown")
    if df.empty:
        st.info("è©²å½“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df = df.rename(columns={"customer_code": "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", "customer_name": "å¾—æ„å…ˆå", "rows": "è¡Œæ•°", "sales_amount": "å£²ä¸Š", "gross_profit": "ç²—åˆ©", "last_sales_date": "æœ€çµ‚è²©å£²æ—¥"})
    st.dataframe(
        _safe_fill_for_display(df, money_cols=["å£²ä¸Š", "ç²—åˆ©"]).style.format({"å£²ä¸Š": "Â¥{:,.0f}", "ç²—åˆ©": "Â¥{:,.0f}"}),
        use_container_width=True,
        hide_index=True,
    )


# -----------------------------
# 5. Main Loop
# -----------------------------
def main() -> None:
    set_page()
    client = setup_bigquery_client()

    # ColMap è§£æ±ºï¼ˆèµ·å‹•ç›´å¾Œã«å¿…é ˆåˆ—ä¸è¶³ã‚’æ¤œå‡ºã—ã¦åœæ­¢ï¼‰
    colmap = resolve_unified_colmap(client)
    missing = colmap.get("_missing_required")
    if missing:
        st.error("VIEW_UNIFIED ã®å¿…é ˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚VIEWå®šç¾©ï¼ˆåˆ—åï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.code(f"ä¸è¶³ã‚­ãƒ¼: {missing}")
        st.stop()

    # â˜… å®Œå…¨è¸è¥²ç›£æŸ»ï¼ˆèµ·å‹•ç›´å¾Œï¼‰
    self_audit()

    with st.sidebar:
        st.header("ğŸ”‘ ãƒ­ã‚°ã‚¤ãƒ³")
        login_id = st.text_input("ãƒ­ã‚°ã‚¤ãƒ³ID (ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹)", key="login_id")
        login_pw = st.text_input("ãƒ‘ã‚¹ã‚³ãƒ¼ãƒ‰ (æºå¸¯ä¸‹4æ¡)", type="password", key="login_pw")

        st.divider()
        st.session_state.use_bqstorage = st.checkbox("é«˜é€Ÿèª­è¾¼ (Storage API)", value=True, key="use_bqstorage")

        if st.button("ğŸ“¡ é€šä¿¡ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯", key="btn_health"):
            try:
                client.query("SELECT 1").result(timeout=10)
                st.success("BigQuery æ¥ç¶šæ­£å¸¸")
            except Exception as e:
                st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")

        if st.button("ğŸ§¹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢", key="btn_clear_cache"):
            st.cache_data.clear()
            st.cache_resource.clear()

        with st.expander("ğŸ”§ VIEW_UNIFIED åˆ—ãƒãƒƒãƒ—ï¼ˆè‡ªå‹•è§£æ±ºçµæœï¼‰", expanded=False):
            st.json(colmap)

        with st.expander("ğŸ”§ VIEW_NEW_DELIVERY åˆ—ãƒãƒƒãƒ—ï¼ˆè‡ªå‹•è§£æ±ºçµæœï¼‰", expanded=False):
            st.json(resolve_new_delivery_colmap(client))

    if not login_id or not login_pw:
        st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
        return

    role = resolve_role(client, login_id.strip(), login_pw.strip())
    if not role.is_authenticated:
        st.error("âŒ ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    st.success(f"ğŸ”“ ãƒ­ã‚°ã‚¤ãƒ³ä¸­: {role.staff_name} ã•ã‚“")
    c1, c2, c3 = st.columns(3)
    c1.metric("ğŸ‘¤ æ‹…å½“", role.staff_name)
    c2.metric("ğŸ›¡ï¸ æ¨©é™", role.role_key)
    c3.metric("ğŸ“ é›»è©±", role.phone)
    st.divider()

    if role.role_admin_view:
        render_fytd_org_section(client, colmap)
    else:
        render_fytd_me_section(client, role.login_email, colmap)

    st.divider()

    scope = render_scope_filters(client, role)
    st.divider()

    if role.role_admin_view:
        render_group_underperformance_section(client, role, scope, colmap)
        st.divider()
        render_yoy_section(client, role.login_email, is_admin=True, scope=scope, colmap=colmap)
        st.divider()
        render_new_deliveries_section(client, role.login_email, is_admin=True, colmap=colmap)
        st.divider()
        render_adoption_alerts_section(client, role.login_email, is_admin=True)
        st.divider()
        render_customer_drilldown(client, role.login_email, is_admin=True, scope=scope, colmap=colmap)
    else:
        render_yoy_section(client, role.login_email, is_admin=False, scope=scope, colmap=colmap)
        st.divider()
        render_new_deliveries_section(client, role.login_email, is_admin=False, colmap=colmap)
        st.divider()
        render_adoption_alerts_section(client, role.login_email, is_admin=False)
        st.divider()
        render_customer_drilldown(client, role.login_email, is_admin=False, scope=scope, colmap=colmap)


if __name__ == "__main__":
    main()
