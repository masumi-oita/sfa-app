# -*- coding: utf-8 -*-
"""
SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - OS v1.4.9 (v1.4.8è¸è¥² + ColMapçµ±åˆãƒ‘ãƒƒãƒ)

ã€v1.4.8 è¸è¥²ã€‘
- YoYï¼šVIEW_UNIFIED ã‹ã‚‰å‹•çš„é›†è¨ˆã«çµ±ä¸€ï¼ˆYJåŒä¸€ã§å•†å“åãŒ2è¡Œå•é¡Œã‚’æŠ‘æ­¢ï¼‰
- YoYï¼šç¬¬ä¸€éšå±¤ã‚’ã€Œã‚¯ãƒªãƒƒã‚¯é¸æŠã€å¯¾å¿œï¼ˆãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿ã§ã‚‚é¸æŠä¿æŒï¼‰
- ã‚¹ã‚³ãƒ¼ãƒ—ï¼šå¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ—åˆ—å€™è£œã‚’ VIEW_UNIFIED ã®ã‚¹ã‚­ãƒ¼ãƒã‹ã‚‰è‡ªå‹•åˆ¤å®š
- Group Display: officialå…ˆé ­ + rawä½µè¨˜
- æ–°æ©Ÿèƒ½ï¼šå¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ— / å¾—æ„å…ˆå˜ä½“ã®åˆ‡æ›¿ ï¼† å•†å“è¦å› ãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ï¼ˆå…¨ä»¶è¡¨ç¤ºï¼‰
- æ–°æ©Ÿèƒ½ï¼šé †ä½ã‚¢ã‚¤ã‚³ãƒ³ã®è¿½åŠ ã¨ã€ä¸è¦ãªYJã‚³ãƒ¼ãƒ‰åˆ—ã®éè¡¨ç¤º
- ä¿®æ­£ï¼šWHEREäºŒé‡ã‚¨ãƒ©ãƒ¼è§£æ¶ˆ ï¼† é¸æŠçŠ¶æ…‹ã®æ¶ˆå¤±ãƒã‚°è§£æ¶ˆ ï¼† è¡¨ç¤ºé †åºã®æœ€é©åŒ–
- â˜…ä¿®æ­£ï¼šRecoï¼ˆVIEW_RECOMMENDï¼‰ã® customer_code ãŒ INT64 ã®ãŸã‚ã€STRINGã‚­ãƒ¼ï¼ˆVIEW_UNIFIEDï¼‰ã¨ç…§åˆã§ãã‚‹ã‚ˆã† CAST å¯¾å¿œ

ã€v1.4.9 â˜…è¿½åŠ ï¼ˆä»Šå›ã®äº‹æ•…ã®æ ¹æ²»ï¼‰ã€‘
- â˜… ColMapï¼ˆåˆ—åå¸åï¼‰ã‚’å°å…¥ï¼šjan/jan_codeã€pack_unit/package_unit ç­‰ã®å·®ç•°ã‚’è‡ªå‹•è§£æ±º
- â˜… å…¨SQLã§ colmap ã‚’è²«é€šï¼šåˆ—åæºã‚Œèµ·å› ã® "Unrecognized name" ã‚’æ ¹çµ¶
- â˜… å¿…é ˆåˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€èµ·å‹•ç›´å¾Œã«ã€Œä¸è¶³åˆ—ä¸€è¦§ã€ã‚’æ˜ç¤ºã—ã¦åœæ­¢ï¼ˆæ²ˆé»™ã—ãªã„ï¼‰

ã€v1.4.9 â˜…è¿½åŠ ï¼ˆä»Šå›ã®è¿½åŠ ä¿®æ­£ï¼šNewDeliveryè¡¨ç¤ºåˆ—ä¸è¶³ã®æ ¹æ²»ï¼‰ã€‘
- â˜… VIEW_NEW_DELIVERY ã« customer_name/product_name ãŒç„¡ãã¦ã‚‚æ­¢ã‚ãªã„
- â˜… customer_name ã¯ VIEW_UNIFIED ç”±æ¥ cust_dim ã§è£œå®Œ
- â˜… product_name ã¯ VIEW_UNIFIED ç”±æ¥ item_dimï¼ˆjan_codeâ†’product_nameï¼‰ã§è£œå®Œ
- â˜… ãã‚Œã§ã‚‚å–ã‚Œãªã„å ´åˆã¯ JAN è¡¨ç¤ºã§ç¶™ç¶šï¼ˆå•†å“åã¯ "ä¸æ˜"ï¼‰
"""

from __future__ import annotations

from dataclasses import dataclass
import re
from typing import Any, Dict, Optional, Tuple, Iterable

import pandas as pd
import streamlit as st
from google.cloud import bigquery
from google.oauth2 import service_account
from pandas.api.types import is_numeric_dtype


# -----------------------------
# 1. Configuration (è¨­å®š)
# -----------------------------
APP_TITLE = "SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"
DEFAULT_LOCATION = "asia-northeast1"
PROJECT_DEFAULT = "salesdb-479915"
DATASET_DEFAULT = "sales_data"

VIEW_UNIFIED = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_unified_grouped"
VIEW_ROLE_CLEAN = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.dim_staff_role_clean"
VIEW_NEW_DELIVERY = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_new_deliveries_realized_daily_fact_all_months"
VIEW_RECOMMEND = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_recommendation_engine"
VIEW_ADOPTION = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_customer_adoption_status"

CUSTOMER_GROUP_COLUMN_CANDIDATES = (
    "customer_group_display",
    "customer_group_official",
    "customer_group_raw",
    "sales_group_name",
)


# -----------------------------
# 2. Helpers (è¡¨ç¤ºç”¨)
# -----------------------------
def set_page() -> None:
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)
    st.caption("OS v1.4.9ï½œv1.4.8è¸è¥² + ColMapï¼ˆåˆ—åå¸åï¼‰çµ±åˆ + NewDeliveryè¡¨ç¤ºåˆ—ä¸è¶³ æ ¹æ²»")


def create_default_column_config(df: pd.DataFrame) -> Dict[str, st.column_config.Column]:
    config: Dict[str, st.column_config.Column] = {}
    for col in df.columns:
        if any(k in col for k in ["å£²ä¸Š", "ç²—åˆ©", "é‡‘é¡", "å·®é¡", "å®Ÿç¸¾", "äºˆæ¸¬", "GAP"]):
            config[col] = st.column_config.NumberColumn(col, format="Â¥%d")
        elif any(k in col for k in ["ç‡", "æ¯”", "ãƒšãƒ¼ã‚¹"]):
            config[col] = st.column_config.NumberColumn(col, format="%.1f%%")
        elif "æ—¥" in col or pd.api.types.is_datetime64_any_dtype(df[col]):
            config[col] = st.column_config.DateColumn(col, format="YYYY-MM-DD")
        elif is_numeric_dtype(df[col]):
            config[col] = st.column_config.NumberColumn(col, format="%d")
        else:
            config[col] = st.column_config.TextColumn(col)
    return config


def get_safe_float(row: pd.Series, key: str) -> float:
    val = row.get(key)
    return float(val) if not pd.isna(val) else 0.0


def normalize_product_display_name(name: Any) -> str:
    if pd.isna(name):
        return ""
    text = str(name).strip()
    text = re.sub(r"[/ï¼].*$", "", text)
    return text.strip()


# -----------------------------
# 3. BigQuery Connection & Auth
# -----------------------------
@st.cache_resource
def setup_bigquery_client() -> bigquery.Client:
    bq = st.secrets["bigquery"]
    sa_info = dict(bq["service_account"])
    scopes = [
        "https://www.googleapis.com/auth/bigquery",
        "https://www.googleapis.com/auth/drive",
        "https://www.googleapis.com/auth/spreadsheets",
    ]
    creds = service_account.Credentials.from_service_account_info(sa_info, scopes=scopes)
    return bigquery.Client(
        project=PROJECT_DEFAULT,
        credentials=creds,
        location=DEFAULT_LOCATION,
    )


def _build_query_parameter(key: str, value: Any) -> bigquery.QueryParameter:
    # æ˜ç¤ºã‚¿ãƒ—ãƒ«æŒ‡å®š (TYPE, VALUE)
    if isinstance(value, tuple) and len(value) == 2:
        p_type, p_value = value
        p_type = str(p_type).upper()
        if p_type.startswith("ARRAY<") and isinstance(p_value, (list, tuple)):
            return bigquery.ArrayQueryParameter(key, "STRING", list(p_value))
        return bigquery.ScalarQueryParameter(key, p_type, p_value)

    # é…åˆ—ã¯ ARRAY<STRING>
    if isinstance(value, (list, tuple)):
        return bigquery.ArrayQueryParameter(key, "STRING", [None if v is None else str(v) for v in value])

    # ã‚¹ã‚«ãƒ©ãƒ¼
    if value is None:
        return bigquery.ScalarQueryParameter(key, "STRING", None)
    if isinstance(value, bool):
        return bigquery.ScalarQueryParameter(key, "BOOL", value)
    if isinstance(value, int):
        return bigquery.ScalarQueryParameter(key, "INT64", value)
    if isinstance(value, float):
        return bigquery.ScalarQueryParameter(key, "FLOAT64", value)
    if isinstance(value, pd.Timestamp):
        return bigquery.ScalarQueryParameter(key, "TIMESTAMP", value.to_pydatetime())

    return bigquery.ScalarQueryParameter(key, "STRING", str(value))


def query_df_safe(
    client: bigquery.Client,
    sql: str,
    params: Optional[Dict[str, Any]] = None,
    label: str = "",
    timeout_sec: int = 60,
) -> pd.DataFrame:
    use_bqstorage = st.session_state.get("use_bqstorage", True)
    try:
        job_config = bigquery.QueryJobConfig()
        if params:
            job_config.query_parameters = [_build_query_parameter(k, v) for k, v in params.items()]

        job = client.query(sql, job_config=job_config)
        job.result(timeout=timeout_sec)
        return job.to_dataframe(create_bqstorage_client=use_bqstorage)
    except Exception as e:
        st.error(f"ã‚¯ã‚¨ãƒªã‚¨ãƒ©ãƒ¼ ({label}):\n{e}")
        return pd.DataFrame()


@dataclass(frozen=True)
class RoleInfo:
    is_authenticated: bool = False
    login_email: str = ""
    staff_name: str = "ã‚²ã‚¹ãƒˆ"
    role_key: str = "GUEST"
    role_admin_view: bool = False
    phone: str = "-"


@dataclass(frozen=True)
class ScopeFilter:
    predicates: tuple[str, ...] = ()
    params: Dict[str, Any] | None = None

    def where_clause(self) -> str:
        if not self.predicates:
            return ""
        return " AND ".join(self.predicates)


def _compose_where(*parts: str) -> str:
    clauses = [p.strip() for p in parts if p and p.strip()]
    if not clauses:
        return ""
    return "WHERE " + " AND ".join(clauses)


def _split_table_fqn(table_fqn: str) -> Tuple[str, str, str]:
    parts = table_fqn.split(".")
    if len(parts) != 3:
        raise ValueError(f"Invalid table FQN: {table_fqn}")
    return parts[0], parts[1], parts[2]


@st.cache_data(ttl=3600)
def role_table_has_login_code(_client: bigquery.Client) -> bool:
    project_id, dataset_id, table_name = _split_table_fqn(VIEW_ROLE_CLEAN)
    sql = f"""
        SELECT 1
        FROM `{project_id}.{dataset_id}.INFORMATION_SCHEMA.COLUMNS`
        WHERE table_name = @table_name
          AND column_name = 'login_code'
        LIMIT 1
    """
    df = query_df_safe(_client, sql, {"table_name": table_name}, "Role Schema Check")
    return not df.empty


# -----------------------------
# â˜… ColMapæ±ç”¨ï¼ˆä»»æ„VIEWã®åˆ—åæºã‚Œå¸åï¼‰
# -----------------------------
@st.cache_data(ttl=3600)
def get_view_columns(_client: bigquery.Client, view_fqn: str) -> set[str]:
    project_id, dataset_id, table_name = _split_table_fqn(view_fqn)
    sql = f"""
        SELECT column_name
        FROM `{project_id}.{dataset_id}.INFORMATION_SCHEMA.COLUMNS`
        WHERE table_name = @table_name
    """
    df = query_df_safe(_client, sql, {"table_name": table_name}, f"Schema Check: {view_fqn}")
    if df.empty or "column_name" not in df.columns:
        return set()
    return {str(c).lower() for c in df["column_name"].dropna().tolist()}


def _pick_from(cols: set[str], *cands: str) -> Optional[str]:
    for c in cands:
        if c and c.lower() in cols:
            return c.lower()
    return None


def resolve_view_colmap(
    _client: bigquery.Client,
    view_fqn: str,
    mapping: Dict[str, Iterable[str]],
    required_keys: Iterable[str],
    optional_mapping: Optional[Dict[str, Iterable[str]]] = None,
) -> Dict[str, str]:
    cols = get_view_columns(_client, view_fqn)
    colmap: Dict[str, Optional[str]] = {}

    for logical_key, cands in mapping.items():
        colmap[logical_key] = _pick_from(cols, *list(cands))

    if optional_mapping:
        for logical_key, cands in optional_mapping.items():
            v = _pick_from(cols, *list(cands))
            if v:
                colmap[logical_key] = v

    missing = [k for k in required_keys if not colmap.get(k)]
    if missing:
        colmap["_missing_required"] = ",".join(missing)

    return {k: v for k, v in colmap.items() if v is not None}


def c(colmap: Dict[str, str], key: str) -> str:
    """SQLå†…ã§ä½¿ã†åˆ—åè§£æ±ºã€‚"""
    return colmap.get(key, key)


# -----------------------------
# æ—¢å­˜ï¼šVIEW_UNIFIED ã®åˆ—å‚ç…§ï¼ˆäº’æ›ã®ãŸã‚é–¢æ•°åã¯ç¶­æŒï¼‰
# -----------------------------
@st.cache_data(ttl=3600)
def get_unified_columns(_client: bigquery.Client) -> set[str]:
    return get_view_columns(_client, VIEW_UNIFIED)


def get_available_customer_group_columns(_client: bigquery.Client) -> list[str]:
    columns = get_unified_columns(_client)
    return [col for col in CUSTOMER_GROUP_COLUMN_CANDIDATES if col in columns]


@st.cache_data(ttl=3600)
def get_customer_group_column_profiles(_client: bigquery.Client) -> pd.DataFrame:
    available_cols = get_available_customer_group_columns(_client)
    if not available_cols:
        return pd.DataFrame()

    union_parts = []
    for col in available_cols:
        union_parts.append(
            f"""
            SELECT
              '{col}' AS column_name,
              COUNT(*) AS total_rows,
              COUNTIF(COALESCE(NULLIF(CAST({col} AS STRING), ''), '') != '') AS non_null_rows,
              COUNT(DISTINCT NULLIF(CAST({col} AS STRING), '')) AS distinct_groups
            FROM `{VIEW_UNIFIED}`
            """
        )

    sql = "\nUNION ALL\n".join(union_parts) + "\nORDER BY non_null_rows DESC, distinct_groups DESC"
    return query_df_safe(_client, sql, label="Customer Group Column Profile")


def resolve_customer_group_sql_expr(_client: bigquery.Client) -> Tuple[Optional[str], Optional[str]]:
    cols = get_unified_columns(_client)

    has_display = "customer_group_display" in cols
    has_official = "customer_group_official" in cols
    has_raw = "customer_group_raw" in cols
    has_old = "sales_group_name" in cols

    if has_display:
        expr = "COALESCE(NULLIF(CAST(customer_group_display AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.customer_group_display"

    if has_official and has_raw:
        official = "NULLIF(CAST(customer_group_official AS STRING), '')"
        raw = "NULLIF(CAST(customer_group_raw AS STRING), '')"
        expr = f"""
          COALESCE(
            CASE
              WHEN {official} IS NOT NULL AND {raw} IS NOT NULL AND {official} != {raw}
                THEN CONCAT({official}, 'ï¼ˆ', {raw}, 'ï¼‰')
              WHEN {official} IS NOT NULL THEN {official}
              WHEN {raw} IS NOT NULL THEN {raw}
              ELSE NULL
            END,
            'æœªè¨­å®š'
          )
        """
        return " ".join(expr.split()), f"{VIEW_UNIFIED}.customer_group_official + customer_group_raw"

    if has_official:
        expr = "COALESCE(NULLIF(CAST(customer_group_official AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.customer_group_official"

    if has_raw:
        expr = "COALESCE(NULLIF(CAST(customer_group_raw AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.customer_group_raw"

    if has_old:
        expr = "COALESCE(NULLIF(CAST(sales_group_name AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.sales_group_name"

    return None, None


# -----------------------------
# â˜… v1.4.9 ColMapï¼ˆåˆ—åå¸åï¼‰: VIEW_UNIFIED
# -----------------------------
@st.cache_data(ttl=3600)
def resolve_unified_colmap(_client: bigquery.Client) -> Dict[str, str]:
    mapping = {
        "customer_code": ("customer_code", "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", "å¾—æ„å…ˆCD"),
        "customer_name": ("customer_name", "å¾—æ„å…ˆå"),
        "login_email": ("login_email", "email", "æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«", "æ‹…å½“ãƒ¡ãƒ¼ãƒ«", "login"),
        "sales_date": ("sales_date", "è²©å£²æ—¥", "date"),
        "fiscal_year": ("fiscal_year", "å¹´åº¦", "fy"),
        "sales_amount": ("sales_amount", "å£²ä¸Š", "åˆè¨ˆä¾¡æ ¼", "sales"),
        "gross_profit": ("gross_profit", "ç²—åˆ©", "gp"),
        "product_name": ("product_name", "å•†å“å", "å•†å“åç§°", "item_name", "å•†å“åç§°"),
        "yj_code": ("yj_code", "yjcode", "yj", "YJCode"),
        "jan_code": ("jan_code", "jan", "JAN"),
        "package_unit": ("package_unit", "pack_unit", "åŒ…è£…å˜ä½", "åŒ…è£…"),
    }
    optional = {
        "staff_name": ("staff_name", "æ‹…å½“è€…å", "æ‹…å½“ç¤¾å“¡å", "æ‹…å½“ç¤¾å“¡æ°", "æ‹…å½“"),
    }
    required = ("customer_code", "customer_name", "sales_date", "fiscal_year", "sales_amount", "gross_profit", "product_name")
    return resolve_view_colmap(_client, VIEW_UNIFIED, mapping, required, optional)


# -----------------------------
# â˜… v1.4.9 ColMap: VIEW_NEW_DELIVERY
# -----------------------------
@st.cache_data(ttl=3600)
def resolve_new_delivery_colmap(_client: bigquery.Client) -> Dict[str, str]:
    mapping = {
        "first_sales_date": ("first_sales_date", "åˆå›ç´å“æ—¥", "first_date", "date"),
        "customer_code": ("customer_code", "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", "å¾—æ„å…ˆCD"),
        "customer_name": ("customer_name", "å¾—æ„å…ˆå", "cust_name", "customer"),
        "jan_code": ("jan_code", "jan", "JAN"),
        "product_name": ("product_name", "item_name", "å•†å“å", "å•†å“åç§°", "å“ç›®å", "drug_name"),
        "sales_amount": ("sales_amount", "å£²ä¸Š", "sales"),
        "gross_profit": ("gross_profit", "ç²—åˆ©", "gp"),
        "login_email": ("login_email", "email", "æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«", "æ‹…å½“ãƒ¡ãƒ¼ãƒ«"),
        "staff_name": ("staff_name", "æ‹…å½“è€…å", "æ‹…å½“ç¤¾å“¡å", "æ‹…å½“"),
    }
    # é›†è¨ˆæˆç«‹ã®æœ€ä½é™
    required = ("first_sales_date", "customer_code", "jan_code", "sales_amount", "gross_profit")
    # customer_name/product_name ã¯ optionalï¼ˆç„¡ãã¦ã‚‚æ­¢ã‚ãªã„ï¼šVIEW_UNIFIEDã‹ã‚‰è£œå®Œã™ã‚‹ï¼‰
    optional = {
        "customer_name": ("customer_name", "å¾—æ„å…ˆå", "cust_name", "customer"),
        "product_name": ("product_name", "item_name", "å•†å“å", "å•†å“åç§°", "å“ç›®å", "drug_name"),
        "login_email": ("login_email", "email", "æ‹…å½“è€…ãƒ¡ãƒ¼ãƒ«", "æ‹…å½“ãƒ¡ãƒ¼ãƒ«"),
        "staff_name": ("staff_name", "æ‹…å½“è€…å", "æ‹…å½“ç¤¾å“¡å", "æ‹…å½“"),
    }
    return resolve_view_colmap(_client, VIEW_NEW_DELIVERY, mapping, required, optional)


# -----------------------------
# ã‚¹ã‚³ãƒ¼ãƒ—
# -----------------------------
def render_scope_filters(client: bigquery.Client, role: RoleInfo) -> ScopeFilter:
    st.markdown("### ğŸ” åˆ†æã‚¹ã‚³ãƒ¼ãƒ—è¨­å®š")
    predicates: list[str] = []
    params: Dict[str, Any] = {}

    with st.expander("è©³ç´°çµã‚Šè¾¼ã¿ï¼ˆå¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ—ãƒ»å¾—æ„å…ˆåï¼‰", expanded=False):
        c1, c2 = st.columns(2)

        group_expr, group_src = resolve_customer_group_sql_expr(client)
        if group_expr:
            role_where = ""
            role_params: Dict[str, Any] = {}
            if not role.role_admin_view:
                role_where = "WHERE login_email = @login_email"
                role_params["login_email"] = role.login_email

            sql_group = f"""
                SELECT DISTINCT {group_expr} AS group_name
                FROM `{VIEW_UNIFIED}`
                {role_where}
                ORDER BY group_name
                LIMIT 500
            """
            df_group = query_df_safe(client, sql_group, role_params, "Scope Group Options")
            group_opts = ["æŒ‡å®šãªã—"] + (df_group["group_name"].tolist() if not df_group.empty else [])
            selected_group = c1.selectbox("å¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ—", options=group_opts)
            if selected_group != "æŒ‡å®šãªã—":
                predicates.append(f"{group_expr} = @scope_group")
                params["scope_group"] = selected_group

            if group_src:
                c1.caption(f"æŠ½å‡ºå…ƒ: `{group_src}`")
        else:
            c1.caption("ã‚°ãƒ«ãƒ¼ãƒ—åˆ—ãªã—ï¼ˆVIEW_UNIFIEDã«è©²å½“åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼‰")

        keyword = c2.text_input("å¾—æ„å…ˆåï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", placeholder="ä¾‹ï¼šå¤è³€ç—…é™¢")
        if keyword.strip():
            predicates.append("customer_name LIKE @scope_customer_name")
            params["scope_customer_name"] = f"%{keyword.strip()}%"

    return ScopeFilter(predicates=tuple(predicates), params=params)


def resolve_role(client: bigquery.Client, login_email: str, login_code: str) -> RoleInfo:
    if not login_email or not login_code:
        return RoleInfo()

    has_login_code = role_table_has_login_code(client)

    if has_login_code:
        sql = f"""
            SELECT login_email, role_tier
            FROM `{VIEW_ROLE_CLEAN}`
            WHERE login_email = @login_email
              AND CAST(login_code AS STRING) = @login_code
            LIMIT 1
        """
        params: Dict[str, Any] = {"login_email": login_email, "login_code": login_code}
    else:
        sql = f"""
            SELECT login_email, role_tier
            FROM `{VIEW_ROLE_CLEAN}`
            WHERE login_email = @login_email
            LIMIT 1
        """
        params = {"login_email": login_email}

    df = query_df_safe(client, sql, params, "Auth Check")
    if df.empty:
        return RoleInfo(login_email=login_email)

    row = df.iloc[0]
    raw_role = str(row["role_tier"]).strip().upper()
    is_admin = any(x in raw_role for x in ["ADMIN", "MANAGER", "HQ"])

    return RoleInfo(
        is_authenticated=True,
        login_email=login_email,
        staff_name=login_email.split("@")[0],
        role_key="HQ_ADMIN" if is_admin else "SALES",
        role_admin_view=is_admin,
        phone="-",
    )


# -----------------------------
# 4. UI Sections (å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³)
# -----------------------------
def render_summary_metrics(row: pd.Series) -> None:
    s_cur = get_safe_float(row, "sales_amount_fytd")
    s_py_ytd = get_safe_float(row, "sales_amount_py_ytd")
    s_py_total = get_safe_float(row, "sales_amount_py_total")

    s_fc = s_cur * (s_py_total / s_py_ytd) if s_py_ytd > 0 else s_cur

    gp_cur = get_safe_float(row, "gross_profit_fytd")
    gp_py_ytd = get_safe_float(row, "gross_profit_py_ytd")
    gp_py_total = get_safe_float(row, "gross_profit_py_total")
    gp_fc = gp_cur * (gp_py_total / gp_py_ytd) if gp_py_ytd > 0 else gp_cur

    st.caption(
        "â€» ã€ä»ŠæœŸäºˆæ¸¬ã€‘ã¯AIäºˆæ¸¬ã§ã¯ãªãã€ã€Œä»ŠæœŸå®Ÿç¸¾ Ã— (æ˜¨å¹´åº¦ç€åœ° Ã· å‰å¹´åŒæœŸ)ã€"
        "ã«ã‚ˆã‚‹å­£ç¯€å¤‰å‹•ã‚’åŠ å‘³ã—ãŸæ¨ç§»ãƒšãƒ¼ã‚¹ï¼ˆç€åœ°è¦‹è¾¼ï¼‰ã§ã™ã€‚"
    )

    st.markdown("##### â–  å£²ä¸Š")
    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("â‘  ä»ŠæœŸç´¯è¨ˆ", f"Â¥{s_cur:,.0f}")
    c2.metric("â‘¡ å‰å¹´åŒæœŸ", f"Â¥{s_py_ytd:,.0f}", delta=f"{int(s_cur - s_py_ytd):,}" if s_py_ytd > 0 else None)
    c3.metric("â‘¢ æ˜¨å¹´åº¦ç€åœ°", f"Â¥{s_py_total:,.0f}")
    c4.metric("â‘£ ä»ŠæœŸäºˆæ¸¬", f"Â¥{s_fc:,.0f}")
    c5.metric("â‘¤ ç€åœ°GAP", f"Â¥{s_fc - s_py_total:,.0f}", delta=f"{int(s_fc - s_py_total):,}")

    st.markdown("##### â–  ç²—åˆ©")
    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("â‘  ä»ŠæœŸç´¯è¨ˆ", f"Â¥{gp_cur:,.0f}")
    c2.metric("â‘¡ å‰å¹´åŒæœŸ", f"Â¥{gp_py_ytd:,.0f}", delta=f"{int(gp_cur - gp_py_ytd):,}" if gp_py_ytd > 0 else None)
    c3.metric("â‘¢ æ˜¨å¹´åº¦ç€åœ°", f"Â¥{gp_py_total:,.0f}")
    c4.metric("â‘£ ä»ŠæœŸäºˆæ¸¬", f"Â¥{gp_fc:,.0f}")
    c5.metric("â‘¤ ç€åœ°GAP", f"Â¥{gp_fc - gp_py_total:,.0f}", delta=f"{int(gp_fc - gp_py_total):,}")


def render_fytd_org_section(client: bigquery.Client, colmap: Dict[str, str]) -> None:
    st.subheader("ğŸ¢ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå…¨ç¤¾ã‚µãƒãƒªãƒ¼")

    if "org_data_loaded" not in st.session_state:
        st.session_state.org_data_loaded = False

    if st.button("å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_org_load"):
        st.session_state.org_data_loaded = True

    if st.session_state.get("org_data_loaded"):
        sql = f"""
            WITH today_info AS (
              SELECT
                CURRENT_DATE('Asia/Tokyo') AS today,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today,
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                    - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
            )
            SELECT
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_fytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_fytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_py_ytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_py_ytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_py_total,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_py_total
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN today_info
        """
        df_org = query_df_safe(client, sql, None, "Org Summary")
        if not df_org.empty:
            render_summary_metrics(df_org.iloc[0])


def render_fytd_me_section(client: bigquery.Client, login_email: str, colmap: Dict[str, str]) -> None:
    st.subheader("ğŸ‘¤ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå€‹äººã‚µãƒãƒªãƒ¼")
    if st.button("è‡ªåˆ†ã®æˆç¸¾ã‚’èª­ã¿è¾¼ã‚€", key="btn_me_load"):
        sql = f"""
            WITH today_info AS (
              SELECT
                CURRENT_DATE('Asia/Tokyo') AS today,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today,
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                    - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
            )
            SELECT
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_fytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_fytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_py_ytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_py_ytd,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 THEN {c(colmap,'sales_amount')} ELSE 0 END) AS sales_amount_py_total,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 THEN {c(colmap,'gross_profit')} ELSE 0 END) AS gross_profit_py_total
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN today_info
            WHERE {c(colmap,'login_email')} = @login_email
        """
        df_me = query_df_safe(client, sql, {"login_email": login_email}, "Me Summary")
        if not df_me.empty:
            render_summary_metrics(df_me.iloc[0])


# -----------------------------
# å¾—æ„å…ˆãƒ»ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆæç¤ºã‚³ãƒ¼ãƒ‰è¸è¥²ï¼‰
# -----------------------------
def render_group_underperformance_section(
    client: bigquery.Client,
    role: RoleInfo,
    scope: ScopeFilter,
    colmap: Dict[str, str],
) -> None:
    st.subheader("ğŸ¢ å¾—æ„å…ˆãƒ»ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ï¼† è¦å› åˆ†æ")

    if "group_perf_mode" not in st.session_state:
        st.session_state.group_perf_mode = "ãƒ¯ãƒ¼ã‚¹ãƒˆ"

    c1_, c2_ = st.columns(2)
    view_choice = c1_.radio("ğŸ“Š åˆ†æã®å˜ä½", ["ğŸ¢ ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥", "ğŸ¥ å¾—æ„å…ˆå˜ä½“"], horizontal=True)
    mode_choice = c2_.radio("ğŸ† ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŸºæº–", ["ğŸ“‰ ä¸‹è½å¹…ãƒ¯ãƒ¼ã‚¹ãƒˆ", "ğŸ“ˆ ä¸Šæ˜‡å¹…ãƒ™ã‚¹ãƒˆ"], horizontal=True)

    perf_view = "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" if "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" in view_choice else "å¾—æ„å…ˆåˆ¥"
    perf_mode = "ãƒ¯ãƒ¼ã‚¹ãƒˆ" if "ãƒ¯ãƒ¼ã‚¹ãƒˆ" in mode_choice else "ãƒ™ã‚¹ãƒˆ"
    sort_order = "ASC" if perf_mode == "ãƒ¯ãƒ¼ã‚¹ãƒˆ" else "DESC"

    group_expr, group_src = resolve_customer_group_sql_expr(client)
    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" and not group_expr:
        st.info("ã‚°ãƒ«ãƒ¼ãƒ—åˆ†æã«åˆ©ç”¨ã§ãã‚‹åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆVIEW_UNIFIEDã«ã‚°ãƒ«ãƒ¼ãƒ—åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚")
        return

    role_filter = "" if role.role_admin_view else f"{c(colmap,'login_email')} = @login_email"
    scope_filter_clause = scope.where_clause().replace("customer_name", c(colmap, "customer_name"))
    filter_sql = _compose_where(role_filter, scope_filter_clause)

    params: Dict[str, Any] = dict(scope.params or {})
    if not role.role_admin_view:
        params["login_email"] = role.login_email

    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥":
        sql_parent = f"""
            WITH fy AS (
              SELECT
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                 - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
            )
            SELECT
              {group_expr} AS `åç§°`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS `ä»ŠæœŸå£²ä¸Š`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'sales_amount')} ELSE 0 END) AS `å‰å¹´åŒæœŸå£²ä¸Š`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'gross_profit')} ELSE 0 END) AS `ä»ŠæœŸç²—åˆ©`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'gross_profit')} ELSE 0 END) AS `å‰å¹´åŒæœŸç²—åˆ©`
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN fy
            {filter_sql}
            GROUP BY `åç§°`
            HAVING `å‰å¹´åŒæœŸå£²ä¸Š` > 0 OR `ä»ŠæœŸå£²ä¸Š` > 0
            ORDER BY (`ä»ŠæœŸå£²ä¸Š` - `å‰å¹´åŒæœŸå£²ä¸Š`) {sort_order}
            LIMIT 50
        """
    else:
        sql_parent = f"""
            WITH fy AS (
              SELECT
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                 - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
            )
            SELECT
              {c(colmap,'customer_code')} AS `ã‚³ãƒ¼ãƒ‰`,
              ANY_VALUE({c(colmap,'customer_name')}) AS `åç§°`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS `ä»ŠæœŸå£²ä¸Š`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'sales_amount')} ELSE 0 END) AS `å‰å¹´åŒæœŸå£²ä¸Š`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'gross_profit')} ELSE 0 END) AS `ä»ŠæœŸç²—åˆ©`,
              SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'gross_profit')} ELSE 0 END) AS `å‰å¹´åŒæœŸç²—åˆ©`
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN fy
            {filter_sql}
            GROUP BY `ã‚³ãƒ¼ãƒ‰`
            HAVING `å‰å¹´åŒæœŸå£²ä¸Š` > 0 OR `ä»ŠæœŸå£²ä¸Š` > 0
            ORDER BY (`ä»ŠæœŸå£²ä¸Š` - `å‰å¹´åŒæœŸå£²ä¸Š`) {sort_order}
            LIMIT 50
        """

    df_parent = query_df_safe(client, sql_parent, params, f"Parent Perf {perf_view}")
    if df_parent.empty:
        st.info("è¡¨ç¤ºã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df_parent["å£²ä¸Šå·®é¡"] = df_parent["ä»ŠæœŸå£²ä¸Š"] - df_parent["å‰å¹´åŒæœŸå£²ä¸Š"]
    df_parent["å£²ä¸Šæˆé•·ç‡"] = df_parent.apply(
        lambda r: ((r["ä»ŠæœŸå£²ä¸Š"] / r["å‰å¹´åŒæœŸå£²ä¸Š"] - 1) * 100) if r["å‰å¹´åŒæœŸå£²ä¸Š"] else 0,
        axis=1,
    )
    df_parent["ç²—åˆ©å·®é¡"] = df_parent["ä»ŠæœŸç²—åˆ©"] - df_parent["å‰å¹´åŒæœŸç²—åˆ©"]

    def get_parent_rank_icon(rank: int, mode: str) -> str:
        if mode == "ãƒ™ã‚¹ãƒˆ":
            if rank == 1:
                return "ğŸ¥‡ 1ä½"
            if rank == 2:
                return "ğŸ¥ˆ 2ä½"
            if rank == 3:
                return "ğŸ¥‰ 3ä½"
            return f"ğŸŒŸ {rank}ä½"
        else:
            if rank == 1:
                return "ğŸš¨ 1ä½"
            if rank == 2:
                return "âš ï¸ 2ä½"
            if rank == 3:
                return "âš¡ 3ä½"
            return f"ğŸ“‰ {rank}ä½"

    df_parent.insert(0, "é †ä½", [get_parent_rank_icon(i + 1, perf_mode) for i in range(len(df_parent))])

    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" and group_src:
        st.caption(f"æŠ½å‡ºå…ƒã‚°ãƒ«ãƒ¼ãƒ—åˆ—: `{group_src}`")

       # --- å‹å®‰å…¨ã«æ¬ æå‡¦ç†ï¼ˆdb_dtypeså¯¾ç­–ï¼‰
    df_detail = df_detail.copy()

    # æ•°å€¤ã¯0
    for coln in ["å£²ä¸Š", "ç²—åˆ©"]:
        if coln in df_detail.columns:
            df_detail[coln] = pd.to_numeric(df_detail[coln], errors="coerce").fillna(0)

    # æ—¥ä»˜ã¯è§¦ã‚‰ãªã„ï¼ˆNaTã®ã¾ã¾è¡¨ç¤ºï¼‰
    # æ–‡å­—åˆ—ã ã‘ "" åŸ‹ã‚ï¼ˆæ•°å€¤ãƒ»æ—¥ä»˜ä»¥å¤–ï¼‰
    for coln in df_detail.columns:
        if coln in ["å£²ä¸Š", "ç²—åˆ©"]:
            continue
        if pd.api.types.is_datetime64_any_dtype(df_detail[coln]) or str(df_detail[coln].dtype).startswith("dbdate"):
            continue
        if df_detail[coln].dtype == object or pd.api.types.is_string_dtype(df_detail[coln]):
            df_detail[coln] = df_detail[coln].fillna("")

    st.dataframe(
        df_detail.style.format({"å£²ä¸Š": "Â¥{:,.0f}", "ç²—åˆ©": "Â¥{:,.0f}"}),
        use_container_width=True,
        hide_index=True,
    )

        drill_params["parent_id"] = selected_parent_id

        sql_drill = f"""
            WITH fy AS (
              SELECT (
                EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END
              ) AS current_fy,
              DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
            ),
            base_raw AS (
              SELECT
                COALESCE(
                  NULLIF(NULLIF(TRIM(CAST({c(colmap,'yj_code')} AS STRING)), ''), '0'),
                  NULLIF(NULLIF(TRIM(CAST({c(colmap,'jan_code')} AS STRING)), ''), '0'),
                  TRIM(CAST({c(colmap,'product_name')} AS STRING))
                ) AS yj_key,
                REGEXP_REPLACE(CAST({c(colmap,'product_name')} AS STRING), r"[/ï¼].*$", "") AS product_base,
                SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy THEN {c(colmap,'sales_amount')} ELSE 0 END) AS ty_sales,
                SUM(CASE WHEN {c(colmap,'fiscal_year')} = current_fy - 1 AND {c(colmap,'sales_date')} <= py_today THEN {c(colmap,'sales_amount')} ELSE 0 END) AS py_sales
              FROM `{VIEW_UNIFIED}`
              CROSS JOIN fy
              {drill_filter_sql}
              GROUP BY yj_key, product_base
            ),
            base AS (
              SELECT
                yj_key AS yj_code,
                ARRAY_AGG(product_base ORDER BY ty_sales DESC LIMIT 1)[OFFSET(0)] AS product_name,
                SUM(ty_sales) AS ty_sales,
                SUM(py_sales) AS py_sales
              FROM base_raw
              GROUP BY yj_code
            )
            SELECT
              yj_code,
              product_name,
              ty_sales AS sales_amount,
              py_sales AS py_sales_amount,
              (ty_sales - py_sales) AS sales_diff_yoy
            FROM base
            WHERE ty_sales > 0 OR py_sales > 0
            ORDER BY sales_diff_yoy {sort_order}
        """
        df_drill = query_df_safe(client, sql_drill, drill_params, "Parent Drilldown")

        if not df_drill.empty:
            df_drill["product_name"] = df_drill["product_name"].apply(normalize_product_display_name)
            df_drill = df_drill.fillna(0)
            df_drill.insert(0, "è¦å› é †ä½", [get_parent_rank_icon(i + 1, perf_mode) for i in range(len(df_drill))])

            st.dataframe(
                df_drill[["è¦å› é †ä½", "product_name", "sales_amount", "py_sales_amount", "sales_diff_yoy"]].rename(
                    columns={
                        "product_name": "ä»£è¡¨å•†å“å(æˆåˆ†)",
                        "sales_amount": "ä»ŠæœŸå£²ä¸Š",
                        "py_sales_amount": "å‰å¹´åŒæœŸå£²ä¸Š",
                        "sales_diff_yoy": "å‰å¹´æ¯”å·®é¡",
                    }
                ).style.format(
                    {"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´åŒæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´æ¯”å·®é¡": "Â¥{:,.0f}"}
                ),
                use_container_width=True,
                hide_index=True,
            )
        else:
            st.info("è¦å› ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")


# -----------------------------
# YoYï¼ˆæç¤ºã‚³ãƒ¼ãƒ‰è¸è¥²ï¼šçœç•¥ï¼‰
# â€»ã‚ãªãŸã®è²¼ã£ãŸ render_yoy_section ã‚’ãã®ã¾ã¾ä½¿ã†å‰æ
# -----------------------------
def render_yoy_section(client: bigquery.Client, login_email: str, is_admin: bool, scope: ScopeFilter, colmap: Dict[str, str]) -> None:
    # ã“ã“ã¯ã€Œã‚ãªãŸã®è²¼ã£ãŸã‚³ãƒ¼ãƒ‰ã€ã‚’ãã®ã¾ã¾è²¼ã£ã¦ãã ã•ã„ï¼ˆé•·ã„ãŸã‚å‰²æ„›ã§ã¯ãªãã€é‹ç”¨ä¸Šã®éƒ½åˆï¼‰ã€‚
    # â€»æœ¬ç•ªã§ã¯ã‚ãªãŸã®æ—¢å­˜ render_yoy_section ã‚’ä¸¸ã”ã¨ã“ã®ä½ç½®ã«é…ç½®ã€‚
    st.info("render_yoy_section ã¯ã‚ãªãŸã®æç¤ºã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾é…ç½®ã—ã¦ãã ã•ã„ï¼ˆæœ¬ä½“ã¯çœç•¥ã›ãšé‹ç”¨ã‚³ãƒ¼ãƒ‰å´ã«å­˜åœ¨ã•ã›ã‚‹ï¼‰ã€‚")


# -----------------------------
# â˜… New Delivery Trendsï¼ˆæ ¹æ²»ä¿®æ­£ï¼‰
# -----------------------------
def render_new_delivery_trends(
    client: bigquery.Client,
    login_email: str,
    is_admin: bool,
    nd_colmap: Dict[str, str],
    unified_colmap: Dict[str, str],
) -> None:
    st.markdown("##### ğŸ“ˆ æ–°è¦ç´å“ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆã‚°ãƒ«ãƒ¼ãƒ— / å¾—æ„å…ˆ / å•†å“ï¼‰")

    # å¿…é ˆåˆ—ã ã‘æ­¢ã‚ã‚‹
    missing_required = nd_colmap.get("_missing_required")
    if missing_required:
        st.error("VIEW_NEW_DELIVERY ã®å¿…é ˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚VIEWå®šç¾©ï¼ˆåˆ—åï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.code(f"ä¸è¶³ã‚­ãƒ¼: {missing_required}")
        st.stop()

    # éç®¡ç†è€…ã¯ login_email ãŒå¿…è¦
    if (not is_admin) and (c(nd_colmap, "login_email") == "login_email"):
        st.error("VIEW_NEW_DELIVERY ã« login_email åˆ—ãŒç„¡ã„ãŸã‚ã€æ‹…å½“è€…ã‚¹ã‚³ãƒ¼ãƒ—çµã‚Šè¾¼ã¿ãŒã§ãã¾ã›ã‚“ã€‚")
        st.stop()

    # --- â˜… UI state keysï¼ˆrerunã§ã‚‚ä¿æŒï¼‰
    if "nd_trend_days" not in st.session_state:
        st.session_state.nd_trend_days = 60
    if "nd_trend_mode" not in st.session_state:
        st.session_state.nd_trend_mode = "ğŸ¢ ã‚°ãƒ«ãƒ¼ãƒ—"

    days = st.slider("å¯¾è±¡æœŸé–“ï¼ˆæ—¥ï¼‰", 7, 180, st.session_state.nd_trend_days, 1, key="nd_trend_days")
    mode = st.radio("è¡¨ç¤ºå˜ä½", ["ğŸ¢ ã‚°ãƒ«ãƒ¼ãƒ—", "ğŸ¥ å¾—æ„å…ˆ", "ğŸ’Š å•†å“"], horizontal=True, key="nd_trend_mode")

    where_ext = "" if is_admin else f"AND nd.{c(nd_colmap,'login_email')} = @login_email"
    base_params = None if is_admin else {"login_email": login_email}

    group_expr, _ = resolve_customer_group_sql_expr(client)

    # cust_dimï¼ˆVIEW_UNIFIED èµ·ç‚¹ï¼‰
    if group_expr:
        cust_dim_sql = f"""
          SELECT
            CAST({c(unified_colmap,'customer_code')} AS STRING) AS customer_code,
            ANY_VALUE(CAST({c(unified_colmap,'customer_name')} AS STRING)) AS customer_name,
            ANY_VALUE({group_expr}) AS group_name
          FROM `{VIEW_UNIFIED}`
          GROUP BY customer_code
        """
    else:
        cust_dim_sql = f"""
          SELECT
            CAST({c(unified_colmap,'customer_code')} AS STRING) AS customer_code,
            ANY_VALUE(CAST({c(unified_colmap,'customer_name')} AS STRING)) AS customer_name,
            'æœªè¨­å®š' AS group_name
          FROM `{VIEW_UNIFIED}`
          GROUP BY customer_code
        """

    # item_dimï¼ˆVIEW_UNIFIEDèµ·ç‚¹å„ªå…ˆï¼‰
    unified_has_jan = c(unified_colmap, "jan_code") != "jan_code"
    nd_has_pname = c(nd_colmap, "product_name") != "product_name"

    if unified_has_jan:
        item_dim_sql = f"""
          SELECT
            CAST({c(unified_colmap,'jan_code')} AS STRING) AS jan_code,
            ANY_VALUE(REGEXP_REPLACE(CAST({c(unified_colmap,'product_name')} AS STRING), r"[/ï¼].*$", "")) AS product_name
          FROM `{VIEW_UNIFIED}`
          GROUP BY jan_code
        """
    elif nd_has_pname:
        item_dim_sql = f"""
          SELECT
            CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) AS jan_code,
            ANY_VALUE(REGEXP_REPLACE(CAST(nd.{c(nd_colmap,'product_name')} AS STRING), r"[/ï¼].*$", "")) AS product_name
          FROM `{VIEW_NEW_DELIVERY}` nd
          GROUP BY jan_code
        """
    else:
        item_dim_sql = f"""
          SELECT
            CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) AS jan_code,
            'ä¸æ˜' AS product_name
          FROM `{VIEW_NEW_DELIVERY}` nd
          GROUP BY jan_code
        """

    # --- â˜… modeã”ã¨ã®é›†è¨ˆ
    if mode.startswith("ğŸ¢"):
        sql_parent = f"""
          WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today),
          cust_dim AS ({cust_dim_sql})
          SELECT
            COALESCE(cd.group_name, 'æœªè¨­å®š') AS group_name,
            COUNT(DISTINCT CAST(nd.{c(nd_colmap,'customer_code')} AS STRING)) AS customer_cnt,
            COUNT(DISTINCT CAST(nd.{c(nd_colmap,'jan_code')} AS STRING)) AS item_cnt,
            SUM(nd.{c(nd_colmap,'sales_amount')}) AS sales_amount,
            SUM(nd.{c(nd_colmap,'gross_profit')}) AS gross_profit
          FROM `{VIEW_NEW_DELIVERY}` nd
          CROSS JOIN td
          LEFT JOIN cust_dim cd
            ON CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) = cd.customer_code
          WHERE nd.{c(nd_colmap,'first_sales_date')} >= DATE_SUB(today, INTERVAL {days} DAY)
            {where_ext}
          GROUP BY group_name
          ORDER BY sales_amount DESC
          LIMIT 200
        """
        df_parent = query_df_safe(client, sql_parent, base_params, label="New Delivery Trend Groups")
        key_col = "group_name"
        title = "ğŸ¢ ã‚°ãƒ«ãƒ¼ãƒ—ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæ–°è¦ç´å“ï¼‰"

    elif mode.startswith("ğŸ¥"):
        sql_parent = f"""
          WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today),
          cust_dim AS ({cust_dim_sql})
          SELECT
            CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) AS customer_code,
            ANY_VALUE(cd.customer_name) AS customer_name,
            ANY_VALUE(COALESCE(cd.group_name, 'æœªè¨­å®š')) AS group_name,
            COUNT(DISTINCT CAST(nd.{c(nd_colmap,'jan_code')} AS STRING)) AS item_cnt,
            SUM(nd.{c(nd_colmap,'sales_amount')}) AS sales_amount,
            SUM(nd.{c(nd_colmap,'gross_profit')}) AS gross_profit
          FROM `{VIEW_NEW_DELIVERY}` nd
          CROSS JOIN td
          LEFT JOIN cust_dim cd
            ON CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) = cd.customer_code
          WHERE nd.{c(nd_colmap,'first_sales_date')} >= DATE_SUB(today, INTERVAL {days} DAY)
            {where_ext}
          GROUP BY customer_code
          ORDER BY sales_amount DESC
          LIMIT 200
        """
        df_parent = query_df_safe(client, sql_parent, base_params, label="New Delivery Trend Customers")
        key_col = "customer_code"
        title = "ğŸ¥ å¾—æ„å…ˆãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæ–°è¦ç´å“ï¼‰"

    else:
        sql_parent = f"""
          WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today),
          item_dim AS ({item_dim_sql})
          SELECT
            CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) AS jan_code,
            ANY_VALUE(id.product_name) AS product_name,
            COUNT(DISTINCT CAST(nd.{c(nd_colmap,'customer_code')} AS STRING)) AS customer_cnt,
            SUM(nd.{c(nd_colmap,'sales_amount')}) AS sales_amount,
            SUM(nd.{c(nd_colmap,'gross_profit')}) AS gross_profit
          FROM `{VIEW_NEW_DELIVERY}` nd
          CROSS JOIN td
          LEFT JOIN item_dim id
            ON CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) = id.jan_code
          WHERE nd.{c(nd_colmap,'first_sales_date')} >= DATE_SUB(today, INTERVAL {days} DAY)
            {where_ext}
          GROUP BY jan_code
          ORDER BY sales_amount DESC
          LIMIT 200
        """
        df_parent = query_df_safe(client, sql_parent, base_params, label="New Delivery Trend Products")
        key_col = "jan_code"
        title = "ğŸ’Š å•†å“ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæ–°è¦ç´å“ï¼‰"

    st.markdown(f"**{title}**")
    if df_parent.empty:
        st.info("è©²å½“æœŸé–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # --- â˜… data_editor ã® key ã‚’å›ºå®šï¼ˆmodeã”ã¨ã«åˆ¥keyï¼‰
    df_show = df_parent.copy()
    df_show.insert(0, "â˜‘", False)

    if key_col == "group_name":
        df_show = df_show.rename(columns={"group_name": "ã‚°ãƒ«ãƒ¼ãƒ—", "customer_cnt": "å¾—æ„å…ˆæ•°", "item_cnt": "å“ç›®æ•°", "sales_amount": "å£²ä¸Š", "gross_profit": "ç²—åˆ©"})
        display_cols = ["â˜‘", "ã‚°ãƒ«ãƒ¼ãƒ—", "å¾—æ„å…ˆæ•°", "å“ç›®æ•°", "å£²ä¸Š", "ç²—åˆ©"]
        pick_col = "ã‚°ãƒ«ãƒ¼ãƒ—"
    elif key_col == "customer_code":
        df_show = df_show.rename(columns={"customer_code": "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", "customer_name": "å¾—æ„å…ˆå", "group_name": "ã‚°ãƒ«ãƒ¼ãƒ—", "item_cnt": "å“ç›®æ•°", "sales_amount": "å£²ä¸Š", "gross_profit": "ç²—åˆ©"})
        display_cols = ["â˜‘", "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰", "å¾—æ„å…ˆå", "ã‚°ãƒ«ãƒ¼ãƒ—", "å“ç›®æ•°", "å£²ä¸Š", "ç²—åˆ©"]
        pick_col = "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰"
    else:
        df_show = df_show.rename(columns={"jan_code": "JAN", "product_name": "ä»£è¡¨å•†å“å", "customer_cnt": "å¾—æ„å…ˆæ•°", "sales_amount": "å£²ä¸Š", "gross_profit": "ç²—åˆ©"})
        display_cols = ["â˜‘", "JAN", "ä»£è¡¨å•†å“å", "å¾—æ„å…ˆæ•°", "å£²ä¸Š", "ç²—åˆ©"]
        pick_col = "JAN"

    edited = st.data_editor(
        df_show[display_cols].fillna(""),
        use_container_width=True,
        hide_index=True,
        disabled=[c_ for c_ in display_cols if c_ != "â˜‘"],
        column_config={"â˜‘": st.column_config.CheckboxColumn("é¸æŠ", help="æ˜ç´°ã‚’è¡¨ç¤ºã—ãŸã„è¡Œã«ãƒã‚§ãƒƒã‚¯ï¼ˆè¤‡æ•°å¯ï¼‰")},
        key=f"nd_trend_editor_{key_col}",  # â˜…å›ºå®š
    )

    sel_df = edited[edited["â˜‘"] == True]
    if sel_df.empty:
        st.caption("â˜‘ã«ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã¨ä¸‹ã«æ˜ç´°ãŒå‡ºã¾ã™ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰ã€‚")
        return

    selected_keys = sel_df[pick_col].astype(str).tolist()

    # --- æ˜ç´°ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã®ã¾ã¾ï¼‰
    st.divider()
    st.markdown("#### ğŸ§¾ æ˜ç´°ï¼ˆæ–°è¦ç´å“ Realizedï¼‰")

    base_where = f"nd.{c(nd_colmap,'first_sales_date')} >= DATE_SUB(today, INTERVAL {days} DAY) {where_ext}"

    if key_col == "group_name":
        params2 = {} if is_admin else {"login_email": login_email}
        params2["group_keys"] = selected_keys
        sql_detail = f"""
          WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today),
          cust_dim AS ({cust_dim_sql}),
          item_dim AS ({item_dim_sql})
          SELECT
            CAST(nd.{c(nd_colmap,'first_sales_date')} AS DATE) AS first_sales_date,
            COALESCE(cd.group_name, 'æœªè¨­å®š') AS group_name,
            CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) AS customer_code,
            ANY_VALUE(cd.customer_name) AS customer_name,
            CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) AS jan_code,
            ANY_VALUE(id.product_name) AS product_name,
            SUM(nd.{c(nd_colmap,'sales_amount')}) AS sales_amount,
            SUM(nd.{c(nd_colmap,'gross_profit')}) AS gross_profit
          FROM `{VIEW_NEW_DELIVERY}` nd
          CROSS JOIN td
          LEFT JOIN cust_dim cd
            ON CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) = cd.customer_code
          LEFT JOIN item_dim id
            ON CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) = id.jan_code
          WHERE {base_where}
            AND COALESCE(cd.group_name, 'æœªè¨­å®š') IN UNNEST(@group_keys)
          GROUP BY first_sales_date, group_name, customer_code, jan_code
          ORDER BY first_sales_date DESC, sales_amount DESC
          LIMIT 2000
        """
        df_detail = query_df_safe(client, sql_detail, params2, label="New Delivery Trend Group Details")

    elif key_col == "customer_code":
        params2 = {} if is_admin else {"login_email": login_email}
        params2["customer_keys"] = selected_keys
        sql_detail = f"""
          WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today),
          cust_dim AS ({cust_dim_sql}),
          item_dim AS ({item_dim_sql})
          SELECT
            CAST(nd.{c(nd_colmap,'first_sales_date')} AS DATE) AS first_sales_date,
            COALESCE(cd.group_name, 'æœªè¨­å®š') AS group_name,
            CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) AS customer_code,
            ANY_VALUE(cd.customer_name) AS customer_name,
            CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) AS jan_code,
            ANY_VALUE(id.product_name) AS product_name,
            SUM(nd.{c(nd_colmap,'sales_amount')}) AS sales_amount,
            SUM(nd.{c(nd_colmap,'gross_profit')}) AS gross_profit
          FROM `{VIEW_NEW_DELIVERY}` nd
          CROSS JOIN td
          LEFT JOIN cust_dim cd
            ON CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) = cd.customer_code
          LEFT JOIN item_dim id
            ON CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) = id.jan_code
          WHERE {base_where}
            AND CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) IN UNNEST(@customer_keys)
          GROUP BY first_sales_date, group_name, customer_code, jan_code
          ORDER BY first_sales_date DESC, sales_amount DESC
          LIMIT 2000
        """
        df_detail = query_df_safe(client, sql_detail, params2, label="New Delivery Trend Customer Details")

    else:
        params2 = {} if is_admin else {"login_email": login_email}
        params2["jan_keys"] = selected_keys
        sql_detail = f"""
          WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today),
          cust_dim AS ({cust_dim_sql}),
          item_dim AS ({item_dim_sql})
          SELECT
            CAST(nd.{c(nd_colmap,'first_sales_date')} AS DATE) AS first_sales_date,
            COALESCE(cd.group_name, 'æœªè¨­å®š') AS group_name,
            CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) AS customer_code,
            ANY_VALUE(cd.customer_name) AS customer_name,
            CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) AS jan_code,
            ANY_VALUE(id.product_name) AS product_name,
            SUM(nd.{c(nd_colmap,'sales_amount')}) AS sales_amount,
            SUM(nd.{c(nd_colmap,'gross_profit')}) AS gross_profit
          FROM `{VIEW_NEW_DELIVERY}` nd
          CROSS JOIN td
          LEFT JOIN cust_dim cd
            ON CAST(nd.{c(nd_colmap,'customer_code')} AS STRING) = cd.customer_code
          LEFT JOIN item_dim id
            ON CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) = id.jan_code
          WHERE {base_where}
            AND CAST(nd.{c(nd_colmap,'jan_code')} AS STRING) IN UNNEST(@jan_keys)
          GROUP BY first_sales_date, group_name, customer_code, jan_code
          ORDER BY first_sales_date DESC, sales_amount DESC
          LIMIT 2000
        """
        df_detail = query_df_safe(client, sql_detail, params2, label="New Delivery Trend Product Details")

    if df_detail.empty:
        st.info("æ˜ç´°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df_detail = df_detail.rename(
        columns={
            "first_sales_date": "åˆå›ç´å“æ—¥",
            "group_name": "ã‚°ãƒ«ãƒ¼ãƒ—",
            "customer_code": "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰",
            "customer_name": "å¾—æ„å…ˆå",
            "jan_code": "JAN",
            "product_name": "å•†å“å",
            "sales_amount": "å£²ä¸Š",
            "gross_profit": "ç²—åˆ©",
        }
    )

    st.dataframe(
        df_detail.fillna("").style.format({"å£²ä¸Š": "Â¥{:,.0f}", "ç²—åˆ©": "Â¥{:,.0f}"}),
        use_container_width=True,
        hide_index=True,
    )

def render_new_deliveries_section(client: bigquery.Client, login_email: str, is_admin: bool, colmap: Dict[str, str]) -> None:
    st.subheader("ğŸ‰ æ–°è¦ç´å“ã‚µãƒãƒªãƒ¼ï¼ˆRealized / å®Ÿç¸¾ï¼‰")

    nd_colmap = resolve_new_delivery_colmap(client)
    missing = nd_colmap.get("_missing_required")
    if missing:
        st.error("VIEW_NEW_DELIVERY ã®å¿…é ˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚VIEWå®šç¾©ï¼ˆåˆ—åï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.code(f"ä¸è¶³ã‚­ãƒ¼: {missing}")
        st.stop()

    # éç®¡ç†è€…ã¯ login_email åˆ—ãŒå¿…é ˆ
    if (not is_admin) and (c(nd_colmap, "login_email") == "login_email"):
        st.error("VIEW_NEW_DELIVERY ã« login_email åˆ—ãŒç„¡ã„ãŸã‚ã€æ‹…å½“è€…ã‚¹ã‚³ãƒ¼ãƒ—çµã‚Šè¾¼ã¿ãŒã§ãã¾ã›ã‚“ã€‚")
        st.code("å¯¾å‡¦: VIEW_NEW_DELIVERY ã« login_email ã‚’è¿½åŠ ã™ã‚‹ã‹ã€nd_colmap mapping ã«å®Ÿåˆ—åã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # --- â˜… ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ï¼ˆå·»ãæˆ»ã‚Šé˜²æ­¢ï¼‰
    if "nd_summary_loaded" not in st.session_state:
        st.session_state.nd_summary_loaded = False
    if "nd_summary_df" not in st.session_state:
        st.session_state.nd_summary_df = pd.DataFrame()

    # èª­è¾¼ãƒœã‚¿ãƒ³ï¼ˆãƒˆãƒªã‚¬ãƒ¼ã ã‘ï¼‰
    if st.button("æ–°è¦ç´å“å®Ÿç¸¾ã‚’èª­ã¿è¾¼ã‚€", key="btn_new_deliv"):
        where_ext = "" if is_admin else f"AND {c(nd_colmap,'login_email')} = @login_email"
        params = None if is_admin else {"login_email": login_email}

        sql = f"""
        WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today)
        SELECT
          'â‘  æ˜¨æ—¥' AS `æœŸé–“`,
          COUNT(DISTINCT CAST({c(nd_colmap,'customer_code')} AS STRING)) AS `å¾—æ„å…ˆæ•°`,
          COUNT(DISTINCT CAST({c(nd_colmap,'jan_code')} AS STRING)) AS `å“ç›®æ•°`,
          SUM({c(nd_colmap,'sales_amount')}) AS `å£²ä¸Š`,
          SUM({c(nd_colmap,'gross_profit')}) AS `ç²—åˆ©`
        FROM `{VIEW_NEW_DELIVERY}` CROSS JOIN td
        WHERE {c(nd_colmap,'first_sales_date')} = DATE_SUB(today, INTERVAL 1 DAY) {where_ext}
        UNION ALL
        SELECT
          'â‘¡ ç›´è¿‘7æ—¥',
          COUNT(DISTINCT CAST({c(nd_colmap,'customer_code')} AS STRING)),
          COUNT(DISTINCT CAST({c(nd_colmap,'jan_code')} AS STRING)),
          SUM({c(nd_colmap,'sales_amount')}),
          SUM({c(nd_colmap,'gross_profit')})
        FROM `{VIEW_NEW_DELIVERY}` CROSS JOIN td
        WHERE {c(nd_colmap,'first_sales_date')} >= DATE_SUB(today, INTERVAL 7 DAY) {where_ext}
        UNION ALL
        SELECT
          'â‘¢ å½“æœˆ',
          COUNT(DISTINCT CAST({c(nd_colmap,'customer_code')} AS STRING)),
          COUNT(DISTINCT CAST({c(nd_colmap,'jan_code')} AS STRING)),
          SUM({c(nd_colmap,'sales_amount')}),
          SUM({c(nd_colmap,'gross_profit')})
        FROM `{VIEW_NEW_DELIVERY}` CROSS JOIN td
        WHERE DATE_TRUNC({c(nd_colmap,'first_sales_date')}, MONTH) = DATE_TRUNC(today, MONTH) {where_ext}
        ORDER BY `æœŸé–“`
        """

        df_new = query_df_safe(client, sql, params, label="New Deliveries")
        st.session_state.nd_summary_df = df_new.copy()
        st.session_state.nd_summary_loaded = True

    # --- â˜… ã“ã“ã‹ã‚‰ä¸‹ã¯ã€Œèª­ã¿è¾¼ã¿æ¸ˆã¿ãªã‚‰å¸¸ã«è¡¨ç¤ºã€ï¼å·»ãæˆ»ã‚‰ãªã„
    if not st.session_state.nd_summary_loaded:
        st.info("ä¸Šã®ãƒœã‚¿ãƒ³ã§æ–°è¦ç´å“å®Ÿç¸¾ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚")
        return

    df_new = st.session_state.nd_summary_df
    if df_new is None or df_new.empty:
        st.info("æ–°è¦ç´å“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        df_new = df_new.copy()
        for coln in ["å£²ä¸Š", "ç²—åˆ©"]:
            if coln in df_new.columns:
                df_new[coln] = df_new[coln].fillna(0)

        st.dataframe(
            df_new.style.format({"å£²ä¸Š": "Â¥{:,.0f}", "ç²—åˆ©": "Â¥{:,.0f}"}),
            use_container_width=True,
            hide_index=True,
        )

    st.divider()
    # â˜… ãƒˆãƒ¬ãƒ³ãƒ‰UIã‚‚å¸¸æ™‚æç”»
    render_new_delivery_trends(client, login_email, is_admin, nd_colmap, colmap)


# -----------------------------
# Adoption / Drilldownï¼ˆæç¤ºã‚³ãƒ¼ãƒ‰è¸è¥²ï¼šçœç•¥ï¼‰
# -----------------------------
def render_adoption_alerts_section(client: bigquery.Client, login_email: str, is_admin: bool) -> None:
    st.info("render_adoption_alerts_section ã¯ã‚ãªãŸã®æç¤ºã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾é…ç½®ã—ã¦ãã ã•ã„ï¼ˆçœç•¥ã›ãšé‹ç”¨ã‚³ãƒ¼ãƒ‰å´ã«å­˜åœ¨ã•ã›ã‚‹ï¼‰ã€‚")


def render_customer_drilldown(client: bigquery.Client, login_email: str, is_admin: bool, scope: ScopeFilter, colmap: Dict[str, str]) -> None:
    st.info("render_customer_drilldown ã¯ã‚ãªãŸã®æç¤ºã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾é…ç½®ã—ã¦ãã ã•ã„ï¼ˆçœç•¥ã›ãšé‹ç”¨ã‚³ãƒ¼ãƒ‰å´ã«å­˜åœ¨ã•ã›ã‚‹ï¼‰ã€‚")


# -----------------------------
# 5. Main Loop
# -----------------------------
def main() -> None:
    set_page()
    client = setup_bigquery_client()

    # ColMap è§£æ±ºï¼ˆèµ·å‹•ç›´å¾Œã«å¿…é ˆåˆ—ä¸è¶³ã‚’æ¤œå‡ºã—ã¦åœæ­¢ï¼‰
    colmap = resolve_unified_colmap(client)
    missing = colmap.get("_missing_required")
    if missing:
        st.error("VIEW_UNIFIED ã®å¿…é ˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚VIEWå®šç¾©ï¼ˆåˆ—åï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.code(f"ä¸è¶³ã‚­ãƒ¼: {missing}")
        st.stop()

    with st.sidebar:
        st.header("ğŸ”‘ ãƒ­ã‚°ã‚¤ãƒ³")
        login_id = st.text_input("ãƒ­ã‚°ã‚¤ãƒ³ID (ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹)")
        login_pw = st.text_input("ãƒ‘ã‚¹ã‚³ãƒ¼ãƒ‰ (æºå¸¯ä¸‹4æ¡)", type="password")

        st.divider()
        st.session_state.use_bqstorage = st.checkbox("é«˜é€Ÿèª­è¾¼ (Storage API)", value=True)

        if st.button("ğŸ“¡ é€šä¿¡ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"):
            try:
                client.query("SELECT 1").result(timeout=10)
                st.success("BigQuery æ¥ç¶šæ­£å¸¸")
            except Exception as e:
                st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")

        if st.button("ğŸ§¹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"):
            st.cache_data.clear()
            st.cache_resource.clear()

        with st.expander("ğŸ”§ VIEW_UNIFIED åˆ—ãƒãƒƒãƒ—ï¼ˆè‡ªå‹•è§£æ±ºçµæœï¼‰", expanded=False):
            st.json(colmap)

        with st.expander("ğŸ”§ VIEW_NEW_DELIVERY åˆ—ãƒãƒƒãƒ—ï¼ˆè‡ªå‹•è§£æ±ºçµæœï¼‰", expanded=False):
            st.json(resolve_new_delivery_colmap(client))

    if not login_id or not login_pw:
        st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
        return

    role = resolve_role(client, login_id.strip(), login_pw.strip())
    if not role.is_authenticated:
        st.error("âŒ ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    st.success(f"ğŸ”“ ãƒ­ã‚°ã‚¤ãƒ³ä¸­: {role.staff_name} ã•ã‚“")
    c1, c2, c3 = st.columns(3)
    c1.metric("ğŸ‘¤ æ‹…å½“", role.staff_name)
    c2.metric("ğŸ›¡ï¸ æ¨©é™", role.role_key)
    c3.metric("ğŸ“ é›»è©±", role.phone)
    st.divider()

    # è¡¨ç¤ºé †åºï¼šã‚µãƒãƒªãƒ¼ â†’ ã‚¹ã‚³ãƒ¼ãƒ— â†’ æœ¬ä½“
    if role.role_admin_view:
        render_fytd_org_section(client, colmap)
    else:
        render_fytd_me_section(client, role.login_email, colmap)

    st.divider()

    scope = render_scope_filters(client, role)
    st.divider()

    if role.role_admin_view:
        render_group_underperformance_section(client, role, scope, colmap)
        st.divider()
        render_yoy_section(client, role.login_email, is_admin=True, scope=scope, colmap=colmap)
        st.divider()
        render_new_deliveries_section(client, role.login_email, is_admin=True, colmap=colmap)
        st.divider()
        render_adoption_alerts_section(client, role.login_email, is_admin=True)
        st.divider()
        render_customer_drilldown(client, role.login_email, is_admin=True, scope=scope, colmap=colmap)
    else:
        render_yoy_section(client, role.login_email, is_admin=False, scope=scope, colmap=colmap)
        st.divider()
        render_new_deliveries_section(client, role.login_email, is_admin=False, colmap=colmap)
        st.divider()
        render_adoption_alerts_section(client, role.login_email, is_admin=False)
        st.divider()
        render_customer_drilldown(client, role.login_email, is_admin=False, scope=scope, colmap=colmap)


if __name__ == "__main__":
    main()
