# -*- coding: utf-8 -*-
"""
SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - OS v1.4.9 (True "è¸è¥²ï¼‹è¿½åŠ " / Backward Compatible)

ã€è¸è¥²ï¼ˆv1.4.8ã®æ—¢å­˜æ©Ÿèƒ½ã¯ç¶­æŒï¼‰ã€‘
- YoYï¼šVIEW_UNIFIED ã‹ã‚‰å‹•çš„é›†è¨ˆã«çµ±ä¸€ï¼ˆYJåŒä¸€ã§å•†å“åãŒ2è¡Œå•é¡Œã‚’æŠ‘æ­¢ï¼‰
- YoYï¼šç¬¬ä¸€éšå±¤ã‚’ã€Œã‚¯ãƒªãƒƒã‚¯é¸æŠã€å¯¾å¿œï¼ˆãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿ã§ã‚‚é¸æŠä¿æŒï¼‰
- ã‚¹ã‚³ãƒ¼ãƒ—ï¼šå¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ—åˆ—å€™è£œã‚’ VIEW_UNIFIED ã®ã‚¹ã‚­ãƒ¼ãƒã‹ã‚‰è‡ªå‹•åˆ¤å®š
- Group Display: officialå…ˆé ­ + rawä½µè¨˜
- å¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ— / å¾—æ„å…ˆå˜ä½“ã®åˆ‡æ›¿ ï¼† å•†å“è¦å› ãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ï¼ˆå…¨ä»¶è¡¨ç¤ºï¼‰
- é †ä½ã‚¢ã‚¤ã‚³ãƒ³ã€ä¸è¦YJåˆ—ã®éè¡¨ç¤ºã€WHEREäºŒé‡å¯¾ç­–ã€é¸æŠæ¶ˆå¤±ãƒã‚°å¯¾ç­–ã€è¡¨ç¤ºé †åºæœ€é©åŒ–
- â˜…Recoï¼ˆVIEW_RECOMMENDï¼‰ã® customer_code ãŒ INT64 ã®ãŸã‚ CASTå¯¾å¿œï¼ˆv1.4.8è¸è¥²ï¼‰

ã€è¿½åŠ ï¼ˆä»Šå›ã®å¿…é ˆè¦ä»¶ï¼‰ã€‘
- â˜…factåˆ—åã®è‡ªå‹•è§£æ±ºï¼ˆjan/pack/yj ç­‰ï¼‰ã‚’ã€ŒVIEW_UNIFIEDã ã‘ã§ãªãã€é–¢é€£VIEWã«ã‚‚æ‹¡å¼µ
  â†’ å®Ÿåƒã‚¢ãƒ—ãƒªã‚’å£Šã•ãªã„ãŸã‚ã€Œå¾Œæ–¹äº’æ›ï¼ˆæ—§åˆ—åå„ªå…ˆ + å€™è£œå¸å + è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ã€ã§å®Ÿè£…
- â˜…ç®¡ç†è€…ã‚¹ã‚³ãƒ¼ãƒ—å¿…é ˆï¼ˆãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ã¯æ˜ç¤ºè¨±å¯ï¼‹ä¸Šé™bytesè¨­å®šï¼‹æ¨å®šå¿…é ˆã®æ®µéšUIï¼‰
- â˜…å…¨ä»¶è¡¨ç¤ºã®æ®µéšUIï¼ˆæ¨å®šã‚³ã‚¹ãƒˆè¡¨ç¤ºï¼‹maximumBytesBilledè¨­å®šï¼‰
  â†’ æ¨å®šï¼ˆDry Runï¼‰â†’ åŒæ„/ä¸Šé™è¨­å®š â†’ å®Ÿè¡Œ ã®é †ã§çµ±åˆ¶
"""

from __future__ import annotations

from dataclasses import dataclass
import re
from typing import Any, Dict, Optional, Tuple, List

import pandas as pd
import streamlit as st
from google.cloud import bigquery
from google.oauth2 import service_account
from pandas.api.types import is_numeric_dtype


# -----------------------------
# 1. Configuration (è¨­å®š)
# -----------------------------
APP_TITLE = "SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"
DEFAULT_LOCATION = "asia-northeast1"
PROJECT_DEFAULT = "salesdb-479915"
DATASET_DEFAULT = "sales_data"

VIEW_UNIFIED = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_unified_grouped"
VIEW_ROLE_CLEAN = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.dim_staff_role_clean"
VIEW_NEW_DELIVERY = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_new_deliveries_realized_daily_fact_all_months"
VIEW_RECOMMEND = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_recommendation_engine"
VIEW_ADOPTION = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_customer_adoption_status"

CUSTOMER_GROUP_COLUMN_CANDIDATES = (
    "customer_group_display",
    "customer_group_official",
    "customer_group_raw",
    "sales_group_name",
)

# ã‚³ã‚¹ãƒˆæ¨å®šã®å‚è€ƒå€¤ï¼ˆBigQueryã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ï¼šæ¦‚ã­ $5 / TB ãŒç›®å®‰ã€‚é‹ç”¨ã§å¤‰ãˆã‚‹ãªã‚‰UIã§å¤‰æ›´å¯èƒ½ï¼‰
DEFAULT_USD_PER_TB = 5.0
DEFAULT_USDJPY = 150.0  # ç›®å®‰ï¼ˆå®Ÿé‹ç”¨ã¯UIã§èª¿æ•´ï¼‰
BYTES_PER_TB = 1024 ** 4


# -----------------------------
# 2. Helpers (è¡¨ç¤ºç”¨)
# -----------------------------
def set_page() -> None:
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)
    st.caption("OS v1.4.9ï½œå®Ÿåƒç¶­æŒ + åˆ—åå·®ç•°å¸å + ç®¡ç†è€…ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³çµ±åˆ¶ï¼ˆæ¨å®šâ†’åŒæ„â†’å®Ÿè¡Œï¼‰")


def create_default_column_config(df: pd.DataFrame) -> Dict[str, st.column_config.Column]:
    config: Dict[str, st.column_config.Column] = {}
    for col in df.columns:
        if any(k in col for k in ["å£²ä¸Š", "ç²—åˆ©", "é‡‘é¡", "å·®é¡", "å®Ÿç¸¾", "äºˆæ¸¬", "GAP"]):
            config[col] = st.column_config.NumberColumn(col, format="Â¥%d")
        elif any(k in col for k in ["ç‡", "æ¯”", "ãƒšãƒ¼ã‚¹"]):
            config[col] = st.column_config.NumberColumn(col, format="%.1f%%")
        elif "æ—¥" in col or pd.api.types.is_datetime64_any_dtype(df[col]):
            config[col] = st.column_config.DateColumn(col, format="YYYY-MM-DD")
        elif is_numeric_dtype(df[col]):
            config[col] = st.column_config.NumberColumn(col, format="%d")
        else:
            config[col] = st.column_config.TextColumn(col)
    return config


def get_safe_float(row: pd.Series, key: str) -> float:
    val = row.get(key)
    return float(val) if not pd.isna(val) else 0.0


def normalize_product_display_name(name: Any) -> str:
    if pd.isna(name):
        return ""
    text = str(name).strip()
    text = re.sub(r"[/ï¼].*$", "", text)
    return text.strip()


def bq_ident(name: str) -> str:
    """BigQueryè­˜åˆ¥å­ï¼ˆåˆ—åï¼‰ã‚’ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆã§å›²ã‚€ã€‚"""
    s = str(name).strip()
    if not s:
        raise ValueError("Empty identifier")
    if not re.fullmatch(r"[A-Za-z_][A-Za-z0-9_]*", s):
        raise ValueError(f"Unsafe identifier: {s}")
    return f"`{s}`"


# -----------------------------
# 3. BigQuery Connection & Auth
# -----------------------------
@st.cache_resource
def setup_bigquery_client() -> bigquery.Client:
    bq = st.secrets["bigquery"]
    sa_info = dict(bq["service_account"])
    scopes = [
        "https://www.googleapis.com/auth/bigquery",
        "https://www.googleapis.com/auth/drive",
        "https://www.googleapis.com/auth/spreadsheets",
    ]
    creds = service_account.Credentials.from_service_account_info(sa_info, scopes=scopes)
    return bigquery.Client(
        project=PROJECT_DEFAULT,
        credentials=creds,
        location=DEFAULT_LOCATION,
    )


def _normalize_param(value: Any) -> Tuple[str, Optional[Any]]:
    if isinstance(value, tuple) and len(value) == 2:
        p_type, p_value = value
        return str(p_type).upper(), p_value

    if value is None:
        return "STRING", None
    if isinstance(value, bool):
        return "BOOL", value
    if isinstance(value, int):
        return "INT64", value
    if isinstance(value, float):
        return "FLOAT64", value
    if isinstance(value, pd.Timestamp):
        return "TIMESTAMP", value.to_pydatetime()

    return "STRING", str(value)


def query_df_safe(
    client: bigquery.Client,
    sql: str,
    params: Optional[Dict[str, Any]] = None,
    label: str = "",
    timeout_sec: int = 60,
    maximum_bytes_billed: Optional[int] = None,
) -> pd.DataFrame:
    use_bqstorage = st.session_state.get("use_bqstorage", True)
    try:
        job_config = bigquery.QueryJobConfig()
        if params:
            query_params = []
            for key, raw_value in params.items():
                p_type, p_value = _normalize_param(raw_value)
                query_params.append(bigquery.ScalarQueryParameter(key, p_type, p_value))
            job_config.query_parameters = query_params

        if maximum_bytes_billed is not None:
            job_config.maximum_bytes_billed = int(maximum_bytes_billed)

        job = client.query(sql, job_config=job_config)
        job.result(timeout=timeout_sec)
        return job.to_dataframe(create_bqstorage_client=use_bqstorage)
    except Exception as e:
        st.error(f"ã‚¯ã‚¨ãƒªã‚¨ãƒ©ãƒ¼ ({label}):\n{e}")
        return pd.DataFrame()


def estimate_query_bytes(
    client: bigquery.Client,
    sql: str,
    params: Optional[Dict[str, Any]] = None,
    label: str = "Estimate",
) -> Optional[int]:
    """DryRunã§å‡¦ç†ãƒã‚¤ãƒˆæ•°æ¨å®šï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰ã€‚"""
    try:
        job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)
        if params:
            query_params = []
            for key, raw_value in params.items():
                p_type, p_value = _normalize_param(raw_value)
                query_params.append(bigquery.ScalarQueryParameter(key, p_type, p_value))
            job_config.query_parameters = query_params

        job = client.query(sql, job_config=job_config)
        return int(job.total_bytes_processed or 0)
    except Exception as e:
        st.warning(f"æ¨å®šã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆ{label}ï¼‰: {e}")
        return None


def bytes_to_human(n: int) -> str:
    if n < 1024:
        return f"{n} B"
    units = ["KB", "MB", "GB", "TB", "PB"]
    v = float(n)
    for u in units:
        v /= 1024.0
        if v < 1024.0:
            return f"{v:.2f} {u}"
    return f"{v:.2f} EB"


def estimate_cost_jpy(bytes_processed: int, usd_per_tb: float, usd_jpy: float) -> float:
    tb = bytes_processed / BYTES_PER_TB
    return tb * float(usd_per_tb) * float(usd_jpy)


@dataclass(frozen=True)
class RoleInfo:
    is_authenticated: bool = False
    login_email: str = ""
    staff_name: str = "ã‚²ã‚¹ãƒˆ"
    role_key: str = "GUEST"
    role_admin_view: bool = False
    phone: str = "-"


@dataclass(frozen=True)
class ScopeFilter:
    predicates: tuple[str, ...] = ()
    params: Dict[str, Any] | None = None

    def where_clause(self) -> str:
        if not self.predicates:
            return ""
        return " AND ".join(self.predicates)

    def is_empty(self) -> bool:
        return not self.predicates


@dataclass(frozen=True)
class AdminScanPolicy:
    require_scope: bool = True
    allow_full_scan: bool = False
    max_bytes_billed: int = 0  # 0 means "no limit" (not recommended)
    must_estimate_before_run: bool = True


def _compose_where(*parts: str) -> str:
    clauses = [p.strip() for p in parts if p and p.strip()]
    if not clauses:
        return ""
    return "WHERE " + " AND ".join(clauses)


def _split_table_fqn(table_fqn: str) -> Tuple[str, str, str]:
    parts = table_fqn.split(".")
    if len(parts) != 3:
        raise ValueError(f"Invalid table FQN: {table_fqn}")
    return parts[0], parts[1], parts[2]


# -----------------------------
# 3.1 Schema utilities (åˆ—åå·®ç•°å¸åã®åŸºç›¤)
# -----------------------------
@st.cache_data(ttl=3600)
def get_table_columns_lower(_client: bigquery.Client, table_fqn: str) -> set[str]:
    project_id, dataset_id, table_name = _split_table_fqn(table_fqn)
    sql = f"""
        SELECT column_name
        FROM `{project_id}.{dataset_id}.INFORMATION_SCHEMA.COLUMNS`
        WHERE table_name = @table_name
    """
    df = query_df_safe(_client, sql, {"table_name": table_name}, f"Schema Check: {table_name}")
    if df.empty or "column_name" not in df.columns:
        return set()
    return {str(c).lower() for c in df["column_name"].dropna().tolist()}


def resolve_col(table_fqn: str, cols_lower: set[str], candidates: List[str], required: bool = True) -> Optional[str]:
    """
    candidatesã®å…ˆé ­ã‹ã‚‰é †ã«å­˜åœ¨ç¢ºèªã—ã€æœ€åˆã«è¦‹ã¤ã‹ã£ãŸå®Ÿåˆ—åï¼ˆå€™è£œæ–‡å­—åˆ—ãã®ã¾ã¾ï¼‰ã‚’è¿”ã™ã€‚
    â€»å¾Œæ–¹äº’æ›ã®ãŸã‚ã€Œæ—§åˆ—åã‚’å…ˆé ­ã€ã«ç½®ãã€‚
    """
    for c in candidates:
        if c.lower() in cols_lower:
            return c
    if required:
        return None
    return None


@st.cache_data(ttl=3600)
def resolve_view_columns_map(_client: bigquery.Client) -> Dict[str, Dict[str, str]]:
    """
    ä¸»è¦VIEWã«ã¤ã„ã¦ã€å¿…è¦åˆ—ã®â€œå®Ÿåˆ—åâ€ã‚’è‡ªå‹•è§£æ±ºã—ã¦è¿”ã™ã€‚
    ã“ã“ãŒã€Œäº‹å‰ã«å¸åã§ãã‚‹ãƒã‚°ã€ã‚’æ½°ã™ä¸­æ ¸ã€‚
    """
    m: Dict[str, Dict[str, str]] = {}

    # --- VIEW_UNIFIEDï¼ˆfactï¼‰
    cols_u = get_table_columns_lower(_client, VIEW_UNIFIED)
    unified = {}

    # å¾Œæ–¹äº’æ›å„ªå…ˆï¼šä»Šã¾ã§ã®å®Ÿåƒã§ä½¿ã£ã¦ãŸåˆ—åã‚’å…ˆé ­ã«ç½®ã
    unified["customer_code"] = resolve_col(VIEW_UNIFIED, cols_u, ["customer_code", "customer_cd", "cust_code"], True) or ""
    unified["customer_name"] = resolve_col(VIEW_UNIFIED, cols_u, ["customer_name", "customer_nm", "cust_name"], True) or ""
    unified["login_email"] = resolve_col(VIEW_UNIFIED, cols_u, ["login_email", "email", "user_email"], True) or ""
    unified["staff_name"] = resolve_col(VIEW_UNIFIED, cols_u, ["staff_name", "æ‹…å½“ç¤¾å“¡å", "æ‹…å½“è€…å", "sales_name"], False) or "staff_name"

    # é‡è¦ã‚­ãƒ¼ï¼ˆå·®ç•°å¸åã®å¿…é ˆï¼‰
    unified["yj_code"] = resolve_col(VIEW_UNIFIED, cols_u, ["yj_code", "yj", "YJCode", "YJ_CODE"], False) or "yj_code"
    unified["jan_code"] = resolve_col(VIEW_UNIFIED, cols_u, ["jan_code", "jan", "JAN", "JAN_CODE"], False) or "jan_code"
    unified["product_name"] = resolve_col(VIEW_UNIFIED, cols_u, ["product_name", "item_name", "å•†å“åç§°", "item_nm"], True) or ""
    unified["package_unit"] = resolve_col(VIEW_UNIFIED, cols_u, ["package_unit", "pack_unit", "pack", "åŒ…è£…å˜ä½", "packaging"], False) or "package_unit"

    unified["sales_date"] = resolve_col(VIEW_UNIFIED, cols_u, ["sales_date", "date", "è²©å£²æ—¥"], True) or ""
    unified["fiscal_year"] = resolve_col(VIEW_UNIFIED, cols_u, ["fiscal_year", "FY", "ä¼šè¨ˆå¹´åº¦"], True) or ""
    unified["sales_amount"] = resolve_col(VIEW_UNIFIED, cols_u, ["sales_amount", "sales", "å£²ä¸Š", "åˆè¨ˆä¾¡æ ¼"], True) or ""
    unified["gross_profit"] = resolve_col(VIEW_UNIFIED, cols_u, ["gross_profit", "gp", "ç²—åˆ©"], True) or ""

    m["unified"] = unified

    # --- VIEW_NEW_DELIVERYï¼ˆæ–°è¦ç´å“ï¼‰
    cols_nd = get_table_columns_lower(_client, VIEW_NEW_DELIVERY)
    nd = {}
    nd["first_sales_date"] = resolve_col(VIEW_NEW_DELIVERY, cols_nd, ["first_sales_date", "first_sale_date", "first_date"], True) or ""
    nd["customer_code"] = resolve_col(VIEW_NEW_DELIVERY, cols_nd, ["customer_code", "customer_cd"], True) or ""
    nd["jan_code"] = resolve_col(VIEW_NEW_DELIVERY, cols_nd, ["jan_code", "jan", "JAN"], True) or ""
    nd["sales_amount"] = resolve_col(VIEW_NEW_DELIVERY, cols_nd, ["sales_amount", "sales", "å£²ä¸Š"], True) or ""
    nd["gross_profit"] = resolve_col(VIEW_NEW_DELIVERY, cols_nd, ["gross_profit", "gp", "ç²—åˆ©"], True) or ""
    nd["login_email"] = resolve_col(VIEW_NEW_DELIVERY, cols_nd, ["login_email", "email", "user_email"], False)  # ç„¡ã„VIEWã‚‚ã‚ã‚‹
    m["new_delivery"] = nd

    # --- VIEW_ADOPTIONï¼ˆæ¡ç”¨ãƒ»å¤±æ³¨ã‚¢ãƒ©ãƒ¼ãƒˆï¼‰
    cols_ad = get_table_columns_lower(_client, VIEW_ADOPTION)
    ad = {}
    ad["login_email"] = resolve_col(VIEW_ADOPTION, cols_ad, ["login_email", "email", "user_email"], False)
    ad["staff_name"] = resolve_col(VIEW_ADOPTION, cols_ad, ["staff_name", "æ‹…å½“è€…å"], False)
    ad["customer_code"] = resolve_col(VIEW_ADOPTION, cols_ad, ["customer_code", "customer_cd"], True) or ""
    ad["customer_name"] = resolve_col(VIEW_ADOPTION, cols_ad, ["customer_name", "customer_nm"], True) or ""
    ad["product_name"] = resolve_col(VIEW_ADOPTION, cols_ad, ["product_name", "item_name", "å•†å“å"], True) or ""
    ad["last_purchase_date"] = resolve_col(VIEW_ADOPTION, cols_ad, ["last_purchase_date", "last_date", "æœ€çµ‚è³¼å…¥æ—¥"], True) or ""
    ad["adoption_status"] = resolve_col(VIEW_ADOPTION, cols_ad, ["adoption_status", "status", "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"], True) or ""
    ad["current_fy_sales"] = resolve_col(VIEW_ADOPTION, cols_ad, ["current_fy_sales", "cur_sales", "ä»ŠæœŸå£²ä¸Š"], True) or ""
    ad["previous_fy_sales"] = resolve_col(VIEW_ADOPTION, cols_ad, ["previous_fy_sales", "py_sales", "å‰æœŸå£²ä¸Š"], True) or ""
    m["adoption"] = ad

    # --- VIEW_RECOMMENDï¼ˆRecoï¼‰
    cols_rc = get_table_columns_lower(_client, VIEW_RECOMMEND)
    rc = {}
    rc["customer_code"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["customer_code", "customer_cd"], True) or ""
    rc["customer_name"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["customer_name", "customer_nm"], False)
    rc["strong_category"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["strong_category", "category", "å¼·ã¿åˆ†é¡"], False)
    rc["priority_rank"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["priority_rank", "rank", "é †ä½"], True) or ""
    rc["recommend_jan"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["recommend_jan", "jan", "JAN"], False)
    rc["recommend_product"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["recommend_product", "product_name", "æ¨å¥¨å•†å“"], True) or ""
    rc["manufacturer"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["manufacturer", "maker", "ãƒ¡ãƒ¼ã‚«ãƒ¼"], False)
    rc["market_scale"] = resolve_col(VIEW_RECOMMEND, cols_rc, ["market_scale", "scale", "å¸‚å ´è¦æ¨¡"], False)
    m["recommend"] = rc

    return m


@st.cache_data(ttl=3600)
def role_table_has_login_code(_client: bigquery.Client) -> bool:
    project_id, dataset_id, table_name = _split_table_fqn(VIEW_ROLE_CLEAN)
    sql = f"""
        SELECT 1
        FROM `{project_id}.{dataset_id}.INFORMATION_SCHEMA.COLUMNS`
        WHERE table_name = @table_name
          AND column_name = 'login_code'
        LIMIT 1
    """
    df = query_df_safe(_client, sql, {"table_name": table_name}, "Role Schema Check")
    return not df.empty


# -----------------------------
# 3.2 Customer Group resolution (è¸è¥²)
# -----------------------------
@st.cache_data(ttl=3600)
def get_unified_columns(_client: bigquery.Client) -> set[str]:
    cols_u = get_table_columns_lower(_client, VIEW_UNIFIED)
    return cols_u


def get_available_customer_group_columns(_client: bigquery.Client) -> list[str]:
    columns = get_unified_columns(_client)
    return [col for col in CUSTOMER_GROUP_COLUMN_CANDIDATES if col in columns]


@st.cache_data(ttl=3600)
def get_customer_group_column_profiles(_client: bigquery.Client) -> pd.DataFrame:
    available_cols = get_available_customer_group_columns(_client)
    if not available_cols:
        return pd.DataFrame()

    union_parts = []
    for col in available_cols:
        union_parts.append(
            f"""
            SELECT
              '{col}' AS column_name,
              COUNT(*) AS total_rows,
              COUNTIF(COALESCE(NULLIF(CAST({bq_ident(col)} AS STRING), ''), '') != '') AS non_null_rows,
              COUNT(DISTINCT NULLIF(CAST({bq_ident(col)} AS STRING), '')) AS distinct_groups
            FROM `{VIEW_UNIFIED}`
            """
        )

    sql = "\nUNION ALL\n".join(union_parts) + "\nORDER BY non_null_rows DESC, distinct_groups DESC"
    return query_df_safe(_client, sql, label="Customer Group Column Profile")


def resolve_customer_group_sql_expr(_client: bigquery.Client) -> Tuple[Optional[str], Optional[str]]:
    cols = get_unified_columns(_client)

    has_display = "customer_group_display" in cols
    has_official = "customer_group_official" in cols
    has_raw = "customer_group_raw" in cols
    has_old = "sales_group_name" in cols

    if has_display:
        expr = "COALESCE(NULLIF(CAST(customer_group_display AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.customer_group_display"

    if has_official and has_raw:
        official = "NULLIF(CAST(customer_group_official AS STRING), '')"
        raw = "NULLIF(CAST(customer_group_raw AS STRING), '')"
        expr = f"""
          COALESCE(
            CASE
              WHEN {official} IS NOT NULL AND {raw} IS NOT NULL AND {official} != {raw}
                THEN CONCAT({official}, 'ï¼ˆ', {raw}, 'ï¼‰')
              WHEN {official} IS NOT NULL THEN {official}
              WHEN {raw} IS NOT NULL THEN {raw}
              ELSE NULL
            END,
            'æœªè¨­å®š'
          )
        """
        return " ".join(expr.split()), f"{VIEW_UNIFIED}.customer_group_official + customer_group_raw"

    if has_official:
        expr = "COALESCE(NULLIF(CAST(customer_group_official AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.customer_group_official"

    if has_raw:
        expr = "COALESCE(NULLIF(CAST(customer_group_raw AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.customer_group_raw"

    if has_old:
        expr = "COALESCE(NULLIF(CAST(sales_group_name AS STRING), ''), 'æœªè¨­å®š')"
        return expr, f"{VIEW_UNIFIED}.sales_group_name"

    return None, None


# -----------------------------
# 3.3 Admin full scan policy (æ®µéšUI)
# -----------------------------
def get_admin_scan_policy(role: RoleInfo) -> AdminScanPolicy:
    """
    ç®¡ç†è€…ã®ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³çµ±åˆ¶ã€‚
    - é€šå¸¸ï¼šscopeå¿…é ˆ
    - ä¾‹å¤–ï¼šæ˜ç¤ºè¨±å¯ï¼ˆãƒã‚§ãƒƒã‚¯ï¼‰ï¼‹ maxBytesè¨­å®š ï¼‹ï¼ˆæ¨å®šâ†’å®Ÿè¡Œã®é †ï¼‰
    """
    if not role.role_admin_view:
        return AdminScanPolicy(require_scope=False, allow_full_scan=False, max_bytes_billed=0, must_estimate_before_run=False)

    # UIã§è¨­å®šå¯èƒ½ã«ã™ã‚‹ï¼ˆãŸã ã—ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å®‰å…¨å¯„ã‚Šï¼‰
    with st.sidebar.expander("ğŸ›¡ï¸ ç®¡ç†è€…ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³çµ±åˆ¶ï¼ˆå¿…èª­ï¼‰", expanded=False):
        st.caption("ã‚¹ã‚³ãƒ¼ãƒ—æœªæŒ‡å®šï¼å…¨ç¤¾ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ã§ã™ã€‚å®Ÿåƒä¿è­·ã®ãŸã‚æ¨å®šâ†’ä¸Šé™â†’å®Ÿè¡Œã®é †ã§çµ±åˆ¶ã—ã¾ã™ã€‚")
        allow_full_scan = st.checkbox("ã‚¹ã‚³ãƒ¼ãƒ—æœªæŒ‡å®šã®ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ã‚’è¨±å¯ã™ã‚‹ï¼ˆä¾‹å¤–ï¼‰", value=False, key="admin_allow_full_scan")
        must_estimate = st.checkbox("ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³æ™‚ã¯æ¨å®šï¼ˆDryRunï¼‰ã‚’å¿…é ˆã«ã™ã‚‹", value=True, key="admin_must_estimate")

        usd_per_tb = st.number_input("æ¨å®šå˜ä¾¡ï¼ˆUSD / TBï¼‰", min_value=0.0, max_value=50.0, value=float(st.session_state.get("usd_per_tb", DEFAULT_USD_PER_TB)), step=0.5)
        usd_jpy = st.number_input("ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆï¼ˆUSDJPYï¼‰", min_value=50.0, max_value=300.0, value=float(st.session_state.get("usd_jpy", DEFAULT_USDJPY)), step=1.0)
        st.session_state["usd_per_tb"] = float(usd_per_tb)
        st.session_state["usd_jpy"] = float(usd_jpy)

        max_gb = st.number_input("maximumBytesBilled ä¸Šé™ï¼ˆGBï¼‰", min_value=0, max_value=5000, value=int(st.session_state.get("admin_max_gb", 200)), step=50)
        st.session_state["admin_max_gb"] = int(max_gb)

        if max_gb == 0:
            st.warning("ä¸Šé™0GBï¼ä¸Šé™ãªã—ï¼ˆéæ¨å¥¨ï¼‰ã€‚å®Ÿåƒä¿è­·ã®è¦³ç‚¹ã§ã¯ä¸Šé™è¨­å®šã‚’æ¨å¥¨ã€‚")

    max_bytes = int(st.session_state.get("admin_max_gb", 200)) * (1024 ** 3)
    if int(st.session_state.get("admin_max_gb", 200)) == 0:
        max_bytes = 0

    return AdminScanPolicy(
        require_scope=True,
        allow_full_scan=bool(st.session_state.get("admin_allow_full_scan", False)),
        max_bytes_billed=max_bytes,
        must_estimate_before_run=bool(st.session_state.get("admin_must_estimate", True)),
    )


def guard_and_run_query_ui(
    client: bigquery.Client,
    role: RoleInfo,
    scope: ScopeFilter,
    sql: str,
    params: Optional[Dict[str, Any]],
    label: str,
    *,
    risky_if_no_scope: bool = True,
    force_estimate: bool = False,
    timeout_sec: int = 120,
) -> pd.DataFrame:
    """
    æ®µéšUIï¼š
    - æ¨å®šï¼ˆDryRunï¼‰
    - max bytes billed è¨­å®šï¼ˆç®¡ç†è€…ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³æ™‚ï¼‰
    - å®Ÿè¡Œ
    """
    policy = get_admin_scan_policy(role)

    is_admin = role.role_admin_view
    scope_empty = scope.is_empty()

    # ç®¡ç†è€…ã‚¹ã‚³ãƒ¼ãƒ—å¿…é ˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    if is_admin and policy.require_scope and scope_empty and risky_if_no_scope and (not policy.allow_full_scan):
        st.warning("âš ï¸ ç®¡ç†è€…ã¯ã‚¹ã‚³ãƒ¼ãƒ—å¿…é ˆã§ã™ã€‚ã‚¹ã‚³ãƒ¼ãƒ—ã‚’æŒ‡å®šã™ã‚‹ã‹ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ä¾‹å¤–è¨±å¯ã€ã‚’ONã«ã—ã¦ãã ã•ã„ã€‚")
        return pd.DataFrame()

    # max bytes billedï¼ˆç®¡ç†è€…ã®ã¿ï¼‰
    max_bytes = None
    if is_admin and scope_empty and policy.allow_full_scan and risky_if_no_scope:
        if policy.max_bytes_billed and policy.max_bytes_billed > 0:
            max_bytes = policy.max_bytes_billed
        else:
            max_bytes = None  # ä¸Šé™ãªã—ï¼ˆéæ¨å¥¨ï¼‰

    # æ¨å®šã¯ã€Œå±é™ºæ¡ä»¶ã€ã¾ãŸã¯ã€Œå¼·åˆ¶ã€ã§å‡ºã™
    need_estimate = force_estimate or (is_admin and scope_empty and policy.allow_full_scan and risky_if_no_scope)
    if need_estimate:
        st.markdown("##### ğŸ§® æ¨å®šï¼ˆDry Runï¼‰")
        colA, colB, colC = st.columns([1, 1, 2])

        estimate_key = f"estimate_bytes::{label}"
        ran_key = f"estimate_ran::{label}"

        if colA.button("æ¨å®šã™ã‚‹ï¼ˆDryRunï¼‰", key=f"btn_est_{label}", use_container_width=True):
            b = estimate_query_bytes(client, sql, params, label=label)
            st.session_state[estimate_key] = b if b is not None else 0
            st.session_state[ran_key] = True

        b_est = int(st.session_state.get(estimate_key, 0) or 0)
        ran = bool(st.session_state.get(ran_key, False))

        if ran:
            usd_per_tb = float(st.session_state.get("usd_per_tb", DEFAULT_USD_PER_TB))
            usd_jpy = float(st.session_state.get("usd_jpy", DEFAULT_USDJPY))
            jpy = estimate_cost_jpy(b_est, usd_per_tb, usd_jpy)

            colB.metric("æ¨å®šå‡¦ç†é‡", bytes_to_human(b_est))
            colC.metric("æ¨å®šã‚³ã‚¹ãƒˆï¼ˆç›®å®‰ï¼‰", f"Â¥{jpy:,.0f}")

            if max_bytes is not None:
                st.info(f"maximumBytesBilled: {bytes_to_human(max_bytes)}ï¼ˆç®¡ç†è€…ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³çµ±åˆ¶ï¼‰")

            # æ¨å®šå¿…é ˆãƒãƒªã‚·ãƒ¼
            if is_admin and scope_empty and policy.allow_full_scan and policy.must_estimate_before_run:
                st.success("æ¨å®šãŒå®Œäº†ã—ã¾ã—ãŸã€‚å®Ÿè¡Œã§ãã¾ã™ã€‚")
        else:
            st.caption("ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ã‚„å…¨ä»¶è¡¨ç¤ºã§ã¯ã€ã¾ãšæ¨å®šã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

        # æ¨å®šå¿…é ˆã®ã¨ãã¯ã€æ¨å®šãªã—ã§ã¯å®Ÿè¡Œä¸å¯
        if is_admin and scope_empty and policy.allow_full_scan and policy.must_estimate_before_run:
            if not ran:
                st.error("æ¨å®šãŒå¿…é ˆã§ã™ï¼ˆæœªå®Ÿè¡Œã®ãŸã‚ã€å®Ÿè¡Œãƒœã‚¿ãƒ³ã¯ç„¡åŠ¹ï¼‰ã€‚")
                return pd.DataFrame()

    st.markdown("##### â–¶ å®Ÿè¡Œ")
    run_disabled = False
    if is_admin and scope_empty and policy.allow_full_scan and policy.must_estimate_before_run and need_estimate:
        ran = bool(st.session_state.get(f"estimate_ran::{label}", False))
        if not ran:
            run_disabled = True

    if st.button(f"å®Ÿè¡Œï¼š{label}", key=f"btn_run_{label}", use_container_width=True, disabled=run_disabled):
        return query_df_safe(
            client,
            sql,
            params=params,
            label=label,
            timeout_sec=timeout_sec,
            maximum_bytes_billed=max_bytes,
        )

    return pd.DataFrame()


# -----------------------------
# 3.4 Scope filters (è¸è¥²ï¼‹å®‰å…¨è£œå¼·)
# -----------------------------
def render_scope_filters(client: bigquery.Client, role: RoleInfo) -> ScopeFilter:
    st.markdown("### ğŸ” åˆ†æã‚¹ã‚³ãƒ¼ãƒ—è¨­å®š")
    predicates: list[str] = []
    params: Dict[str, Any] = {}

    with st.expander("è©³ç´°çµã‚Šè¾¼ã¿ï¼ˆå¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ—ãƒ»å¾—æ„å…ˆåï¼‰", expanded=False):
        c1, c2 = st.columns(2)

        group_expr, group_src = resolve_customer_group_sql_expr(client)
        if group_expr:
            role_where = ""
            role_params: Dict[str, Any] = {}
            if not role.role_admin_view:
                role_where = "WHERE login_email = @login_email"
                role_params["login_email"] = role.login_email

            sql_group = f"""
                SELECT DISTINCT {group_expr} AS group_name
                FROM `{VIEW_UNIFIED}`
                {role_where}
                ORDER BY group_name
                LIMIT 500
            """
            df_group = query_df_safe(client, sql_group, role_params, "Scope Group Options")
            group_opts = ["æŒ‡å®šãªã—"] + (df_group["group_name"].tolist() if not df_group.empty else [])
            selected_group = c1.selectbox("å¾—æ„å…ˆã‚°ãƒ«ãƒ¼ãƒ—", options=group_opts)
            if selected_group != "æŒ‡å®šãªã—":
                predicates.append(f"{group_expr} = @scope_group")
                params["scope_group"] = selected_group

            if group_src:
                c1.caption(f"æŠ½å‡ºå…ƒ: `{group_src}`")
        else:
            c1.caption("ã‚°ãƒ«ãƒ¼ãƒ—åˆ—ãªã—ï¼ˆVIEW_UNIFIEDã«è©²å½“åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼‰")

        keyword = c2.text_input("å¾—æ„å…ˆåï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", placeholder="ä¾‹ï¼šå¤è³€ç—…é™¢")
        if keyword.strip():
            predicates.append("customer_name LIKE @scope_customer_name")
            params["scope_customer_name"] = f"%{keyword.strip()}%"

    return ScopeFilter(predicates=tuple(predicates), params=params)


def resolve_role(client: bigquery.Client, login_email: str, login_code: str) -> RoleInfo:
    if not login_email or not login_code:
        return RoleInfo()

    has_login_code = role_table_has_login_code(client)

    if has_login_code:
        sql = f"""
            SELECT login_email, role_tier
            FROM `{VIEW_ROLE_CLEAN}`
            WHERE login_email = @login_email
              AND CAST(login_code AS STRING) = @login_code
            LIMIT 1
        """
        params: Dict[str, Any] = {"login_email": login_email, "login_code": login_code}
    else:
        sql = f"""
            SELECT login_email, role_tier
            FROM `{VIEW_ROLE_CLEAN}`
            WHERE login_email = @login_email
            LIMIT 1
        """
        params = {"login_email": login_email}

    df = query_df_safe(client, sql, params, "Auth Check")
    if df.empty:
        return RoleInfo(login_email=login_email)

    row = df.iloc[0]
    raw_role = str(row.get("role_tier", "")).strip().upper()
    is_admin = any(x in raw_role for x in ["ADMIN", "MANAGER", "HQ"])

    return RoleInfo(
        is_authenticated=True,
        login_email=login_email,
        staff_name=login_email.split("@")[0],
        role_key="HQ_ADMIN" if is_admin else "SALES",
        role_admin_view=is_admin,
        phone="-",
    )


# -----------------------------
# 4. UI Sections (å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³)
# -----------------------------
def render_summary_metrics(row: pd.Series) -> None:
    s_cur = get_safe_float(row, "sales_amount_fytd")
    s_py_ytd = get_safe_float(row, "sales_amount_py_ytd")
    s_py_total = get_safe_float(row, "sales_amount_py_total")

    s_fc = s_cur * (s_py_total / s_py_ytd) if s_py_ytd > 0 else s_cur

    gp_cur = get_safe_float(row, "gross_profit_fytd")
    gp_py_ytd = get_safe_float(row, "gross_profit_py_ytd")
    gp_py_total = get_safe_float(row, "gross_profit_py_total")
    gp_fc = gp_cur * (gp_py_total / gp_py_ytd) if gp_py_ytd > 0 else gp_cur

    st.caption(
        "â€» ã€ä»ŠæœŸäºˆæ¸¬ã€‘ã¯AIäºˆæ¸¬ã§ã¯ãªãã€ã€Œä»ŠæœŸå®Ÿç¸¾ Ã— (æ˜¨å¹´åº¦ç€åœ° Ã· å‰å¹´åŒæœŸ)ã€"
        "ã«ã‚ˆã‚‹å­£ç¯€å¤‰å‹•ã‚’åŠ å‘³ã—ãŸæ¨ç§»ãƒšãƒ¼ã‚¹ï¼ˆç€åœ°è¦‹è¾¼ï¼‰ã§ã™ã€‚"
    )

    st.markdown("##### â–  å£²ä¸Š")
    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("â‘  ä»ŠæœŸç´¯è¨ˆ", f"Â¥{s_cur:,.0f}")
    c2.metric("â‘¡ å‰å¹´åŒæœŸ", f"Â¥{s_py_ytd:,.0f}", delta=f"{int(s_cur - s_py_ytd):,}" if s_py_ytd > 0 else None)
    c3.metric("â‘¢ æ˜¨å¹´åº¦ç€åœ°", f"Â¥{s_py_total:,.0f}")
    c4.metric("â‘£ ä»ŠæœŸäºˆæ¸¬", f"Â¥{s_fc:,.0f}")
    c5.metric("â‘¤ ç€åœ°GAP", f"Â¥{s_fc - s_py_total:,.0f}", delta=f"{int(s_fc - s_py_total):,}")

    st.markdown("##### â–  ç²—åˆ©")
    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("â‘  ä»ŠæœŸç´¯è¨ˆ", f"Â¥{gp_cur:,.0f}")
    c2.metric("â‘¡ å‰å¹´åŒæœŸ", f"Â¥{gp_py_ytd:,.0f}", delta=f"{int(gp_cur - gp_py_ytd):,}" if gp_py_ytd > 0 else None)
    c3.metric("â‘¢ æ˜¨å¹´åº¦ç€åœ°", f"Â¥{gp_py_total:,.0f}")
    c4.metric("â‘£ ä»ŠæœŸäºˆæ¸¬", f"Â¥{gp_fc:,.0f}")
    c5.metric("â‘¤ ç€åœ°GAP", f"Â¥{gp_fc - gp_py_total:,.0f}", delta=f"{int(gp_fc - gp_py_total):,}")


def render_fytd_org_section(client: bigquery.Client) -> None:
    st.subheader("ğŸ¢ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå…¨ç¤¾ã‚µãƒãƒªãƒ¼")

    if "org_data_loaded" not in st.session_state:
        st.session_state.org_data_loaded = False

    if st.button("å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_org_load"):
        st.session_state.org_data_loaded = True

    if st.session_state.get("org_data_loaded"):
        sql = f"""
            WITH today_info AS (
              SELECT
                CURRENT_DATE('Asia/Tokyo') AS today,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today,
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                    - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
            )
            SELECT
              SUM(CASE WHEN fiscal_year = current_fy THEN sales_amount ELSE 0 END) AS sales_amount_fytd,
              SUM(CASE WHEN fiscal_year = current_fy THEN gross_profit ELSE 0 END) AS gross_profit_fytd,
              SUM(CASE WHEN fiscal_year = current_fy - 1 AND sales_date <= py_today THEN sales_amount ELSE 0 END) AS sales_amount_py_ytd,
              SUM(CASE WHEN fiscal_year = current_fy - 1 AND sales_date <= py_today THEN gross_profit ELSE 0 END) AS gross_profit_py_ytd,
              SUM(CASE WHEN fiscal_year = current_fy - 1 THEN sales_amount ELSE 0 END) AS sales_amount_py_total,
              SUM(CASE WHEN fiscal_year = current_fy - 1 THEN gross_profit ELSE 0 END) AS gross_profit_py_total
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN today_info
        """
        df_org = query_df_safe(client, sql, None, "Org Summary")
        if not df_org.empty:
            render_summary_metrics(df_org.iloc[0])


def render_fytd_me_section(client: bigquery.Client, login_email: str) -> None:
    st.subheader("ğŸ‘¤ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå€‹äººã‚µãƒãƒªãƒ¼")
    if st.button("è‡ªåˆ†ã®æˆç¸¾ã‚’èª­ã¿è¾¼ã‚€", key="btn_me_load"):
        sql = f"""
            WITH today_info AS (
              SELECT
                CURRENT_DATE('Asia/Tokyo') AS today,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today,
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                    - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
            )
            SELECT
              SUM(CASE WHEN fiscal_year = current_fy THEN sales_amount ELSE 0 END) AS sales_amount_fytd,
              SUM(CASE WHEN fiscal_year = current_fy THEN gross_profit ELSE 0 END) AS gross_profit_fytd,
              SUM(CASE WHEN fiscal_year = current_fy - 1 AND sales_date <= py_today THEN sales_amount ELSE 0 END) AS sales_amount_py_ytd,
              SUM(CASE WHEN fiscal_year = current_fy - 1 AND sales_date <= py_today THEN gross_profit ELSE 0 END) AS gross_profit_py_ytd,
              SUM(CASE WHEN fiscal_year = current_fy - 1 THEN sales_amount ELSE 0 END) AS sales_amount_py_total,
              SUM(CASE WHEN fiscal_year = current_fy - 1 THEN gross_profit ELSE 0 END) AS gross_profit_py_total
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN today_info
            WHERE login_email = @login_email
        """
        df_me = query_df_safe(client, sql, {"login_email": login_email}, "Me Summary")
        if not df_me.empty:
            render_summary_metrics(df_me.iloc[0])


def render_group_underperformance_section(client: bigquery.Client, role: RoleInfo, scope: ScopeFilter) -> None:
    st.subheader("ğŸ¢ å¾—æ„å…ˆãƒ»ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ï¼† è¦å› åˆ†æ")

    c1, c2 = st.columns(2)
    view_choice = c1.radio("ğŸ“Š åˆ†æã®å˜ä½", ["ğŸ¢ ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥", "ğŸ¥ å¾—æ„å…ˆå˜ä½“"], horizontal=True)
    mode_choice = c2.radio("ğŸ† ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŸºæº–", ["ğŸ“‰ ä¸‹è½å¹…ãƒ¯ãƒ¼ã‚¹ãƒˆ", "ğŸ“ˆ ä¸Šæ˜‡å¹…ãƒ™ã‚¹ãƒˆ"], horizontal=True)

    perf_view = "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" if "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" in view_choice else "å¾—æ„å…ˆåˆ¥"
    perf_mode = "ãƒ¯ãƒ¼ã‚¹ãƒˆ" if "ãƒ¯ãƒ¼ã‚¹ãƒˆ" in mode_choice else "ãƒ™ã‚¹ãƒˆ"
    sort_order = "ASC" if perf_mode == "ãƒ¯ãƒ¼ã‚¹ãƒˆ" else "DESC"

    group_expr, group_src = resolve_customer_group_sql_expr(client)
    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" and not group_expr:
        st.info("ã‚°ãƒ«ãƒ¼ãƒ—åˆ†æã«åˆ©ç”¨ã§ãã‚‹åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆVIEW_UNIFIEDã«ã‚°ãƒ«ãƒ¼ãƒ—åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚")
        return

    role_filter = "" if role.role_admin_view else "login_email = @login_email"
    scope_filter_clause = scope.where_clause()
    filter_sql = _compose_where(role_filter, scope_filter_clause)

    params: Dict[str, Any] = dict(scope.params or {})
    if not role.role_admin_view:
        params["login_email"] = role.login_email

    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥":
        sql_parent = f"""
            WITH fy AS (
              SELECT
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                 - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
            )
            SELECT
              {group_expr} AS `åç§°`,
              SUM(CASE WHEN fiscal_year = current_fy THEN sales_amount ELSE 0 END) AS `ä»ŠæœŸå£²ä¸Š`,
              SUM(CASE WHEN fiscal_year = current_fy - 1 AND sales_date <= py_today THEN sales_amount ELSE 0 END) AS `å‰å¹´åŒæœŸå£²ä¸Š`,
              SUM(CASE WHEN fiscal_year = current_fy THEN gross_profit ELSE 0 END) AS `ä»ŠæœŸç²—åˆ©`,
              SUM(CASE WHEN fiscal_year = current_fy - 1 AND sales_date <= py_today THEN gross_profit ELSE 0 END) AS `å‰å¹´åŒæœŸç²—åˆ©`
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN fy
            {filter_sql}
            GROUP BY `åç§°`
            HAVING `å‰å¹´åŒæœŸå£²ä¸Š` > 0 OR `ä»ŠæœŸå£²ä¸Š` > 0
            ORDER BY (`ä»ŠæœŸå£²ä¸Š` - `å‰å¹´åŒæœŸå£²ä¸Š`) {sort_order}
            LIMIT 50
        """
    else:
        sql_parent = f"""
            WITH fy AS (
              SELECT
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                 - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy,
                DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
            )
            SELECT
              customer_code AS `ã‚³ãƒ¼ãƒ‰`,
              ANY_VALUE(customer_name) AS `åç§°`,
              SUM(CASE WHEN fiscal_year = current_fy THEN sales_amount ELSE 0 END) AS `ä»ŠæœŸå£²ä¸Š`,
              SUM(CASE WHEN fiscal_year = current_fy - 1 AND sales_date <= py_today THEN sales_amount ELSE 0 END) AS `å‰å¹´åŒæœŸå£²ä¸Š`,
              SUM(CASE WHEN fiscal_year = current_fy THEN gross_profit ELSE 0 END) AS `ä»ŠæœŸç²—åˆ©`,
              SUM(CASE WHEN fiscal_year = current_fy - 1 AND sales_date <= py_today THEN gross_profit ELSE 0 END) AS `å‰å¹´åŒæœŸç²—åˆ©`
            FROM `{VIEW_UNIFIED}`
            CROSS JOIN fy
            {filter_sql}
            GROUP BY `ã‚³ãƒ¼ãƒ‰`
            HAVING `å‰å¹´åŒæœŸå£²ä¸Š` > 0 OR `ä»ŠæœŸå£²ä¸Š` > 0
            ORDER BY (`ä»ŠæœŸå£²ä¸Š` - `å‰å¹´åŒæœŸå£²ä¸Š`) {sort_order}
            LIMIT 50
        """

    # è¦ªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯è»½ã„ã®ã§é€šå¸¸å®Ÿè¡Œ
    df_parent = query_df_safe(client, sql_parent, params, f"Parent Perf {perf_view}")
    if df_parent.empty:
        st.info("è¡¨ç¤ºã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df_parent["å£²ä¸Šå·®é¡"] = df_parent["ä»ŠæœŸå£²ä¸Š"] - df_parent["å‰å¹´åŒæœŸå£²ä¸Š"]
    df_parent["å£²ä¸Šæˆé•·ç‡"] = df_parent.apply(
        lambda r: ((r["ä»ŠæœŸå£²ä¸Š"] / r["å‰å¹´åŒæœŸå£²ä¸Š"] - 1) * 100) if r["å‰å¹´åŒæœŸå£²ä¸Š"] else 0,
        axis=1,
    )
    df_parent["ç²—åˆ©å·®é¡"] = df_parent["ä»ŠæœŸç²—åˆ©"] - df_parent["å‰å¹´åŒæœŸç²—åˆ©"]

    def get_parent_rank_icon(rank: int, mode: str) -> str:
        if mode == "ãƒ™ã‚¹ãƒˆ":
            if rank == 1:
                return "ğŸ¥‡ 1ä½"
            if rank == 2:
                return "ğŸ¥ˆ 2ä½"
            if rank == 3:
                return "ğŸ¥‰ 3ä½"
            return f"ğŸŒŸ {rank}ä½"
        else:
            if rank == 1:
                return "ğŸš¨ 1ä½"
            if rank == 2:
                return "âš ï¸ 2ä½"
            if rank == 3:
                return "âš¡ 3ä½"
            return f"ğŸ“‰ {rank}ä½"

    df_parent.insert(0, "é †ä½", [get_parent_rank_icon(i + 1, perf_mode) for i in range(len(df_parent))])

    if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥" and group_src:
        st.caption(f"æŠ½å‡ºå…ƒã‚°ãƒ«ãƒ¼ãƒ—åˆ—: `{group_src}`")

    event = st.dataframe(
        df_parent.style.format(
            {
                "ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}",
                "å‰å¹´åŒæœŸå£²ä¸Š": "Â¥{:,.0f}",
                "ä»ŠæœŸç²—åˆ©": "Â¥{:,.0f}",
                "å‰å¹´åŒæœŸç²—åˆ©": "Â¥{:,.0f}",
                "å£²ä¸Šå·®é¡": "Â¥{:,.0f}",
                "å£²ä¸Šæˆé•·ç‡": "{:.1f}%",
                "ç²—åˆ©å·®é¡": "Â¥{:,.0f}",
            }
        ),
        use_container_width=True,
        hide_index=True,
        selection_mode="single-row",
        on_select="rerun",
        key=f"grid_parent_{perf_view}_{perf_mode}",
    )

    selected_parent_id = None
    selected_parent_name = None

    try:
        sel_rows = []
        if hasattr(event, "selection") and hasattr(event.selection, "rows"):
            sel_rows = event.selection.rows
        elif isinstance(event, dict) and "selection" in event:
            sel_rows = event["selection"].get("rows", [])

        if sel_rows:
            idx = sel_rows[0]
            if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥":
                selected_parent_id = str(df_parent.iloc[idx]["åç§°"])
                selected_parent_name = selected_parent_id
            else:
                selected_parent_id = str(df_parent.iloc[idx]["ã‚³ãƒ¼ãƒ‰"])
                selected_parent_name = str(df_parent.iloc[idx]["åç§°"])
    except Exception:
        pass

    if selected_parent_id:
        st.markdown(f"#### ğŸ” è¦å› åˆ†æï¼ˆå•†å“ãƒ™ãƒ¼ã‚¹ {perf_mode}ãƒ»å…¨ä»¶ä¸€è¦§ï¼‰")

        drill_params = dict(params)

        if perf_view == "ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥":
            drill_filter_sql = _compose_where(role_filter, scope_filter_clause, f"{group_expr} = @parent_id")
        else:
            drill_filter_sql = _compose_where(role_filter, scope_filter_clause, "customer_code = @parent_id")

        drill_params["parent_id"] = selected_parent_id

        sql_drill = f"""
            WITH fy AS (
              SELECT (
                EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END
              ) AS current_fy,
              DATE_SUB(CURRENT_DATE('Asia/Tokyo'), INTERVAL 1 YEAR) AS py_today
            ),
            base_raw AS (
              SELECT
                COALESCE(
                  NULLIF(NULLIF(TRIM(CAST(yj_code AS STRING)), ''), '0'),
                  NULLIF(NULLIF(TRIM(CAST(jan_code AS STRING)), ''), '0'),
                  TRIM(CAST(product_name AS STRING))
                ) AS yj_key,
                REGEXP_REPLACE(CAST(product_name AS STRING), r"[/ï¼].*$", "") AS product_base,
                SUM(CASE WHEN fiscal_year = current_fy THEN sales_amount ELSE 0 END) AS ty_sales,
                SUM(CASE WHEN fiscal_year = current_fy - 1 AND sales_date <= py_today THEN sales_amount ELSE 0 END) AS py_sales
              FROM `{VIEW_UNIFIED}`
              CROSS JOIN fy
              {drill_filter_sql}
              GROUP BY yj_key, product_base
            ),
            base AS (
              SELECT
                yj_key AS yj_code,
                ARRAY_AGG(product_base ORDER BY ty_sales DESC LIMIT 1)[OFFSET(0)] AS product_name,
                SUM(ty_sales) AS ty_sales,
                SUM(py_sales) AS py_sales
              FROM base_raw
              GROUP BY yj_code
            )
            SELECT
              yj_code,
              product_name,
              ty_sales AS sales_amount,
              py_sales AS py_sales_amount,
              (ty_sales - py_sales) AS sales_diff_yoy
            FROM base
            WHERE ty_sales > 0 OR py_sales > 0
            ORDER BY sales_diff_yoy {sort_order}
        """

        # ã“ã“ã¯å…¨ä»¶ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ã€ç®¡ç†è€…ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³çµ±åˆ¶ã‚’é©ç”¨ï¼ˆã‚¹ã‚³ãƒ¼ãƒ—ãªã—ã¯å±é™ºï¼‰
        df_drill = guard_and_run_query_ui(
            client,
            role,
            scope,
            sql_drill,
            drill_params,
            label=f"è¦å› åˆ†æï¼ˆ{selected_parent_name}ï¼‰",
            risky_if_no_scope=True,
            force_estimate=False,
            timeout_sec=180,
        )

        if not df_drill.empty:
            df_drill["product_name"] = df_drill["product_name"].apply(normalize_product_display_name)
            df_drill = df_drill.fillna(0)
            df_drill.insert(0, "è¦å› é †ä½", [get_parent_rank_icon(i + 1, perf_mode) for i in range(len(df_drill))])

            st.dataframe(
                df_drill[["è¦å› é †ä½", "product_name", "sales_amount", "py_sales_amount", "sales_diff_yoy"]].rename(
                    columns={
                        "product_name": "ä»£è¡¨å•†å“å(æˆåˆ†)",
                        "sales_amount": "ä»ŠæœŸå£²ä¸Š",
                        "py_sales_amount": "å‰å¹´åŒæœŸå£²ä¸Š",
                        "sales_diff_yoy": "å‰å¹´æ¯”å·®é¡",
                    }
                ).style.format(
                    {"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´åŒæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´æ¯”å·®é¡": "Â¥{:,.0f}"}
                ),
                use_container_width=True,
                hide_index=True,
            )


def render_yoy_section(client: bigquery.Client, role: RoleInfo, scope: ScopeFilter) -> None:
    st.subheader("ğŸ“Š å¹´é–“ YoY ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆæˆåˆ†ãƒ»YJå„ªå…ˆï½œYJ=0/nullã¯JANã‚­ãƒ¼ã§è¿½è·¡ï¼‰")

    if "yoy_mode" not in st.session_state:
        st.session_state.yoy_mode = "ãƒ¯ãƒ¼ã‚¹ãƒˆ"  # ãƒ¯ãƒ¼ã‚¹ãƒˆ / ãƒ™ã‚¹ãƒˆ / æ–°è¦
    if "yoy_df" not in st.session_state:
        st.session_state.yoy_df = pd.DataFrame()
    if "selected_yoy_key" not in st.session_state:
        st.session_state.selected_yoy_key = "å…¨æˆåˆ†ã‚’è¡¨ç¤º"

    c1, c2, c3 = st.columns(3)

    def load_yoy(mode_name: str) -> None:
        st.session_state.yoy_mode = mode_name

        role_filter = "" if role.role_admin_view else "login_email = @login_email"
        scope_where = scope.where_clause()
        where_sql = _compose_where(role_filter, scope_where)

        params: Dict[str, Any] = dict(scope.params or {})
        if not role.role_admin_view:
            params["login_email"] = role.login_email

        if mode_name == "ãƒ¯ãƒ¼ã‚¹ãƒˆ":
            diff_filter = "py_sales > 0 AND (ty_sales - py_sales) < 0"
            order_by = "sales_diff_yoy ASC"
        elif mode_name == "ãƒ™ã‚¹ãƒˆ":
            diff_filter = "py_sales > 0 AND (ty_sales - py_sales) > 0"
            order_by = "sales_diff_yoy DESC"
        else:
            diff_filter = "py_sales = 0 AND ty_sales > 0"
            order_by = "ty_sales DESC"

        sql = f"""
            WITH fy AS (
              SELECT
                (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
                 - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
            ),
            base_raw AS (
              SELECT
                COALESCE(
                  NULLIF(NULLIF(TRIM(CAST(yj_code AS STRING)), ''), '0'),
                  NULLIF(NULLIF(TRIM(CAST(jan_code AS STRING)), ''), '0'),
                  REGEXP_REPLACE(CAST(product_name AS STRING), r"[/ï¼].*$", "")
                ) AS yj_key,
                REGEXP_REPLACE(CAST(product_name AS STRING), r"[/ï¼].*$", "") AS product_base,
                SUM(CASE WHEN fiscal_year = fy.current_fy THEN sales_amount ELSE 0 END) AS ty_sales,
                SUM(CASE WHEN fiscal_year = fy.current_fy - 1 THEN sales_amount ELSE 0 END) AS py_sales
              FROM `{VIEW_UNIFIED}`
              CROSS JOIN fy
              {where_sql}
              GROUP BY yj_key, product_base
            ),
            base AS (
              SELECT
                yj_key,
                ARRAY_AGG(product_base ORDER BY ty_sales DESC LIMIT 1)[OFFSET(0)] AS product_name,
                SUM(ty_sales) AS ty_sales,
                SUM(py_sales) AS py_sales
              FROM base_raw
              GROUP BY yj_key
            )
            SELECT
              yj_key,
              product_name,
              ty_sales,
              py_sales,
              (ty_sales - py_sales) AS sales_diff_yoy
            FROM base
            WHERE {diff_filter}
            ORDER BY {order_by}
            LIMIT 100
        """

        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯100ä»¶å›ºå®šã§æ¯”è¼ƒçš„è»½é‡ã€‚ã“ã“ã¯é€šå¸¸å®Ÿè¡Œã€‚
        st.session_state.yoy_df = query_df_safe(client, sql, params, f"YoY Load {mode_name}")

    with c1:
        if st.button("ğŸ“‰ ä¸‹è½å¹…ãƒ¯ãƒ¼ã‚¹ãƒˆ", use_container_width=True):
            load_yoy("ãƒ¯ãƒ¼ã‚¹ãƒˆ")
    with c2:
        if st.button("ğŸ“ˆ ä¸Šæ˜‡å¹…ãƒ™ã‚¹ãƒˆ", use_container_width=True):
            load_yoy("ãƒ™ã‚¹ãƒˆ")
    with c3:
        if st.button("ğŸ†• æ–°è¦/æ¯”è¼ƒä¸èƒ½", use_container_width=True):
            load_yoy("æ–°è¦")

    if st.session_state.yoy_df.empty:
        st.info("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã‚€ã«ã¯ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
        return

    df_rank = st.session_state.yoy_df.copy()
    df_rank["product_name"] = df_rank["product_name"].apply(normalize_product_display_name)

    st.markdown(f"#### ğŸ† ç¬¬ä¸€éšå±¤ï¼šæˆåˆ†ã‚­ãƒ¼ï¼ˆYJå„ªå…ˆï¼‰{st.session_state.yoy_mode} ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    event = st.dataframe(
        df_rank[["product_name", "ty_sales", "py_sales", "sales_diff_yoy"]].rename(
            columns={
                "product_name": "ä»£è¡¨å•†å“å(æˆåˆ†)",
                "ty_sales": "ä»ŠæœŸå£²ä¸Š",
                "py_sales": "å‰æœŸå£²ä¸Š",
                "sales_diff_yoy": "å‰å¹´æ¯”å·®é¡",
            }
        ).style.format({"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´æ¯”å·®é¡": "Â¥{:,.0f}"}),
        use_container_width=True,
        hide_index=True,
        selection_mode="single-row",
        on_select="rerun",
        key=f"grid_yoy_{st.session_state.yoy_mode}",
    )

    try:
        sel_rows = event.selection.rows if hasattr(event, "selection") else []
        if sel_rows:
            st.session_state.selected_yoy_key = str(df_rank.iloc[sel_rows[0]]["yj_key"])
    except Exception:
        pass

    st.divider()
    st.header("ğŸ” ç¬¬äºŒéšå±¤ï¼šè©³ç´°åˆ†æï¼ˆã‚¹ã‚³ãƒ¼ãƒ—å†…ï¼‰")

    key_opts = ["å…¨æˆåˆ†ã‚’è¡¨ç¤º"] + list(df_rank["yj_key"].astype(str).unique())
    display_map = {"å…¨æˆåˆ†ã‚’è¡¨ç¤º": "ğŸš© ã‚¹ã‚³ãƒ¼ãƒ—å†…ã®å…¨æˆåˆ†ã‚’åˆè¨ˆã—ã¦è¡¨ç¤º"}
    for _, r in df_rank.iterrows():
        k = str(r["yj_key"])
        display_map[k] = f"{normalize_product_display_name(r['product_name'])}ï¼ˆå·®é¡: Â¥{r['sales_diff_yoy']:,.0f}ï¼‰"

    idx = 0
    if st.session_state.selected_yoy_key in key_opts:
        idx = key_opts.index(st.session_state.selected_yoy_key)

    selected_key = st.selectbox(
        "è©³ç´°ã‚’è¦‹ãŸã„æˆåˆ†ã‚­ãƒ¼ã‚’é¸æŠï¼ˆ[å…¨æˆåˆ†ã‚’è¡¨ç¤º]ã§å…¨é‡ï¼‰",
        options=key_opts,
        index=idx,
        format_func=lambda x: display_map.get(x, x),
    )
    st.session_state.selected_yoy_key = selected_key

    # å…¨ä»¶è¡¨ç¤ºçµ±åˆ¶ï¼ˆæ®µéšUIï¼‰
    st.markdown("##### ğŸ“Œ å…¨ä»¶è¡¨ç¤ºï¼ˆLIMITãªã—ï¼‰ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    full1, full2 = st.columns([1, 2])
    show_all = full1.checkbox("å…¨ä»¶è¡¨ç¤ºï¼ˆLIMITãªã—ï¼‰", value=False, key="yoy_show_all")
    st.caption("â€» å…¨ä»¶è¡¨ç¤ºã¯é‡ããªã‚Šã¾ã™ã€‚ç®¡ç†è€…ã§ã‚¹ã‚³ãƒ¼ãƒ—æœªæŒ‡å®šã®å ´åˆã€æ¨å®šâ†’ä¸Šé™â†’å®Ÿè¡Œã‚’å¼·åˆ¶ã—ã¾ã™ã€‚")

    role_filter = "" if role.role_admin_view else "login_email = @login_email"
    scope_where = scope.where_clause()

    params: Dict[str, Any] = dict(scope.params or {})
    if not role.role_admin_view:
        params["login_email"] = role.login_email

    key_filter = ""
    if selected_key != "å…¨æˆåˆ†ã‚’è¡¨ç¤º":
        key_expr = """
          COALESCE(
            NULLIF(NULLIF(TRIM(CAST(yj_code AS STRING)), ''), '0'),
            NULLIF(NULLIF(TRIM(CAST(jan_code AS STRING)), ''), '0'),
            REGEXP_REPLACE(CAST(product_name AS STRING), r"[/ï¼].*$", "")
          )
        """
        key_filter = f"{' '.join(key_expr.split())} = @target_key"
        params["target_key"] = selected_key

    where_sql = _compose_where(role_filter, scope_where, key_filter)
    sort_order = "ASC" if st.session_state.yoy_mode == "ãƒ¯ãƒ¼ã‚¹ãƒˆ" else "DESC"

    # ---- å¾—æ„å…ˆåˆ¥å†…è¨³
    st.markdown("#### ğŸ§¾ å¾—æ„å…ˆåˆ¥å†…è¨³ï¼ˆå‰å¹´å·®é¡ï¼‰")
    limit_sql = "" if show_all else "LIMIT 50"
    sql_cust = f"""
      WITH fy AS (
        SELECT
          (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
           - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
      ),
      base AS (
        SELECT
          customer_name,
          SUM(CASE WHEN fiscal_year = fy.current_fy THEN sales_amount ELSE 0 END) AS ty_sales,
          SUM(CASE WHEN fiscal_year = fy.current_fy - 1 THEN sales_amount ELSE 0 END) AS py_sales
        FROM `{VIEW_UNIFIED}`
        CROSS JOIN fy
        {where_sql}
        GROUP BY customer_name
      )
      SELECT
        customer_name AS `å¾—æ„å…ˆå`,
        ty_sales AS `ä»ŠæœŸå£²ä¸Š`,
        py_sales AS `å‰æœŸå£²ä¸Š`,
        (ty_sales - py_sales) AS `å‰å¹´å·®é¡`
      FROM base
      WHERE ty_sales != 0 OR py_sales != 0
      ORDER BY `å‰å¹´å·®é¡` {sort_order}
      {limit_sql}
    """

    df_cust = guard_and_run_query_ui(
        client,
        role,
        scope,
        sql_cust,
        params,
        label="YoY è©³ç´°ï¼šå¾—æ„å…ˆåˆ¥å†…è¨³",
        risky_if_no_scope=True,
        force_estimate=show_all,
        timeout_sec=180,
    )
    if not df_cust.empty:
        st.dataframe(
            df_cust.fillna(0).style.format(
                {"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´å·®é¡": "Â¥{:,.0f}"}
            ),
            use_container_width=True,
            hide_index=True,
        )

    # ---- JANãƒ»å•†å“åˆ¥
    st.markdown("#### ğŸ§ª åŸå› è¿½åŠï¼šJANãƒ»å•†å“åˆ¥ï¼ˆå‰å¹´å·®é¡å¯„ä¸ï¼‰")
    sql_jan = f"""
      WITH fy AS (
        SELECT
          (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
           - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
      ),
      base AS (
        SELECT
          CAST(jan_code AS STRING) AS jan,
          REGEXP_REPLACE(CAST(product_name AS STRING), r"[/ï¼].*$", "") AS product_base,
          CAST(package_unit AS STRING) AS package_unit,
          SUM(CASE WHEN fiscal_year = fy.current_fy THEN sales_amount ELSE 0 END) AS ty_sales,
          SUM(CASE WHEN fiscal_year = fy.current_fy - 1 THEN sales_amount ELSE 0 END) AS py_sales
        FROM `{VIEW_UNIFIED}`
        CROSS JOIN fy
        {where_sql}
        GROUP BY jan, product_base, package_unit
      )
      SELECT
        jan AS `JAN`,
        product_base AS `ä»£è¡¨å•†å“å`,
        package_unit AS `åŒ…è£…`,
        ty_sales AS `ä»ŠæœŸå£²ä¸Š`,
        py_sales AS `å‰æœŸå£²ä¸Š`,
        (ty_sales - py_sales) AS `å‰å¹´å·®é¡`
      FROM base
      WHERE ty_sales != 0 OR py_sales != 0
      ORDER BY `å‰å¹´å·®é¡` {sort_order}
      {"" if show_all else "LIMIT 500"}
    """

    df_jan = guard_and_run_query_ui(
        client,
        role,
        scope,
        sql_jan,
        params,
        label="YoY è©³ç´°ï¼šJANãƒ»å•†å“åˆ¥",
        risky_if_no_scope=True,
        force_estimate=show_all,
        timeout_sec=240,
    )
    if not df_jan.empty:
        st.dataframe(
            df_jan.fillna(0).style.format(
                {"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´å·®é¡": "Â¥{:,.0f}"}
            ),
            use_container_width=True,
            hide_index=True,
        )

    # ---- æœˆæ¬¡æ¨ç§»
    st.markdown("#### ğŸ“… åŸå› è¿½åŠï¼šæœˆæ¬¡æ¨ç§»ï¼ˆå‰å¹´å·®é¡ï¼‰")
    sql_month = f"""
      WITH fy AS (
        SELECT
          (EXTRACT(YEAR FROM CURRENT_DATE('Asia/Tokyo'))
           - CASE WHEN EXTRACT(MONTH FROM CURRENT_DATE('Asia/Tokyo')) < 4 THEN 1 ELSE 0 END) AS current_fy
      ),
      base AS (
        SELECT
          FORMAT_DATE('%Y-%m', sales_date) AS ym,
          SUM(CASE WHEN fiscal_year = fy.current_fy THEN sales_amount ELSE 0 END) AS ty_sales,
          SUM(CASE WHEN fiscal_year = fy.current_fy - 1 THEN sales_amount ELSE 0 END) AS py_sales
        FROM `{VIEW_UNIFIED}`
        CROSS JOIN fy
        {where_sql}
        GROUP BY ym
      )
      SELECT
        ym AS `å¹´æœˆ`,
        ty_sales AS `ä»ŠæœŸå£²ä¸Š`,
        py_sales AS `å‰æœŸå£²ä¸Š`,
        (ty_sales - py_sales) AS `å‰å¹´å·®é¡`
      FROM base
      ORDER BY `å¹´æœˆ`
    """
    df_month = guard_and_run_query_ui(
        client,
        role,
        scope,
        sql_month,
        params,
        label="YoY è©³ç´°ï¼šæœˆæ¬¡æ¨ç§»",
        risky_if_no_scope=True,
        force_estimate=False,
        timeout_sec=180,
    )
    if not df_month.empty:
        st.dataframe(
            df_month.fillna(0).style.format(
                {"ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}", "å‰å¹´å·®é¡": "Â¥{:,.0f}"}
            ),
            use_container_width=True,
            hide_index=True,
        )


def render_new_deliveries_section(client: bigquery.Client, role: RoleInfo, scope: ScopeFilter) -> None:
    st.subheader("ğŸ‰ æ–°è¦ç´å“ã‚µãƒãƒªãƒ¼ï¼ˆRealized / å®Ÿç¸¾ï¼‰")

    cols = resolve_view_columns_map(client)["new_delivery"]
    # åˆ—åå·®ç•°å¸åï¼šå¿…é ˆåˆ—ãŒè§£æ±ºã§ããªã„å ´åˆã¯ã€Œå‹•ã‹ãªã„ã€ã®ã§ã€ã“ã“ã§æ˜ç¤ºã—ã¦è½ã¨ã™ï¼ˆå®Ÿåƒç ´å£Šå›é¿ï¼‰
    required = ["first_sales_date", "customer_code", "jan_code", "sales_amount", "gross_profit"]
    if any(not cols.get(k) for k in required):
        st.error("æ–°è¦ç´å“VIEWã®åˆ—åãŒè§£æ±ºã§ãã¾ã›ã‚“ã€‚VIEW_NEW_DELIVERYã®ã‚¹ã‚­ãƒ¼ãƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.code(str(cols))
        return

    fsd = cols["first_sales_date"]
    cust = cols["customer_code"]
    jan = cols["jan_code"]
    sa = cols["sales_amount"]
    gp = cols["gross_profit"]
    le = cols.get("login_email")  # ç„¡ã„å ´åˆã‚ã‚Š

    if st.button("æ–°è¦ç´å“å®Ÿç¸¾ã‚’èª­ã¿è¾¼ã‚€", key="btn_new_deliv"):
        where_ext = ""
        params = dict(scope.params or {})
        scope_clause = scope.where_clause()
        # scopeã¯VIEW_UNIFIEDå‰æã®ãŸã‚ã€NEW_DELIVERYã«ç›´æ¥å½“ã¦ã‚‹ã®ã¯å±é™ºï¼ˆåˆ—ãŒç„¡ã„å¯èƒ½æ€§ï¼‰ã€‚
        # ã“ã“ã§ã¯ã€Œå®Ÿåƒç¶­æŒã€ã‚’å„ªå…ˆã—ã€NEW_DELIVERYã§ã¯ã‚¹ã‚³ãƒ¼ãƒ—ï¼ˆé¡§å®¢åLIKE/ã‚°ãƒ«ãƒ¼ãƒ—ï¼‰ã‚’é©ç”¨ã—ãªã„ã€‚
        # ä»£ã‚ã‚Šã«ã€æ‹…å½“è€…åˆ¶é™ã®ã¿ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ï¼‰ã‚’é©ç”¨ã€‚
        if not role.role_admin_view and le:
            where_ext = f"AND {bq_ident(le)} = @login_email"
            params["login_email"] = role.login_email

        sql = f"""
        WITH td AS (SELECT CURRENT_DATE('Asia/Tokyo') AS today)
        SELECT
          'â‘  æ˜¨æ—¥' AS `æœŸé–“`,
          COUNT(DISTINCT {bq_ident(cust)}) AS `å¾—æ„å…ˆæ•°`,
          COUNT(DISTINCT {bq_ident(jan)}) AS `å“ç›®æ•°`,
          SUM({bq_ident(sa)}) AS `å£²ä¸Š`,
          SUM({bq_ident(gp)}) AS `ç²—åˆ©`
        FROM `{VIEW_NEW_DELIVERY}` CROSS JOIN td
        WHERE {bq_ident(fsd)} = DATE_SUB(today, INTERVAL 1 DAY) {where_ext}
        UNION ALL
        SELECT
          'â‘¡ ç›´è¿‘7æ—¥',
          COUNT(DISTINCT {bq_ident(cust)}),
          COUNT(DISTINCT {bq_ident(jan)}),
          SUM({bq_ident(sa)}),
          SUM({bq_ident(gp)})
        FROM `{VIEW_NEW_DELIVERY}` CROSS JOIN td
        WHERE {bq_ident(fsd)} >= DATE_SUB(today, INTERVAL 7 DAY) {where_ext}
        UNION ALL
        SELECT
          'â‘¢ å½“æœˆ',
          COUNT(DISTINCT {bq_ident(cust)}),
          COUNT(DISTINCT {bq_ident(jan)}),
          SUM({bq_ident(sa)}),
          SUM({bq_ident(gp)})
        FROM `{VIEW_NEW_DELIVERY}` CROSS JOIN td
        WHERE DATE_TRUNC({bq_ident(fsd)}, MONTH) = DATE_TRUNC(today, MONTH) {where_ext}
        ORDER BY `æœŸé–“`
        """
        df_new = query_df_safe(client, sql, params if params else None, label="New Deliveries")

        if not df_new.empty:
            df_new[["å£²ä¸Š", "ç²—åˆ©"]] = df_new[["å£²ä¸Š", "ç²—åˆ©"]].fillna(0)
            st.dataframe(
                df_new.style.format({"å£²ä¸Š": "Â¥{:,.0f}", "ç²—åˆ©": "Â¥{:,.0f}"}),
                use_container_width=True,
                hide_index=True,
            )
        else:
            st.info("æ–°è¦ç´å“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")


def render_adoption_alerts_section(client: bigquery.Client, role: RoleInfo, scope: ScopeFilter) -> None:
    st.subheader("ğŸš¨ æ¡ç”¨ã‚¢ã‚¤ãƒ†ãƒ ãƒ»å¤±æ³¨ã‚¢ãƒ©ãƒ¼ãƒˆ")

    cols = resolve_view_columns_map(client)["adoption"]
    required = ["customer_name", "product_name", "last_purchase_date", "adoption_status", "current_fy_sales", "previous_fy_sales"]
    if any(not cols.get(k) for k in required):
        st.error("æ¡ç”¨ã‚¢ãƒ©ãƒ¼ãƒˆVIEWã®åˆ—åãŒè§£æ±ºã§ãã¾ã›ã‚“ã€‚VIEW_ADOPTIONã®ã‚¹ã‚­ãƒ¼ãƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.code(str(cols))
        return

    staff = cols.get("staff_name")
    cust = cols["customer_name"]
    prod = cols["product_name"]
    lastd = cols["last_purchase_date"]
    stat = cols["adoption_status"]
    cur = cols["current_fy_sales"]
    py = cols["previous_fy_sales"]
    le = cols.get("login_email")

    where_clause = ""
    params = dict(scope.params or {})
    # scopeã¯VIEW_UNIFIEDå‰æã€‚ADOPTIONã«ç›´æ¥å½“ã¦ã‚‹ã¨å£Šã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ã€Œå®Ÿåƒç¶­æŒã€å„ªå…ˆã§é©ç”¨ã—ãªã„ã€‚
    # ä»£ã‚ã‚Šã«æ‹…å½“è€…åˆ¶é™ã®ã¿ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ï¼‰ã€‚
    if (not role.role_admin_view) and le:
        where_clause = f"WHERE {bq_ident(le)} = @login_email"
        params["login_email"] = role.login_email

    sql = f"""
        SELECT
            {bq_ident(staff) if staff else "'æœªè¨­å®š'"} AS `æ‹…å½“è€…å`,
            {bq_ident(cust)} AS `å¾—æ„å…ˆå`,
            {bq_ident(prod)} AS `å•†å“å`,
            {bq_ident(lastd)} AS `æœ€çµ‚è³¼å…¥æ—¥`,
            {bq_ident(stat)} AS `ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹`,
            {bq_ident(cur)} AS `ä»ŠæœŸå£²ä¸Š`,
            {bq_ident(py)} AS `å‰æœŸå£²ä¸Š`,
            ({bq_ident(cur)} - {bq_ident(py)}) AS `å£²ä¸Šå·®é¡`
        FROM `{VIEW_ADOPTION}`
        {where_clause}
        ORDER BY
            CASE
                WHEN CAST({bq_ident(stat)} AS STRING) LIKE '%ğŸ”´%' THEN 1
                WHEN CAST({bq_ident(stat)} AS STRING) LIKE '%ğŸŸ¡%' THEN 2
                ELSE 3
            END,
            `å£²ä¸Šå·®é¡` ASC
    """

    df_alerts = guard_and_run_query_ui(
        client,
        role,
        scope,
        sql,
        params if params else None,
        label="æ¡ç”¨ãƒ»å¤±æ³¨ã‚¢ãƒ©ãƒ¼ãƒˆ",
        risky_if_no_scope=True,
        force_estimate=False,
        timeout_sec=180,
    )
    if df_alerts.empty:
        st.info("ç¾åœ¨ã€ã‚¢ãƒ©ãƒ¼ãƒˆå¯¾è±¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df_alerts["æ‹…å½“è€…å"] = df_alerts["æ‹…å½“è€…å"].fillna("æœªè¨­å®š")
    col1, col2 = st.columns(2)
    with col1:
        selected_status = st.multiselect(
            "ğŸ¯ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§çµã‚Šè¾¼ã¿",
            options=df_alerts["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"].unique(),
            default=[s for s in df_alerts["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"].unique() if "ğŸŸ¡" in str(s) or "ğŸ”´" in str(s)],
        )
    with col2:
        all_staffs = sorted(df_alerts["æ‹…å½“è€…å"].unique().tolist())
        selected_staffs = st.multiselect("ğŸ‘¤ æ‹…å½“è€…ã§çµã‚Šè¾¼ã¿", options=all_staffs, default=[])

    df_display = df_alerts.copy()
    if selected_status:
        df_display = df_display[df_display["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"].isin(selected_status)]
    if selected_staffs:
        df_display = df_display[df_display["æ‹…å½“è€…å"].isin(selected_staffs)]

    if df_display.empty:
        st.info("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    for col in ["ä»ŠæœŸå£²ä¸Š", "å‰æœŸå£²ä¸Š", "å£²ä¸Šå·®é¡"]:
        df_display[col] = pd.to_numeric(df_display[col], errors="coerce").fillna(0)

    st.dataframe(
        df_display.style.format(
            {
                "ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}",
                "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}",
                "å£²ä¸Šå·®é¡": "Â¥{:,.0f}",
                "æœ€çµ‚è³¼å…¥æ—¥": lambda t: t.strftime("%Y-%m-%d") if pd.notnull(t) else "",
            }
        ),
        use_container_width=True,
        hide_index=True,
    )


def render_customer_drilldown(client: bigquery.Client, role: RoleInfo, scope: ScopeFilter) -> None:
    st.subheader("ğŸ¯ æ‹…å½“å…ˆãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ ï¼† ææ¡ˆï¼ˆRecoï¼‰")

    cols_map = resolve_view_columns_map(client)
    u = cols_map["unified"]
    r = cols_map["recommend"]
    a = cols_map["adoption"]

    # --- å¾—æ„å…ˆä¸€è¦§ï¼ˆVIEW_UNIFIEDï¼šã‚¹ã‚³ãƒ¼ãƒ—é©ç”¨OKï¼‰
    role_filter = "" if role.role_admin_view else f"{bq_ident(u['login_email'])} = @login_email"
    scope_filter = scope.where_clause()
    customer_where = _compose_where(role_filter, scope_filter, f"{bq_ident(u['customer_name'])} IS NOT NULL")

    customer_params: Dict[str, Any] = dict(scope.params or {})
    if not role.role_admin_view:
        customer_params["login_email"] = role.login_email

    sql_cust = f"""
        SELECT DISTINCT {bq_ident(u['customer_code'])} AS customer_code, {bq_ident(u['customer_name'])} AS customer_name
        FROM `{VIEW_UNIFIED}`
        {customer_where}
        LIMIT 2000
    """
    df_cust = guard_and_run_query_ui(
        client,
        role,
        scope,
        sql_cust,
        customer_params,
        label="å¾—æ„å…ˆä¸€è¦§ï¼ˆã‚¹ã‚³ãƒ¼ãƒ—å†…ï¼‰",
        risky_if_no_scope=True,
        force_estimate=False,
        timeout_sec=120,
    )
    if df_cust.empty:
        st.info("è¡¨ç¤ºã§ãã‚‹å¾—æ„å…ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    search_term = st.text_input("ğŸ” å¾—æ„å…ˆåã§æ¤œç´¢ï¼ˆä¸€éƒ¨å…¥åŠ›ï¼‰", placeholder="ä¾‹ï¼šå¤è³€")
    filtered_df = df_cust[df_cust["customer_name"].str.contains(search_term, na=False)] if search_term else df_cust
    if filtered_df.empty:
        st.info("æ¤œç´¢æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹å¾—æ„å…ˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    opts = {row["customer_code"]: f"{row['customer_code']} : {row['customer_name']}" for _, row in filtered_df.iterrows()}
    sel = st.selectbox("å¾—æ„å…ˆã‚’é¸æŠ", options=list(opts.keys()), format_func=lambda x: opts[x])
    if not sel:
        return

    st.divider()
    st.markdown("##### ğŸ“¦ ç¾åœ¨ã®æ¡ç”¨ã‚¢ã‚¤ãƒ†ãƒ ï¼ˆç¨¼åƒçŠ¶æ³ï¼‰")

    # --- æ¡ç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆVIEW_ADOPTIONï¼šcustomer_codeåˆ—ãŒå¿…è¦ï¼‰
    if not a.get("customer_code"):
        st.warning("æ¡ç”¨VIEWã« customer_code ãŒè¦‹å½“ãŸã‚Šã¾ã›ã‚“ã€‚æ¡ç”¨å†…è¨³ã®è¡¨ç¤ºã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
    else:
        sql_adopt = f"""
            SELECT
                {bq_ident(a['product_name'])} AS `å•†å“å`,
                {bq_ident(a['adoption_status'])} AS `ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹`,
                {bq_ident(a['last_purchase_date'])} AS `æœ€çµ‚è³¼å…¥æ—¥`,
                {bq_ident(a['current_fy_sales'])} AS `ä»ŠæœŸå£²ä¸Š`,
                {bq_ident(a['previous_fy_sales'])} AS `å‰æœŸå£²ä¸Š`
            FROM `{VIEW_ADOPTION}`
            WHERE CAST({bq_ident(a['customer_code'])} AS STRING) = @c
            ORDER BY
                CASE
                    WHEN CAST({bq_ident(a['adoption_status'])} AS STRING) LIKE '%ğŸŸ¢%' THEN 1
                    WHEN CAST({bq_ident(a['adoption_status'])} AS STRING) LIKE '%ğŸŸ¡%' THEN 2
                    ELSE 3
                END,
                `ä»ŠæœŸå£²ä¸Š` DESC
        """
        df_adopt = query_df_safe(client, sql_adopt, {"c": str(sel)}, "Customer Adoption")
        if not df_adopt.empty:
            for col in ["ä»ŠæœŸå£²ä¸Š", "å‰æœŸå£²ä¸Š"]:
                df_adopt[col] = pd.to_numeric(df_adopt[col], errors="coerce").fillna(0)
            st.dataframe(
                df_adopt.style.format(
                    {
                        "ä»ŠæœŸå£²ä¸Š": "Â¥{:,.0f}",
                        "å‰æœŸå£²ä¸Š": "Â¥{:,.0f}",
                        "æœ€çµ‚è³¼å…¥æ—¥": lambda t: t.strftime("%Y-%m-%d") if pd.notnull(t) else "",
                    }
                ),
                use_container_width=True,
                hide_index=True,
            )
        else:
            st.info("ã“ã®å¾—æ„å…ˆã®æ¡ç”¨ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    st.markdown("<br>", unsafe_allow_html=True)
    st.markdown("##### ğŸ’¡ AI æ¨å¥¨ææ¡ˆå•†å“ï¼ˆRecoï¼‰")

    # â˜…é‡è¦ï¼šVIEW_RECOMMEND.customer_code ã¯ INT64ã€VIEW_UNIFIED.customer_code ã¯ STRING
    # â†’ ç…§åˆã¯ CAST(customer_code AS STRING) = @c ã§å®‰å…¨ã«çµ±ä¸€ï¼ˆè¸è¥²ï¼‰
    if not r.get("customer_code") or not r.get("priority_rank") or not r.get("recommend_product"):
        st.warning("Reco VIEWã®å¿…è¦åˆ—ãŒè§£æ±ºã§ãã¾ã›ã‚“ã€‚Recoã®è¡¨ç¤ºã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        st.code(str(r))
        return

    sql_rec = f"""
        SELECT
          {bq_ident(r['customer_name']) if r.get('customer_name') else "NULL"} AS customer_name,
          {bq_ident(r['strong_category']) if r.get('strong_category') else "NULL"} AS strong_category,
          {bq_ident(r['priority_rank'])} AS priority_rank,
          {bq_ident(r['recommend_jan']) if r.get('recommend_jan') else "NULL"} AS recommend_jan,
          {bq_ident(r['recommend_product'])} AS recommend_product,
          {bq_ident(r['manufacturer']) if r.get('manufacturer') else "NULL"} AS manufacturer,
          {bq_ident(r['market_scale']) if r.get('market_scale') else "NULL"} AS market_scale
        FROM `{VIEW_RECOMMEND}`
        WHERE CAST({bq_ident(r['customer_code'])} AS STRING) = @c
        ORDER BY priority_rank ASC
        LIMIT 10
    """
    df_rec = query_df_safe(client, sql_rec, {"c": str(sel)}, "Recommendation")
    if not df_rec.empty:
        df_disp = df_rec[["priority_rank", "recommend_product", "manufacturer", "strong_category", "market_scale"]].rename(
            columns={
                "priority_rank": "é †ä½",
                "recommend_product": "æ¨å¥¨å•†å“",
                "manufacturer": "ãƒ¡ãƒ¼ã‚«ãƒ¼",
                "strong_category": "å¼·ã¿åˆ†é¡",
                "market_scale": "å¸‚å ´è¦æ¨¡",
            }
        )
        st.dataframe(df_disp, use_container_width=True, hide_index=True)
    else:
        st.info("ç¾åœ¨ã€ã“ã®å¾—æ„å…ˆã¸ã®æ¨å¥¨å•†å“ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")


# -----------------------------
# 5. Main Loop
# -----------------------------
def main() -> None:
    set_page()
    client = setup_bigquery_client()

    with st.sidebar:
        st.header("ğŸ”‘ ãƒ­ã‚°ã‚¤ãƒ³")
        login_id = st.text_input("ãƒ­ã‚°ã‚¤ãƒ³ID (ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹)")
        login_pw = st.text_input("ãƒ‘ã‚¹ã‚³ãƒ¼ãƒ‰ (æºå¸¯ä¸‹4æ¡)", type="password")

        st.divider()
        st.session_state.use_bqstorage = st.checkbox("é«˜é€Ÿèª­è¾¼ (Storage API)", value=True)

        if st.button("ğŸ“¡ é€šä¿¡ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"):
            try:
                client.query("SELECT 1").result(timeout=10)
                st.success("BigQuery æ¥ç¶šæ­£å¸¸")
            except Exception as e:
                st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")

        if st.button("ğŸ§¹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"):
            st.cache_data.clear()
            st.cache_resource.clear()

    if not login_id or not login_pw:
        st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
        return

    role = resolve_role(client, login_id.strip(), login_pw.strip())
    if not role.is_authenticated:
        st.error("âŒ ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ã“ã“ã§ä¸€åº¦ã€åˆ—åå·®ç•°å¸åã®è§£æ±ºã‚’èµ°ã‚‰ã›ã¦ãŠãï¼ˆå®Ÿåƒã§ã®çªç„¶æ­»ã‚’é˜²ãï¼‰
    try:
        _ = resolve_view_columns_map(client)
    except Exception as e:
        st.error(f"åˆ—åè‡ªå‹•è§£æ±ºã®åˆæœŸåŒ–ã§ã‚¨ãƒ©ãƒ¼: {e}")
        return

    st.success(f"ğŸ”“ ãƒ­ã‚°ã‚¤ãƒ³ä¸­: {role.staff_name} ã•ã‚“")
    c1, c2, c3 = st.columns(3)
    c1.metric("ğŸ‘¤ æ‹…å½“", role.staff_name)
    c2.metric("ğŸ›¡ï¸ æ¨©é™", role.role_key)
    c3.metric("ğŸ“ é›»è©±", role.phone)
    st.divider()

    # â˜…è¡¨ç¤ºé †åºï¼šã‚µãƒãƒªãƒ¼ã‚’æœ€ä¸Šéƒ¨ã«ï¼ˆè¸è¥²ï¼‰
    if role.role_admin_view:
        render_fytd_org_section(client)
    else:
        render_fytd_me_section(client, role.login_email)

    st.divider()

    # â˜…è¡¨ç¤ºé †åºï¼šãã®ä¸‹ã«ã‚¹ã‚³ãƒ¼ãƒ—è¨­å®šï¼ˆè¸è¥²ï¼‰
    scope = render_scope_filters(client, role)
    st.divider()

    # ç®¡ç†è€…çµ±åˆ¶ã®èª¬æ˜ï¼ˆæ˜ç¤ºï¼‰
    if role.role_admin_view and scope.is_empty():
        st.warning("ç®¡ç†è€…ã‚¹ã‚³ãƒ¼ãƒ—æœªæŒ‡å®šï¼å…¨ç¤¾ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®çµ±åˆ¶è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.caption("ï¼ˆæ¨å®šâ†’ä¸Šé™â†’å®Ÿè¡Œã®çµ±åˆ¶ã¯ã€é‡ã„/å…¨ä»¶ç³»ã‚¯ã‚¨ãƒªã§è‡ªå‹•é©ç”¨ã•ã‚Œã¾ã™ï¼‰")

    # ---- sectionsï¼ˆè¸è¥²ï¼‹è¿½åŠ ï¼‰
    if role.role_admin_view:
        render_group_underperformance_section(client, role, scope)
        st.divider()
        render_yoy_section(client, role, scope)
        st.divider()
        render_new_deliveries_section(client, role, scope)
        st.divider()
        render_adoption_alerts_section(client, role, scope)
        st.divider()
        render_customer_drilldown(client, role, scope)
    else:
        render_yoy_section(client, role, scope)
        st.divider()
        render_new_deliveries_section(client, role, scope)
        st.divider()
        render_adoption_alerts_section(client, role, scope)
        st.divider()
        render_customer_drilldown(client, role, scope)


if __name__ == "__main__":
    main()
