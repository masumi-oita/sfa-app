from __future__ import annotations

import os
import re
import time
from dataclasses import dataclass
from typing import Any, Dict, Optional, Tuple, List

import pandas as pd
import streamlit as st

from google.cloud import bigquery
from google.oauth2 import service_account
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FuturesTimeoutError


# ============================================================
# CONFIG
# ============================================================
PROJECT_ID = os.getenv("BQ_PROJECT_ID", "salesdb-479915")
DATASET = os.getenv("BQ_DATASET", "sales_data")

V_SYS_MONTH = f"`{PROJECT_ID}.{DATASET}.v_sys_current_month`"

V_ADMIN_ORG_FYTD_SCOPED = f"`{PROJECT_ID}.{DATASET}.v_admin_org_fytd_summary_scoped`"
V_ADMIN_FYTD_MOM_TOP_SCOPED = f"`{PROJECT_ID}.{DATASET}.v_admin_customer_fytd_top_named_scoped`"
V_ADMIN_FYTD_MOM_BOTTOM_SCOPED = f"`{PROJECT_ID}.{DATASET}.v_admin_customer_fytd_bottom_named_scoped`"

V_YOY_TOP = f"`{PROJECT_ID}.{DATASET}.v_sales_customer_yoy_top_current_month`"
V_YOY_BOTTOM = f"`{PROJECT_ID}.{DATASET}.v_sales_customer_yoy_bottom_current_month`"
V_YOY_INVALID = f"`{PROJECT_ID}.{DATASET}.v_sales_customer_yoy_uncomparable_current_month`"

V_FACT = f"`{PROJECT_ID}.{DATASET}.v_sales_fact_login_jan_daily`"
V_STAFF_EMAIL_NAME = f"`{PROJECT_ID}.{DATASET}.v_staff_email_name`"
DIM_STAFF_ROLE = f"`{PROJECT_ID}.{DATASET}.dim_staff_role`"

# BigQuery timeoutï¼ˆSQLå®Ÿè¡Œï¼‰
BQ_TIMEOUT_SEC = int(os.getenv("BQ_TIMEOUT_SEC", "60"))
# BigQuery client åˆæœŸåŒ– timeoutï¼ˆâ˜…ã“ã“ãŒä»Šå›ã®ä¸»çŠ¯ï¼‰
BQ_CLIENT_INIT_TIMEOUT_SEC = int(os.getenv("BQ_CLIENT_INIT_TIMEOUT_SEC", "10"))


# ============================================================
# UI
# ============================================================
st.set_page_config(page_title="SFA Sales OSï¼ˆå…¥å£ï¼‰", layout="wide")
st.title("SFA Sales OSï¼ˆå…¥å£ï¼‰")  # çœŸã£é»’å›é¿


# ============================================================
# Utils
# ============================================================
def yen(x: Any) -> str:
    try:
        if pd.isna(x):
            return ""
        return f"Â¥{int(round(float(x))):,}"
    except Exception:
        return ""


def pct(x: Any) -> str:
    try:
        if pd.isna(x):
            return ""
        return f"{float(x) * 100:.1f}%"
    except Exception:
        return ""


def safe_lower(s: Any) -> str:
    return str(s).strip().lower() if s is not None else ""


def parse_code_from_label(label: str) -> str:
    m = re.search(r"\((.+?)\)\s*$", label)
    return m.group(1) if m else label


# ============================================================
# Perf log
# ============================================================
@dataclass
class QueryPerf:
    name: str
    ok: bool
    query_sec: float
    df_sec: float
    total_sec: float
    bytes_gb: float
    rows: int
    job_id: str
    note: str


if "perf_logs" not in st.session_state:
    st.session_state.perf_logs: List[QueryPerf] = []

if "cache_bust" not in st.session_state:
    st.session_state.cache_bust = 0


# ============================================================
# BigQuery Client (â˜…ã“ã“ã‚’å¼·åŒ–ï¼šsecretsæ˜ç¤º + init timeout)
# ============================================================
def _build_bq_client_strict() -> bigquery.Client:
    """
    Streamlit Cloudã§ bigquery.Client() ã®ADCæ¢ç´¢ãŒãƒãƒ³ã‚°ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚
    st.secrets ã® service account ã‚’å„ªå…ˆã—ã¦æ˜ç¤ºçš„ã«ä½œã‚‹ã€‚
    """
    # 1) Streamlit secrets ã« service account JSON ãŒã‚ã‚‹å ´åˆï¼ˆæ¨å¥¨ï¼‰
    if "gcp_service_account" in st.secrets:
        info = dict(st.secrets["gcp_service_account"])
        creds = service_account.Credentials.from_service_account_info(
            info,
            scopes=["https://www.googleapis.com/auth/cloud-platform"],
        )
        return bigquery.Client(project=PROJECT_ID, credentials=creds)

    # 2) ç„¡ã‘ã‚Œã°å¾“æ¥ã®ADCï¼ˆãŸã ã—ã“ã“ãŒãƒãƒ³ã‚°ã—ã‚„ã™ã„ï¼‰
    return bigquery.Client(project=PROJECT_ID)


@st.cache_resource
def get_bq_client() -> bigquery.Client:
    """
    â˜… clientç”Ÿæˆã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§è¡Œã„ã€timeoutã§å¿…ãšè½ã¨ã™
    """
    with ThreadPoolExecutor(max_workers=1) as ex:
        fut = ex.submit(_build_bq_client_strict)
        try:
            return fut.result(timeout=BQ_CLIENT_INIT_TIMEOUT_SEC)
        except FuturesTimeoutError:
            raise RuntimeError(
                f"BigQuery clientåˆæœŸåŒ–ãŒ {BQ_CLIENT_INIT_TIMEOUT_SEC}s ã‚’è¶…ãˆã¦ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚"
                "ï¼ˆADCæ¢ç´¢ãƒãƒ³ã‚°ã®å¯èƒ½æ€§å¤§ã€‚st.secrets['gcp_service_account'] ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰"
            )


def _make_job_config(params: Optional[Dict[str, Any]]) -> bigquery.QueryJobConfig:
    qps = []
    if params:
        for k, v in params.items():
            qps.append(bigquery.ScalarQueryParameter(k, "STRING", str(v)))
    return bigquery.QueryJobConfig(query_parameters=qps)


def _to_df(result, prefer_storage_api: bool) -> Tuple[pd.DataFrame, float, str]:
    t1 = time.time()
    note = ""
    try:
        if prefer_storage_api:
            df = result.to_dataframe(create_bqstorage_client=True)
            note = "df:StorageAPI"
        else:
            df = result.to_dataframe()
            note = "df:REST"
    except Exception as e:
        df = result.to_dataframe()
        note = f"df:fallback(REST) ({type(e).__name__})"
    t2 = time.time()
    return df, (t2 - t1), note


@st.cache_data(ttl=300, show_spinner=False)
def qdf_cached(
    sql: str,
    params: Optional[Dict[str, Any]],
    prefer_storage_api: bool,
    cache_bust: int,
    timeout_sec: int,
) -> Tuple[pd.DataFrame, QueryPerf]:
    t0 = time.time()

    # â˜…ã“ã“ã§ get_bq_client() ãŒæ­¢ã¾ã‚‹ãªã‚‰ã€å¿…ãšä¾‹å¤–ã§ç”»é¢ã«å‡ºã™
    client = get_bq_client()

    job = client.query(sql, job_config=_make_job_config(params))
    try:
        result = job.result(timeout=timeout_sec)
        t_query_done = time.time()

        df, df_sec, df_note = _to_df(result, prefer_storage_api=prefer_storage_api)
        t_end = time.time()

        bytes_gb = float(job.total_bytes_processed or 0) / 1e9
        perf = QueryPerf(
            name="",
            ok=True,
            query_sec=(t_query_done - t0),
            df_sec=df_sec,
            total_sec=(t_end - t0),
            bytes_gb=bytes_gb,
            rows=int(df.shape[0]),
            job_id=str(job.job_id),
            note=df_note,
        )
        return df, perf

    except Exception as e:
        t_end = time.time()
        perf = QueryPerf(
            name="",
            ok=False,
            query_sec=0.0,
            df_sec=0.0,
            total_sec=(t_end - t0),
            bytes_gb=0.0,
            rows=0,
            job_id=str(getattr(job, "job_id", "")),
            note=f"ERROR: {type(e).__name__}: {e}",
        )
        return pd.DataFrame(), perf


def qdf(
    name: str,
    sql: str,
    params: Optional[Dict[str, Any]] = None,
    prefer_storage_api: bool = True,
    show_check: bool = True,
) -> pd.DataFrame:
    df, perf = qdf_cached(
        sql=sql,
        params=params,
        prefer_storage_api=prefer_storage_api,
        cache_bust=st.session_state.cache_bust,
        timeout_sec=BQ_TIMEOUT_SEC,
    )
    perf.name = name
    st.session_state.perf_logs.append(perf)

    if show_check:
        if perf.ok:
            st.caption(
                f"âœ… [{perf.name}] query={perf.query_sec:.1f}s / df={perf.df_sec:.1f}s / total={perf.total_sec:.1f}s "
                f"| bytes={perf.bytes_gb:.2f}GB | rows={perf.rows:,} | {perf.note}"
            )
        else:
            st.error(f"âŒ [{perf.name}] {perf.note}")

    return df


# ============================================================
# Role / Name
# ============================================================
@st.cache_data(ttl=600, show_spinner=False)
def get_staff_name_norm(login_email: str) -> str:
    df, _ = qdf_cached(
        sql=f"""
            SELECT staff_name_norm
            FROM {V_STAFF_EMAIL_NAME}
            WHERE LOWER(login_email)=@email
            LIMIT 1
        """,
        params={"email": login_email},
        prefer_storage_api=True,
        cache_bust=0,
        timeout_sec=BQ_TIMEOUT_SEC,
    )
    if df.empty:
        return login_email
    return str(df.iloc[0]["staff_name_norm"])


@st.cache_data(ttl=600, show_spinner=False)
def get_role_scope(login_email: str) -> Dict[str, Any]:
    df, _ = qdf_cached(
        sql=f"""
            SELECT role_tier, area_name, scope_type
            FROM {DIM_STAFF_ROLE}
            WHERE LOWER(login_email)=@email
            LIMIT 1
        """,
        params={"email": login_email},
        prefer_storage_api=True,
        cache_bust=0,
        timeout_sec=BQ_TIMEOUT_SEC,
    )
    if df.empty:
        return {}
    return df.iloc[0].to_dict()


# ============================================================
# Sidebarï¼ˆrerun loopå¯¾ç­–æ¸ˆã¿ï¼‰
# ============================================================
with st.sidebar:
    st.header("ãƒ­ã‚°ã‚¤ãƒ³")

    qp_email = safe_lower(st.query_params.get("user_email", ""))
    user_email = safe_lower(st.text_input("user_emailï¼ˆãƒ¡ãƒ¼ãƒ«ï¼‰", value=qp_email))

    if user_email and qp_email != user_email:
        st.query_params["user_email"] = user_email

    prefer_storage_api = st.toggle("é«˜é€Ÿè»¢é€ï¼ˆStorage APIï¼‰ã‚’è©¦ã™", value=True)
    show_checks = st.toggle("ãƒã‚§ãƒƒã‚¯è¡¨ç¤ºï¼ˆSQLè¨ˆæ¸¬ã‚’è¡¨ç¤ºï¼‰", value=True)

    col_a, col_b = st.columns(2)
    if col_a.button("è¨ˆæ¸¬ãƒ­ã‚°ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.perf_logs = []
    if col_b.button("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–"):
        st.session_state.cache_bust += 1
        st.session_state.perf_logs = []

    st.divider()
    st.caption("â€»çœŸã£é»’/å›ºã¾ã‚‹æ™‚ï¼šãƒã‚§ãƒƒã‚¯è¡¨ç¤ºONã§ã©ã“ã§æ­¢ã¾ã£ã¦ã‚‹ã‹ç¢ºèªã§ãã¾ã™ã€‚")

if not user_email:
    st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ user_email ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    st.stop()


# ============================================================
# Headerï¼ˆå¿…ãšè¡¨ç¤ºï¼‰
# ============================================================
left, right = st.columns([2, 1])
with left:
    st.subheader(f"ãƒ­ã‚°ã‚¤ãƒ³: {user_email}")
with right:
    st.caption(f"BQ timeout: {BQ_TIMEOUT_SEC}s / client init timeout: {BQ_CLIENT_INIT_TIMEOUT_SEC}s")


# ============================================================
# â˜… client health checkï¼ˆã“ã“ã§æ­¢ã¾ã‚‹ãªã‚‰åŸå› ã¯èªè¨¼/ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰
# ============================================================
with st.spinner("BigQuery client åˆæœŸåŒ–ãƒã‚§ãƒƒã‚¯..."):
    try:
        _ = get_bq_client()
        st.success("BigQuery client OK")
    except Exception as e:
        st.error(f"BigQuery client åˆæœŸåŒ–ã«å¤±æ•—: {e}")
        st.stop()


# ============================================================
# current_month å–å¾—
# ============================================================
with st.spinner("sys_current_month å–å¾—ä¸­..."):
    sys_df = qdf(
        name="sys_current_month",
        sql=f"SELECT * FROM {V_SYS_MONTH} LIMIT 1",
        params=None,
        prefer_storage_api=prefer_storage_api,
        show_check=show_checks,
    )

if not sys_df.empty and "current_month" in sys_df.columns:
    current_month = str(sys_df.iloc[0]["current_month"])
else:
    current_month = "2026-01-01"

staff_name = get_staff_name_norm(user_email)
role = get_role_scope(user_email)

c1, c2, c3, c4 = st.columns(4)
c1.metric("Current month", current_month)
c2.metric("ãƒ­ã‚°ã‚¤ãƒ³æ°å", staff_name)
c3.metric("role_tier", role.get("role_tier", "-"))
c4.metric("area", role.get("area_name", "-"))

st.divider()

# ============================================================
# Tabs
# ============================================================
tab_admin, tab_drill, tab_perf = st.tabs(["ç®¡ç†è€…å…¥å£ï¼ˆåˆ†æï¼‰", "ãƒ‰ãƒªãƒ«ï¼ˆæ˜ç´°ï¼‰", "è¨ˆæ¸¬ãƒ­ã‚°ï¼ˆé…ã„åŸå› ï¼‰"])

with tab_admin:
    st.subheader("A) å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰")

    with st.spinner("FYTDã‚µãƒãƒªãƒ¼å–å¾—ä¸­..."):
        org = qdf(
            name="admin_org_fytd_summary_scoped",
            sql=f"""
                SELECT sales_amount_fytd, gross_profit_fytd, gross_profit_rate_fytd
                FROM {V_ADMIN_ORG_FYTD_SCOPED}
                WHERE viewer_email=@email
                LIMIT 1
            """,
            params={"email": user_email},
            prefer_storage_api=prefer_storage_api,
            show_check=show_checks,
        )

    if org.empty:
        st.warning("FYTDã‚µãƒãƒªãƒ¼ãŒå–å¾—ã§ãã¾ã›ã‚“ï¼ˆrole/area/scoped ã‚’ç¢ºèªï¼‰")
    else:
        r = org.iloc[0]
        k1, k2, k3 = st.columns(3)
        k1.metric("FYTD å£²ä¸Š", yen(r.get("sales_amount_fytd")))
        k2.metric("FYTD ç²—åˆ©", yen(r.get("gross_profit_fytd")))
        k3.metric("FYTD ç²—åˆ©ç‡", pct(r.get("gross_profit_rate_fytd")))

    st.divider()
    st.subheader("B) FYTD MoMï¼ˆå‰æœˆå·®ï¼‰ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    left, right = st.columns(2)

    with left:
        st.markdown("### ğŸ“‰ ä¸‹è½ï¼ˆFYTD å‰æœˆå·®ï¼‰")
        with st.spinner("ä¸‹è½ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—ä¸­..."):
            bottom = qdf(
                name="admin_customer_fytd_bottom_named_scoped",
                sql=f"""
                    SELECT
                      å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰,
                      å¾—æ„å…ˆå,
                      æ”¯åº—å,
                      sales_amount_fytd,
                      gross_profit_fytd,
                      sales_diff_mom,
                      gross_profit_diff_mom
                    FROM {V_ADMIN_FYTD_MOM_BOTTOM_SCOPED}
                    WHERE viewer_email=@email
                    ORDER BY sales_diff_mom ASC
                    LIMIT 50
                """,
                params={"email": user_email},
                prefer_storage_api=prefer_storage_api,
                show_check=show_checks,
            )
        st.dataframe(bottom, use_container_width=True, height=520)

    with right:
        st.markdown("### ğŸ“ˆ ä¼¸é•·ï¼ˆFYTD å‰æœˆå·®ï¼‰")
        with st.spinner("ä¼¸é•·ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—ä¸­..."):
            top = qdf(
                name="admin_customer_fytd_top_named_scoped",
                sql=f"""
                    SELECT
                      å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰,
                      å¾—æ„å…ˆå,
                      æ”¯åº—å,
                      sales_amount_fytd,
                      gross_profit_fytd,
                      sales_diff_mom,
                      gross_profit_diff_mom
                    FROM {V_ADMIN_FYTD_MOM_TOP_SCOPED}
                    WHERE viewer_email=@email
                    ORDER BY sales_diff_mom DESC
                    LIMIT 50
                """,
                params={"email": user_email},
                prefer_storage_api=prefer_storage_api,
                show_check=show_checks,
            )
        st.dataframe(top, use_container_width=True, height=520)

    st.divider()
    st.subheader("C) å½“æœˆ YoYï¼ˆå‰å¹´æ¯”è¼ƒï¼‰")
    t1, t2, t3 = st.tabs(["ä¸‹è½ï¼ˆYoY validï¼‰", "ä¼¸é•·ï¼ˆYoY validï¼‰", "æ¯”è¼ƒä¸èƒ½ï¼ˆYoY invalidï¼‰"])

    with t1:
        yoy_bottom = qdf(
            name="sales_customer_yoy_bottom_current_month",
            sql=f"SELECT * FROM {V_YOY_BOTTOM} WHERE login_email=@email LIMIT 200",
            params={"email": user_email},
            prefer_storage_api=prefer_storage_api,
            show_check=show_checks,
        )
        st.dataframe(yoy_bottom, use_container_width=True, height=520)

    with t2:
        yoy_top = qdf(
            name="sales_customer_yoy_top_current_month",
            sql=f"SELECT * FROM {V_YOY_TOP} WHERE login_email=@email LIMIT 200",
            params={"email": user_email},
            prefer_storage_api=prefer_storage_api,
            show_check=show_checks,
        )
        st.dataframe(yoy_top, use_container_width=True, height=520)

    with t3:
        yoy_inv = qdf(
            name="sales_customer_yoy_uncomparable_current_month",
            sql=f"SELECT * FROM {V_YOY_INVALID} WHERE login_email=@email LIMIT 200",
            params={"email": user_email},
            prefer_storage_api=prefer_storage_api,
            show_check=show_checks,
        )
        st.dataframe(yoy_inv, use_container_width=True, height=520)

with tab_drill:
    st.subheader("å¾—æ„å…ˆ â†’ å½“æœˆ æ—¥æ¬¡æ˜ç´°ï¼ˆJANç²’åº¦ï¼‰")

    with st.form("drill_form", clear_on_submit=False):
        kw = st.text_input("å¾—æ„å…ˆåï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", value="")
        limit_candidates = st.slider("å€™è£œä»¶æ•°", 10, 200, 50)
        run = st.form_submit_button("æ¤œç´¢ â†’ å€™è£œè¡¨ç¤º")

    if run and kw.strip():
        cand = qdf(
            name="drill_candidates",
            sql=f"""
                SELECT DISTINCT customer_code, customer_name
                FROM {V_FACT}
                WHERE login_email=@email
                  AND month=DATE(@m)
                  AND customer_name LIKE CONCAT('%', @kw, '%')
                LIMIT {int(limit_candidates)}
            """,
            params={"email": user_email, "m": current_month, "kw": kw.strip()},
            prefer_storage_api=prefer_storage_api,
            show_check=show_checks,
        )

        if cand.empty:
            st.info("å€™è£œãªã—")
        else:
            labels = cand.apply(lambda r: f"{r['customer_name']} ({r['customer_code']})", axis=1).tolist()
            pick = st.selectbox("å¾—æ„å…ˆé¸æŠ", labels)
            code = parse_code_from_label(pick)

            with st.form("detail_form", clear_on_submit=False):
                limit_rows = st.slider("è¡¨ç¤ºè¡Œæ•°", 100, 5000, 800)
                run_detail = st.form_submit_button("å½“æœˆã®æ˜ç´°ã‚’è¡¨ç¤º")

            if run_detail:
                detail = qdf(
                    name="drill_detail_daily",
                    sql=f"""
                        SELECT
                          sales_date AS æ—¥ä»˜,
                          item_name  AS å•†å“å,
                          pack_unit  AS åŒ…è£…,
                          jan        AS JAN,
                          yj_code    AS YJ,
                          quantity   AS æ•°é‡,
                          sales_amount AS å£²ä¸Š,
                          gross_profit AS ç²—åˆ©
                        FROM {V_FACT}
                        WHERE login_email=@email
                          AND customer_code=@code
                          AND month=DATE(@m)
                        ORDER BY sales_date DESC
                        LIMIT {int(limit_rows)}
                    """,
                    params={"email": user_email, "code": code, "m": current_month},
                    prefer_storage_api=prefer_storage_api,
                    show_check=show_checks,
                )
                st.dataframe(detail, use_container_width=True, height=640)

with tab_perf:
    st.subheader("ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§å®Ÿè¡Œã•ã‚ŒãŸã‚¯ã‚¨ãƒªè¨ˆæ¸¬ãƒ­ã‚°")

    logs = st.session_state.perf_logs
    if not logs:
        st.info("ã¾ã è¨ˆæ¸¬ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        df_log = pd.DataFrame([{
            "name": x.name,
            "ok": x.ok,
            "query_sec": round(x.query_sec, 2),
            "df_sec": round(x.df_sec, 2),
            "total_sec": round(x.total_sec, 2),
            "bytes_gb": round(x.bytes_gb, 3),
            "rows": x.rows,
            "job_id": x.job_id,
            "note": x.note,
        } for x in logs]).sort_values(["total_sec", "bytes_gb"], ascending=[False, False])

        st.dataframe(df_log, use_container_width=True, height=520)
        st.markdown("### è¦‹åˆ†ã‘æ–¹")
        st.write(
            "- query_sec ãŒé•·ã„ â†’ BigQueryå´ãŒé‡ã„ï¼ˆVIEWã®JOIN/é›†è¨ˆ/ã‚¹ã‚­ãƒ£ãƒ³ï¼‰\n"
            "- df_sec ãŒé•·ã„ â†’ è»¢é€ãŒé‡ã„ï¼ˆStorage APIæœªå°å…¥ or çµæœãŒå¤§ãã™ãã‚‹ï¼‰\n"
            "- bytes_gb ãŒå¤§ãã„ â†’ SELECT * / çµã‚Šè¾¼ã¿ä¸è¶³ / ä¸è¦JOIN ã®å¯èƒ½æ€§"
        )
