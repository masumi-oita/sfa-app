# app.py
# -*- coding: utf-8 -*-
"""
SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - OS v1.9.9 (RBAC + Staff Master BQ Fallback / No Drive Creds)

ã€ã“ã®ç‰ˆã®ç‹™ã„ï¼ˆ403 Drive credentials ã‚’ç¢ºå®Ÿã«æ½°ã™ï¼‰ã€‘
- Roleå‚ç…§ã¯ã€ŒBASE TABLEã€ã‚’æœ€å„ªå…ˆï¼ˆsales_staff_master_bqï¼‰ã«å›ºå®š
- äº’æ›ã®ãŸã‚ã€BQå´ã§ VIEW `sales_staff_master` ã‚’ BASE TABLEå‚ç…§ã«ã—ã¦ã‚‚OK
- ã©ã†ã—ã¦ã‚‚ EXTERNAL(Sheets) ã‚’è¸ã¾ãªã„ã‚ˆã†ã«è¨­è¨ˆï¼ˆDrive credentials ã‚’å–ã‚Šã«è¡Œã‹ãªã„ï¼‰
- v1.9.8 ã®æ©Ÿèƒ½ï¼ˆFYTD/YoY/å¤šæ¬¡å…ƒå¢—æ¸›è¦å› /å¾—æ„å…ˆãƒ‰ãƒªãƒ«/ææ¡ˆï¼‰ã‚’è¸è¥²

å‰æï¼š
- `salesdb-479915.sales_data.sales_staff_master_bq` ãŒ BASE TABLE ã¨ã—ã¦å­˜åœ¨ï¼ˆGASåŒæœŸå¾Œï¼‰
- `v_sales_fact_unified` / `v_admin_org_fytd_summary_scoped` / `v_staff_fytd_summary_scoped`
  / `v_sales_customer_yoy_*` / `v_sales_fact_login_jan_daily` / `v_sales_recommendation_engine` ãŒå­˜åœ¨
"""

from __future__ import annotations

import json
from dataclasses import dataclass
from typing import Any, Dict, Optional, Tuple

import pandas as pd
import streamlit as st
from pandas.api.types import is_numeric_dtype

from google.cloud import bigquery
from google.oauth2 import service_account
from google.api_core.exceptions import BadRequest, GoogleAPICallError


# -----------------------------
# 1. Configuration
# -----------------------------
APP_TITLE = "SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"
DEFAULT_LOCATION = "asia-northeast1"
CACHE_TTL_SEC = 300

APP_URL = "https://sfa-premium-app-2.streamlit.app/"
PROJECT_DEFAULT = "salesdb-479915"
DATASET_DEFAULT = "sales_data"

# â˜…åˆ†æã®åœŸå°ã¨ãªã‚‹çµ±åˆView
VIEW_UNIFIED = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_unified"

# KPIã‚«ãƒ¼ãƒ‰ç”¨ãªã©ã®æ—¢å­˜View
VIEW_FYTD_ORG = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_admin_org_fytd_summary_scoped"
VIEW_FYTD_ME = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_staff_fytd_summary_scoped"
VIEW_YOY_TOP = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_top_current_month_named"
VIEW_YOY_BOTTOM = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_bottom_current_month_named"
VIEW_YOY_UNCOMP = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_uncomparable_current_month_named"

# æˆ¦ç•¥ææ¡ˆï¼ˆv1.6.0ã€œï¼‰
VIEW_RECOMMEND = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_recommendation_engine"
VIEW_FACT_DAILY = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_login_jan_daily"
VIEW_ITEM_MASTER = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.vw_item_master_norm"

# â˜…é‡è¦ï¼šRole/Staff Master ã¯ BASE TABLE ã‚’å‚ç…§ï¼ˆ403ã‚’ç¢ºå®Ÿã«å›é¿ï¼‰
#   - ã“ã“ã¯ã€Œå¿…ãš BASE TABLEã€ã‚’æŒ‡ã™
TABLE_STAFF_MASTER_BQ = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.sales_staff_master_bq"
#   - äº’æ›ã®ãŸã‚ã« VIEW ã‚’ä½¿ã†å ´åˆã¯ã€BQå´ã§ã“ã®VIEWãŒ BASE TABLEå‚ç…§ã§ã‚ã‚‹ã“ã¨ï¼ˆEXTERNALä¸å¯ï¼‰
VIEW_STAFF_MASTER = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.sales_staff_master"

# é™¤å¤–ã‚³ãƒ¼ãƒ‰å®šç¾©
NOISE_JAN_SQL = "('0', '22221', '99998', '33334')"


# -----------------------------
# 2. Helpers (Display)
# -----------------------------
def set_page():
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)
    st.caption("OS v1.9.9ï½œRBAC + Staff Master(BQ)ï½œBigQueryé›†è¨ˆãƒ»å‹•çš„SQLç‰ˆï¼ˆ403å›é¿ï¼‰")


def get_qr_code_url(url: str) -> str:
    return f"https://api.qrserver.com/v1/create-qr-code/?size=150x150&data={url}"


def rename_columns_for_display(df: pd.DataFrame, mapping: Dict[str, str]) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    cols = {c: mapping.get(c, c) for c in df.columns}
    return df.rename(columns=cols)


def create_default_column_config(df: pd.DataFrame) -> Dict[str, st.column_config.Column]:
    config: Dict[str, st.column_config.Column] = {}
    for col in df.columns:
        if any(k in col for k in ["å£²ä¸Š", "ç²—åˆ©", "é‡‘é¡", "å·®", "å®Ÿç¸¾", "äºˆæ¸¬", "GAP"]):
            config[col] = st.column_config.NumberColumn(col, format="Â¥%d")
        elif any(k in col for k in ["ç‡", "æ¯”", "ãƒšãƒ¼ã‚¹"]):
            config[col] = st.column_config.NumberColumn(col, format="%.1f%%")
        elif is_numeric_dtype(df[col]):
            config[col] = st.column_config.NumberColumn(col, format="%d")
        else:
            config[col] = st.column_config.TextColumn(col)
    return config


def get_safe_float(row: pd.Series, key: str) -> float:
    val = row.get(key)
    if pd.isna(val):
        return 0.0
    try:
        return float(val)
    except Exception:
        return 0.0


JP_COLS_FYTD = {
    "login_email": "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«",
    "display_name": "æ‹…å½“è€…å",
    "sales_amount_fytd": "å£²ä¸Šï¼ˆFYTDï¼‰",
    "gross_profit_fytd": "ç²—åˆ©ï¼ˆFYTDï¼‰",
    "sales_amount_py_total": "å‰å¹´å£²ä¸Šå®Ÿç¸¾ï¼ˆå¹´ï¼‰",
    "sales_forecast_total": "å£²ä¸Šç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰",
    "gross_profit_py_total": "å‰å¹´ç²—åˆ©å®Ÿç¸¾ï¼ˆå¹´ï¼‰",
    "gp_forecast_total": "ç²—åˆ©ç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰",
}

JP_COLS_YOY = {
    "customer_code": "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰",
    "customer_name": "å¾—æ„å…ˆå",
    "sales_amount": "å£²ä¸Šï¼ˆå½“æœˆï¼‰",
    "gross_profit": "ç²—åˆ©ï¼ˆå½“æœˆï¼‰",
    "sales_amount_py": "å£²ä¸Šï¼ˆå‰å¹´åŒæœˆï¼‰",
    "sales_diff_yoy": "å‰å¹´å·®ï¼ˆå£²ä¸Šï¼‰",
}


# -----------------------------
# 3. BigQuery Connection / Query
# -----------------------------
def setup_bigquery_client() -> Tuple[bigquery.Client, str, str, str]:
    if "bigquery" not in st.secrets:
        st.error("âŒ Secretsè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()

    bq = st.secrets["bigquery"]
    project_id = str(bq.get("project_id") or PROJECT_DEFAULT)
    location = str(bq.get("location") or DEFAULT_LOCATION)
    sa = dict(bq.get("service_account"))

    # â˜…Drive credentials ç³»ã®ã‚¨ãƒ©ãƒ¼å›é¿ï¼š
    # - EXTERNALï¼ˆSheetsï¼‰ã‚’è¸ã¾ãªã‘ã‚Œã° drive ã‚¹ã‚³ãƒ¼ãƒ—è‡ªä½“ã¯ä¸è¦
    # - ãŸã ã—ã€ä»Šå¾Œ EXTERNAL ã‚’ä½¿ã†å¯èƒ½æ€§ãŒã‚ã‚‹ãªã‚‰ scopes ã‚’ä»˜ä¸ã—ã¦ã‚‚è‰¯ã„
    scopes = [
        "https://www.googleapis.com/auth/cloud-platform",
        # å¿…è¦ãªå ´åˆã®ã¿æœ‰åŠ¹åŒ–ï¼ˆEXTERNALå‚ç…§ã‚’ä½¿ã†æ™‚ï¼‰
        # "https://www.googleapis.com/auth/drive.readonly",
        # "https://www.googleapis.com/auth/spreadsheets.readonly",
    ]

    creds = service_account.Credentials.from_service_account_info(sa, scopes=scopes)
    client = bigquery.Client(project=project_id, credentials=creds, location=location)
    return client, project_id, location, json.dumps(sa, ensure_ascii=False)


def _build_qparams(params: Optional[Dict[str, Any]]) -> list:
    qparams = []
    if not params:
        return qparams
    for k, v in params.items():
        if isinstance(v, bool):
            qparams.append(bigquery.ScalarQueryParameter(k, "BOOL", v))
        elif isinstance(v, int):
            qparams.append(bigquery.ScalarQueryParameter(k, "INT64", v))
        elif isinstance(v, float):
            qparams.append(bigquery.ScalarQueryParameter(k, "FLOAT64", v))
        else:
            qparams.append(bigquery.ScalarQueryParameter(k, "STRING", str(v)))
    return qparams


def query_df_safe(
    client: bigquery.Client,
    sql: str,
    params: Optional[Dict[str, Any]] = None,
    label: str = "",
    use_bqstorage: bool = True,
    timeout_sec: int = 60,
) -> pd.DataFrame:
    try:
        job_config = bigquery.QueryJobConfig()
        qparams = _build_qparams(params)
        if qparams:
            job_config.query_parameters = qparams
        job = client.query(sql, job_config=job_config)
        job.result(timeout=timeout_sec)
        return job.to_dataframe(create_bqstorage_client=use_bqstorage)
    except (BadRequest, GoogleAPICallError, Exception) as e:
        st.error(f"Query Failed: {label}\n{e}")
        with st.expander("è©³ç´°ï¼ˆSQL / paramsï¼‰", expanded=False):
            st.code(sql.strip(), language="sql")
            st.json(params or {})
        return pd.DataFrame()


# -----------------------------
# 4. Role / RBAC (Master Integrated)
# -----------------------------
@dataclass(frozen=True)
class RoleInfo:
    login_email: str
    staff_name: str = "ã‚²ã‚¹ãƒˆ"
    role_key: str = "SALES"  # HQ_ADMIN / AREA_MANAGER / SALES
    role_admin_view: bool = False
    phone: str = "-"
    area_name: str = "æœªè¨­å®š"


def _normalize_role(raw_role: str) -> Tuple[str, bool, str]:
    """
    raw_role ä¾‹:
      - "HQ_ADMIN"
      - "AREA_MANAGERï¼ˆç†Šæœ¬ï¼‰"
      - "SALESï¼ˆå¤§åˆ†ï¼‰"
      - "ADMIN"
    """
    rr = (raw_role or "").strip().upper()
    is_admin = any(x in rr for x in ["ADMIN", "MANAGER", "HQ", "çµ±æ‹¬"])
    role_key = "HQ_ADMIN" if is_admin else "SALES"

    # ã‚¨ãƒªã‚¢æŠ½å‡ºï¼ˆæ‹¬å¼§ãŒã‚ã‚Œã°ä¸­èº«ã€ãªã‘ã‚Œã° roleæ–‡å­—åˆ—ãã®ã‚‚ã®ã‚’ area ã®ãƒ’ãƒ³ãƒˆã«ï¼‰
    area = "æœªè¨­å®š"
    if "ï¼ˆ" in rr and "ï¼‰" in rr:
        try:
            area = rr.split("ï¼ˆ", 1)[1].split("ï¼‰", 1)[0].strip() or "æœªè¨­å®š"
        except Exception:
            area = "æœªè¨­å®š"
    else:
        # ä¾‹: "KUMAMOTO" ãªã©ãŒæ··ã˜ã‚‹å ´åˆã«å‚™ãˆã€ãã®ã¾ã¾æ®‹ã™
        area = rr if rr else "æœªè¨­å®š"

    return role_key, is_admin, area


def resolve_role(client: bigquery.Client, login_email: str, use_bqstorage: bool, timeout_sec: int) -> RoleInfo:
    """
    â˜…æœ€å„ªå…ˆã§ BASE TABLE(sales_staff_master_bq) ã‚’å‚ç…§
    äº’æ›VIEW(sales_staff_master)ã¯ã€BQå´ã§ BASE TABLEå‚ç…§ã«ãªã£ã¦ã„ã‚‹å ´åˆã®ã¿ä½¿ã†ã“ã¨ã€‚
    """
    login_email = (login_email or "").strip().lower()
    if not login_email:
        return RoleInfo(login_email="")

    sql_bq = f"""
SELECT
  email,
  staff_name,
  role,
  phone
FROM `{TABLE_STAFF_MASTER_BQ}`
WHERE LOWER(email) = @login_email
LIMIT 1
"""
    df = query_df_safe(
        client,
        sql_bq,
        params={"login_email": login_email},
        label="Role Check (BASE TABLE)",
        use_bqstorage=use_bqstorage,
        timeout_sec=timeout_sec,
    )

    # äº’æ›ï¼ˆä»»æ„ï¼‰ï¼šBASE TABLEãŒæœªæ•´å‚™ã®æ™‚ã ã‘ VIEW ã‚’è©¦ã™
    if df.empty:
        sql_view = f"""
SELECT
  email,
  staff_name,
  role,
  phone
FROM `{VIEW_STAFF_MASTER}`
WHERE LOWER(email) = @login_email
LIMIT 1
"""
        df = query_df_safe(
            client,
            sql_view,
            params={"login_email": login_email},
            label="Role Check (VIEW fallback)",
            use_bqstorage=use_bqstorage,
            timeout_sec=timeout_sec,
        )

    if df.empty:
        return RoleInfo(login_email=login_email)

    r = df.iloc[0]
    raw_role = str(r.get("role", "")).strip()
    role_key, is_admin, area = _normalize_role(raw_role)

    return RoleInfo(
        login_email=login_email,
        staff_name=str(r.get("staff_name", "ä¸æ˜")),
        role_key=role_key,
        role_admin_view=bool(is_admin),
        phone=str(r.get("phone", "-")),
        area_name=area,
    )


# -----------------------------
# 5. Query Runner (scoped views)
# -----------------------------
def run_scoped_query(
    client: bigquery.Client,
    sql_template: str,
    scope_col: str,
    login_email: str,
    allow_fallback: bool,
    use_bqstorage: bool,
    timeout_sec: int,
) -> pd.DataFrame:
    # __WHERE__ ã‚’å·®ã—æ›¿ãˆï¼ˆscoped viewã®åˆ—ã«åˆã‚ã›ã‚‹ï¼‰
    sql = sql_template.replace("__WHERE__", f"WHERE {scope_col} = @login_email")
    df = query_df_safe(
        client,
        sql,
        params={"login_email": login_email},
        label="Scoped Query",
        use_bqstorage=use_bqstorage,
        timeout_sec=timeout_sec,
    )
    if not df.empty:
        return df

    if allow_fallback:
        sql_all = sql_template.replace(
            "__WHERE__", f'WHERE {scope_col} = "all" OR {scope_col} IS NULL'
        )
        return query_df_safe(
            client,
            sql_all,
            params=None,
            label="Fallback(all) Query",
            use_bqstorage=use_bqstorage,
            timeout_sec=timeout_sec,
        )

    return pd.DataFrame()


# -----------------------------
# 6. BigQuery Calculation Logicï¼ˆå¤šæ¬¡å…ƒå¢—æ¸›ï¼‰
# -----------------------------
def fetch_ranking_from_bq(
    client: bigquery.Client,
    ranking_type: str,
    axis_mode: str,
    is_sales_mode: bool,
    use_bqstorage: bool,
    timeout_sec: int,
) -> pd.DataFrame:
    is_worst = (ranking_type == "worst")
    is_product = (axis_mode == "product")
    group_col = "product_name" if is_product else "customer_name"
    target_val = "sales_amount" if is_sales_mode else "gross_profit"
    order_dir = "ASC" if is_worst else "DESC"

    sql = f"""
WITH base_stats AS (
  SELECT MAX(fiscal_year) AS current_fy FROM `{VIEW_UNIFIED}`
)
SELECT
  {group_col} AS name,
  SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN sales_amount ELSE 0 END) AS sales_cur,
  SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN gross_profit ELSE 0 END) AS gp_cur,
  SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) - 1 THEN sales_amount ELSE 0 END) AS sales_prev,
  SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN {target_val} ELSE 0 END)
  - SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) - 1 THEN {target_val} ELSE 0 END) AS diff_val,
  SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN sales_amount ELSE 0 END)
  - SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) - 1 THEN sales_amount ELSE 0 END) AS sales_diff,
  SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) THEN gross_profit ELSE 0 END)
  - SUM(CASE WHEN fiscal_year = (SELECT current_fy FROM base_stats) - 1 THEN gross_profit ELSE 0 END) AS gp_diff
FROM `{VIEW_UNIFIED}`
WHERE
  jan_code NOT IN {NOISE_JAN_SQL}
  AND jan_code NOT LIKE '999%'
  AND LENGTH(jan_code) > 5
GROUP BY {group_col}
HAVING (sales_cur > 0 OR sales_prev > 0)
ORDER BY diff_val {order_dir}
LIMIT 1000
"""
    return query_df_safe(
        client,
        sql,
        params=None,
        label="Ranking Query",
        use_bqstorage=use_bqstorage,
        timeout_sec=timeout_sec,
    )


def fetch_drilldown_from_bq(
    client: bigquery.Client,
    key_col: str,
    key_val: str,
    target_col: str,
    is_worst: bool,
    is_sales_mode: bool,
    use_bqstorage: bool,
    timeout_sec: int,
) -> pd.DataFrame:
    order_dir = "ASC" if is_worst else "DESC"
    sort_col_alias = "å£²ä¸Šå·®é¡" if is_sales_mode else "ç²—åˆ©å·®é¡"
    target_label = "å¾—æ„å…ˆå" if target_col == "customer_name" else "å•†å“å"

    sql = f"""
SELECT
  {target_col} AS `{target_label}`,
  SUM(CASE WHEN fiscal_year = 2025 THEN sales_amount ELSE 0 END) AS `ä»Šå¹´å£²ä¸Š`,
  SUM(CASE WHEN fiscal_year = 2024 THEN sales_amount ELSE 0 END) AS `å‰å¹´å£²ä¸Š`,
  SUM(CASE WHEN fiscal_year = 2025 THEN sales_amount ELSE 0 END)
  - SUM(CASE WHEN fiscal_year = 2024 THEN sales_amount ELSE 0 END) AS `å£²ä¸Šå·®é¡`,
  SUM(CASE WHEN fiscal_year = 2025 THEN gross_profit ELSE 0 END) AS `ä»Šå¹´ç²—åˆ©`,
  SUM(CASE WHEN fiscal_year = 2025 THEN gross_profit ELSE 0 END)
  - SUM(CASE WHEN fiscal_year = 2024 THEN gross_profit ELSE 0 END) AS `ç²—åˆ©å·®é¡`
FROM `{VIEW_UNIFIED}`
WHERE {key_col} = @key_val
GROUP BY 1
ORDER BY `{sort_col_alias}` {order_dir}
LIMIT 500
"""
    return query_df_safe(
        client,
        sql,
        params={"key_val": key_val},
        label="Drilldown Query",
        use_bqstorage=use_bqstorage,
        timeout_sec=timeout_sec,
    )


# -----------------------------
# 7. UI Components
# -----------------------------
def sidebar_controls() -> Dict[str, Any]:
    st.sidebar.image(get_qr_code_url(APP_URL), caption="ğŸ“±ã‚¹ãƒãƒ›ã§ã‚¢ã‚¯ã‚»ã‚¹", width=150)
    st.sidebar.divider()
    use_bqstorage = st.sidebar.toggle("BigQuery Storage APIï¼ˆé«˜é€Ÿï¼‰", value=True)
    timeout_sec = st.sidebar.slider("ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰", min_value=10, max_value=300, value=60, step=10)
    show_sql = st.sidebar.toggle("SQLè¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰", value=False)
    if st.sidebar.button("Clear Cache"):
        st.cache_data.clear()
        st.sidebar.success("Cache Cleared.")
    return {"use_bqstorage": use_bqstorage, "timeout_sec": timeout_sec, "show_sql": show_sql}


def get_login_email_ui() -> str:
    st.sidebar.header("Login Simulation")
    default = st.secrets.get("default_login_email", "") if "default_login_email" in st.secrets else ""
    login_email = st.sidebar.text_input("Login Email", value=default).strip()
    if not login_email:
        st.info("ğŸ‘ˆ å·¦ã® Login Email ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        st.stop()
    return login_email


def render_interactive_ranking_matrix(
    client: bigquery.Client,
    ranking_type: str,
    axis_mode: str,
    is_sales_mode: bool,
    opts: Dict[str, Any],
):
    is_worst = (ranking_type == "worst")
    is_product = (axis_mode == "product")
    label_col = "å•†å“å" if is_product else "å¾—æ„å…ˆå"
    mode_label = "å£²ä¸Š" if is_sales_mode else "ç²—åˆ©"

    df_rank = fetch_ranking_from_bq(
        client,
        ranking_type,
        axis_mode,
        is_sales_mode,
        use_bqstorage=opts["use_bqstorage"],
        timeout_sec=opts["timeout_sec"],
    )
    if df_rank.empty:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df_disp = df_rank.rename(
        columns={
            "name": label_col,
            "sales_cur": "ä»Šå¹´å£²ä¸Š",
            "sales_prev": "å‰å¹´å£²ä¸Š",
            "sales_diff": "å£²ä¸Šå·®é¡",
            "gp_cur": "ä»Šå¹´ç²—åˆ©",
            "gp_diff": "ç²—åˆ©å·®é¡",
        }
    )

    if is_sales_mode:
        cols = [label_col, "å£²ä¸Šå·®é¡", "ä»Šå¹´å£²ä¸Š", "å‰å¹´å£²ä¸Š", "ç²—åˆ©å·®é¡", "ä»Šå¹´ç²—åˆ©"]
    else:
        cols = [label_col, "ç²—åˆ©å·®é¡", "ä»Šå¹´ç²—åˆ©", "å£²ä¸Šå·®é¡", "ä»Šå¹´å£²ä¸Š", "å‰å¹´å£²ä¸Š"]

    st.markdown(f"##### â‘  {label_col}ã‚’é¸æŠï¼ˆ{mode_label}ãƒ™ãƒ¼ã‚¹ï¼‰")
    st.caption(f"â€»{mode_label}ã®å¢—æ¸›é¡ãŒå¤§ãã„é †ï¼ˆè¨ˆç®—: BigQueryï¼‰")

    key_suffix = f"{ranking_type}_{axis_mode}_{mode_label}"
    event = st.dataframe(
        df_disp[cols],
        use_container_width=True,
        hide_index=True,
        column_config=create_default_column_config(df_disp[cols]),
        height=420,
        on_select="rerun",
        selection_mode="single-row",
        key=f"rank_{key_suffix}",
    )

    if len(event.selection["rows"]) == 0:
        return

    idx = event.selection["rows"][0]
    selected_val = df_disp.iloc[idx][label_col]

    st.divider()
    st.subheader(f"ğŸ” å†…è¨³åˆ†æ: {selected_val}")

    key_col = "product_name" if is_product else "customer_name"
    target_col = "customer_name" if is_product else "product_name"

    df_drill = fetch_drilldown_from_bq(
        client,
        key_col=key_col,
        key_val=str(selected_val),
        target_col=target_col,
        is_worst=is_worst,
        is_sales_mode=is_sales_mode,
        use_bqstorage=opts["use_bqstorage"],
        timeout_sec=opts["timeout_sec"],
    )
    if df_drill.empty:
        st.warning("è©³ç´°ãƒ‡ãƒ¼ã‚¿ãªã—")
        return

    drill_label = "å¾—æ„å…ˆå" if is_product else "å•†å“å"
    if is_sales_mode:
        d_cols = [drill_label, "å£²ä¸Šå·®é¡", "ä»Šå¹´å£²ä¸Š", "å‰å¹´å£²ä¸Š", "ç²—åˆ©å·®é¡", "ä»Šå¹´ç²—åˆ©"]
    else:
        d_cols = [drill_label, "ç²—åˆ©å·®é¡", "ä»Šå¹´ç²—åˆ©", "å£²ä¸Šå·®é¡", "ä»Šå¹´å£²ä¸Š", "å‰å¹´å£²ä¸Š"]

    st.dataframe(
        df_drill[d_cols],
        use_container_width=True,
        hide_index=True,
        column_config=create_default_column_config(df_drill[d_cols]),
        height=500,
        key=f"drill_{key_suffix}",
    )


def render_fytd_org_section(client: bigquery.Client, login_email: str, role: RoleInfo, opts: Dict[str, Any]):
    st.subheader("ğŸ¢ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå…¨ç¤¾")
    if st.button("å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_org_load", use_container_width=True):
        st.session_state.org_data_loaded = True

    if not st.session_state.org_data_loaded:
        st.info("ğŸ‘† ä¸Šã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")
        return

    sql_kpi = f"SELECT * FROM `{VIEW_FYTD_ORG}` __WHERE__ LIMIT 100"
    df_org = run_scoped_query(
        client,
        sql_kpi,
        scope_col="viewer_email",
        login_email=login_email,
        allow_fallback=True,  # admin_viewãªã‚‰all fallbackè¨±å®¹
        use_bqstorage=opts["use_bqstorage"],
        timeout_sec=opts["timeout_sec"],
    )

    if not df_org.empty:
        row = df_org.iloc[0]
        s_cur = get_safe_float(row, "sales_amount_fytd")
        s_py = get_safe_float(row, "sales_amount_py_total")
        s_fc = get_safe_float(row, "sales_forecast_total")

        gp_cur = get_safe_float(row, "gross_profit_fytd")
        gp_py = get_safe_float(row, "gross_profit_py_total")
        gp_fc = get_safe_float(row, "gp_forecast_total")

        st.markdown("##### â–  å£²ä¸Š (Sales)")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("â‘  ç¾çŠ¶", f"Â¥{s_cur:,.0f}")
        c2.metric("â‘¡ æ˜¨å¹´", f"Â¥{s_py:,.0f}")
        c3.metric("â‘¢ äºˆæ¸¬", f"Â¥{s_fc:,.0f}")
        c4.metric("â‘£ GAP", f"Â¥{(s_fc - s_py):,.0f}", delta_color="off")

        st.markdown("##### â–  ç²—åˆ© (Gross Profit)")
        c5, c6, c7, c8 = st.columns(4)
        c5.metric("â‘  ç¾çŠ¶", f"Â¥{gp_cur:,.0f}")
        c6.metric("â‘¡ æ˜¨å¹´", f"Â¥{gp_py:,.0f}")
        c7.metric("â‘¢ äºˆæ¸¬", f"Â¥{gp_fc:,.0f}")
        c8.metric("â‘£ GAP", f"Â¥{(gp_fc - gp_py):,.0f}", delta_color="off")
        st.divider()

    st.subheader("ğŸ“Š å¢—æ¸›è¦å› åˆ†æï¼ˆå¤šæ¬¡å…ƒï¼‰")

    c_axis, c_val = st.columns(2)
    with c_axis:
        axis_sel = st.radio("é›†è¨ˆè»¸:", ["ğŸ“¦ å•†å“è»¸", "ğŸ¥ å¾—æ„å…ˆè»¸"], horizontal=True)
        axis_mode = "product" if "å•†å“" in axis_sel else "customer"
    with c_val:
        val_sel = st.radio("è©•ä¾¡æŒ‡æ¨™:", ["ğŸ’° å£²ä¸Šé‡‘é¡", "ğŸ’¹ ç²—åˆ©é‡‘é¡"], horizontal=True)
        is_sales_mode = "å£²ä¸Š" in val_sel

    tab_worst, tab_best = st.tabs(["ğŸ“‰ ãƒ¯ãƒ¼ã‚¹ãƒˆï¼ˆæ¸›ï¼‰", "ğŸ“ˆ ãƒ™ã‚¹ãƒˆï¼ˆå¢—ï¼‰"])
    with tab_worst:
        render_interactive_ranking_matrix(client, "worst", axis_mode, is_sales_mode, opts)
    with tab_best:
        render_interactive_ranking_matrix(client, "best", axis_mode, is_sales_mode, opts)


def render_fytd_me_section(client: bigquery.Client, login_email: str, opts: Dict[str, Any]):
    st.subheader("ğŸ‘¤ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œè‡ªåˆ†")
    if st.button("è‡ªåˆ†ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_me", use_container_width=True):
        sql = f"SELECT * FROM `{VIEW_FYTD_ME}` __WHERE__ LIMIT 100"
        df_me = run_scoped_query(
            client,
            sql,
            scope_col="login_email",
            login_email=login_email,
            allow_fallback=False,
            use_bqstorage=opts["use_bqstorage"],
            timeout_sec=opts["timeout_sec"],
        )
        if df_me.empty:
            st.warning("è‡ªåˆ†FYTDãŒ0ä»¶ã§ã™ã€‚")
            return

        df_disp = rename_columns_for_display(df_me, JP_COLS_FYTD)
        cols = list(df_disp.columns)
        if "æ‹…å½“è€…å" in cols:
            cols.remove("æ‹…å½“è€…å")
            cols.insert(0, "æ‹…å½“è€…å")

        st.dataframe(
            df_disp[cols],
            use_container_width=True,
            hide_index=True,
            column_config=create_default_column_config(df_disp[cols]),
            height=260,
        )


def render_yoy_section(client: bigquery.Client, login_email: str, allow_fallback: bool, opts: Dict[str, Any]):
    st.subheader("ğŸ“Š å½“æœˆYoYï¼ˆå¾—æ„å…ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰")
    c1, c2, c3 = st.columns(3)

    def _show_table(title: str, view_name: str, key: str):
        if st.button(title, key=key, use_container_width=True):
            sql = f"SELECT * FROM `{view_name}` __WHERE__ LIMIT 200"
            df = run_scoped_query(
                client,
                sql,
                scope_col="login_email",
                login_email=login_email,
                allow_fallback=allow_fallback,
                use_bqstorage=opts["use_bqstorage"],
                timeout_sec=opts["timeout_sec"],
            )
            if df.empty:
                st.info("0ä»¶ã§ã™ã€‚")
                return
            df_disp = rename_columns_for_display(df, JP_COLS_YOY)
            st.dataframe(df_disp, use_container_width=True, hide_index=True, height=420)

    with c1:
        _show_table("YoY Topï¼ˆä¼¸ã³ï¼‰", VIEW_YOY_TOP, "btn_top")
    with c2:
        _show_table("YoY Bottomï¼ˆè½ã¡ï¼‰", VIEW_YOY_BOTTOM, "btn_btm")
    with c3:
        _show_table("æ–°è¦/æ¯”è¼ƒä¸èƒ½", VIEW_YOY_UNCOMP, "btn_unc")


def render_customer_drilldown(client: bigquery.Client, login_email: str, opts: Dict[str, Any]):
    st.subheader("ğŸ¯ å¾—æ„å…ˆåˆ¥ãƒ»æˆ¦ç•¥ææ¡ˆï¼ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« & æœªæ¡ç”¨ã‚®ãƒ£ãƒƒãƒ—ï¼‰")

    sql_cust = f"""
SELECT DISTINCT customer_code, customer_name
FROM `{VIEW_FACT_DAILY}`
WHERE login_email = @login_email
ORDER BY customer_code
"""
    df_cust = query_df_safe(
        client,
        sql_cust,
        params={"login_email": login_email},
        label="Cust List",
        use_bqstorage=opts["use_bqstorage"],
        timeout_sec=opts["timeout_sec"],
    )
    if df_cust.empty:
        st.info("å¾—æ„å…ˆãŒå–å¾—ã§ãã¾ã›ã‚“ï¼ˆå£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒãªã„å¯èƒ½æ€§ï¼‰")
        return

    cust_options = {
        row["customer_code"]: f"{row['customer_code']} : {row['customer_name']}"
        for _, row in df_cust.iterrows()
    }
    selected_code = st.selectbox(
        "åˆ†æã™ã‚‹å¾—æ„å…ˆã‚’é¸æŠã—ã¦ãã ã•ã„",
        options=list(cust_options.keys()),
        format_func=lambda x: cust_options[x],
    )
    if not selected_code:
        return

    st.divider()

    # æ¨å¥¨ï¼ˆv_sales_recommendation_engine å´ã®åˆ—ã¯ç’°å¢ƒã§ç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ã¾ãšã¯ * ã§å–å¾—ï¼‰
    sql_rec = f"""
SELECT *
FROM `{VIEW_RECOMMEND}`
WHERE customer_code = @cust_code
ORDER BY priority_rank ASC
"""
    df_rec = query_df_safe(
        client,
        sql_rec,
        params={"cust_code": selected_code},
        label="Recommendation",
        use_bqstorage=opts["use_bqstorage"],
        timeout_sec=opts["timeout_sec"],
    )

    c1, c2 = st.columns([1, 2])

    with c1:
        st.markdown("#### ğŸ¥ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«")
        strong = "-"
        if not df_rec.empty:
            # strong_category / targeted_category ãªã©æºã‚Œå¸å
            for k in ["strong_category", "targeted_category", "main_category", "category_name"]:
                if k in df_rec.columns:
                    strong = str(df_rec.iloc[0].get(k, "-") or "-")
                    break
        st.info(f"ä¸»åŠ›é ˜åŸŸ: **{strong}**")

    with c2:
        st.markdown("#### ğŸ’¡ AIææ¡ˆãƒªã‚¹ãƒˆï¼ˆæœªæ¡ç”¨å“ï¼‰")
        if df_rec.empty:
            st.info("ææ¡ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆVIEWå®šç¾©/åˆ—åã‚’ç¢ºèªï¼‰")
        else:
            # ä»£è¡¨åˆ—ã®æºã‚Œå¸å
            cols = []
            if "priority_rank" in df_rec.columns:
                cols.append("priority_rank")
            if "recommend_product" in df_rec.columns:
                cols.append("recommend_product")
            elif "product_name" in df_rec.columns:
                cols.append("product_name")
            if "manufacturer" in df_rec.columns:
                cols.append("manufacturer")
            elif "maker_name" in df_rec.columns:
                cols.append("maker_name")
            if "market_scale" in df_rec.columns:
                cols.append("market_scale")
            if "recommend_jan" in df_rec.columns:
                cols.append("recommend_jan")

            disp = df_rec[cols].copy() if cols else df_rec.copy()
            rename_map = {
                "priority_rank": "é †ä½",
                "recommend_product": "å•†å“",
                "product_name": "å•†å“",
                "manufacturer": "ãƒ¡ãƒ¼ã‚«ãƒ¼",
                "maker_name": "ãƒ¡ãƒ¼ã‚«ãƒ¼",
                "market_scale": "è¦æ¨¡",
                "recommend_jan": "JAN",
            }
            disp = disp.rename(columns=rename_map)
            st.dataframe(disp, use_container_width=True, hide_index=True, height=420)

    with st.expander("å‚è€ƒï¼šç¾åœ¨ã®æ¡ç”¨å“ãƒªã‚¹ãƒˆï¼ˆFYTDï¼‰ã‚’è¦‹ã‚‹"):
        sql_adopted = f"""
SELECT
  m.product_name,
  SUM(t.sales_amount) AS sales_fytd,
  SUM(t.gross_profit) AS gp_fytd
FROM `{VIEW_FACT_DAILY}` t
LEFT JOIN `{VIEW_ITEM_MASTER}` m
  ON CAST(t.jan AS STRING) = CAST(m.jan_code AS STRING)
WHERE
  t.customer_code = @cust_code
  AND t.fiscal_year = 2025
GROUP BY 1
ORDER BY 2 DESC
LIMIT 100
"""
        df_adopted = query_df_safe(
            client,
            sql_adopted,
            params={"cust_code": selected_code},
            label="Adopted List",
            use_bqstorage=opts["use_bqstorage"],
            timeout_sec=opts["timeout_sec"],
        )
        if df_adopted.empty:
            st.info("æ¡ç”¨å“ãŒå–å¾—ã§ãã¾ã›ã‚“ã€‚")
        else:
            renamed = df_adopted.rename(
                columns={"product_name": "å•†å“å", "sales_fytd": "å£²ä¸Š(FYTD)", "gp_fytd": "ç²—åˆ©(FYTD)"}
            )
            st.dataframe(
                renamed,
                use_container_width=True,
                hide_index=True,
                column_config=create_default_column_config(renamed),
                height=420,
            )


# -----------------------------
# 8. Main
# -----------------------------
def main():
    if "org_data_loaded" not in st.session_state:
        st.session_state.org_data_loaded = False

    set_page()
    client, project_id, location, sa_json = setup_bigquery_client()
    opts = sidebar_controls()

    login_email = get_login_email_ui()
    st.divider()

    # â˜…Roleè§£æ±ºï¼ˆBASE TABLEå„ªå…ˆï¼‰
    role = resolve_role(
        client,
        login_email=login_email,
        use_bqstorage=opts["use_bqstorage"],
        timeout_sec=opts["timeout_sec"],
    )

    # ãƒ­ã‚°ã‚¤ãƒ³è¡¨ç¤º
    st.write(f"ğŸ‘¤ **æ‹…å½“:** {role.staff_name}")
    st.write(f"ğŸ“§ **Email:** {role.login_email}")
    st.write(f"ğŸ›¡ï¸ **Role:** {role.role_key}")
    st.write(f"ğŸ—ºï¸ **Area:** {role.area_name}")
    # é›»è©±ã¯æœ«å°¾4æ¡ã ã‘è¦‹ã›ã‚‹ï¼ˆå†…éƒ¨ä»•æ§˜ï¼‰
    phone_tail = (role.phone or "").replace("-", "").strip()[-4:] if role.phone and role.phone != "-" else ""
    st.write(f"ğŸ“ **Phone:** ***-****-{phone_tail}" if phone_tail else "ğŸ“ **Phone:** -")
    st.divider()

    allow_fallback = role.role_admin_view  # adminã®ã¿ all fallback ã‚’è¨±å¯

    if role.role_admin_view:
        t1, t2, t3 = st.tabs(["ğŸ¢ çµ„ç¹”çŠ¶æ³ï¼ˆçµŒå–¶ï¼‰", "ğŸ‘¤ å€‹äººæˆç¸¾ï¼ˆè¡Œå‹•ï¼‰", "ğŸ¯ æˆ¦ç•¥ææ¡ˆï¼ˆç¾å ´ï¼‰"])
        with t1:
            render_fytd_org_section(client, login_email, role, opts)
        with t2:
            render_fytd_me_section(client, login_email, opts)
            st.divider()
            render_yoy_section(client, login_email, allow_fallback=True, opts=opts)
        with t3:
            render_customer_drilldown(client, login_email, opts)
    else:
        t1, t2, t3 = st.tabs(["ğŸ‘¤ ä»Šå¹´ã®æˆç¸¾ï¼ˆFYTDï¼‰", "ğŸ“Š å¾—æ„å…ˆåˆ¥ï¼ˆYoYï¼‰", "ğŸ¯ ææ¡ˆã‚’ä½œã‚‹"])
        with t1:
            render_fytd_me_section(client, login_email, opts)
        with t2:
            render_yoy_section(client, login_email, allow_fallback=False, opts=opts)
        with t3:
            render_customer_drilldown(client, login_email, opts)

    st.caption("â€» 403(Drive credentials) ãŒå‡ºã‚‹å ´åˆï¼šRoleå‚ç…§ãŒ EXTERNAL ã‚’è¸ã‚“ã§ã„ã¾ã™ã€‚å¿…ãš sales_staff_master_bq(BASE TABLE) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚")


if __name__ == "__main__":
    main()
