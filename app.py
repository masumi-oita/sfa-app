# app.py
# -*- coding: utf-8 -*-
"""
SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - OS v1.8.1 (Layout Fixed)

ã€æ›´æ–°å±¥æ­´ v1.8.1ã€‘
- [UI] ãƒ¯ãƒ¼ã‚¹ãƒˆåˆ†æç”»é¢ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå´©ã‚Œï¼ˆæ–‡å­—é‡è¤‡ï¼‰ã‚’é˜²ããŸã‚ã€UIé…ç½®ã‚’æ•´ç†
- [Config] QRã‚³ãƒ¼ãƒ‰URLã‚’å›ºå®šè¨­å®š
- [Data] BigQueryå´ã§ã€Œå•†å“åä¸æ˜ã€ãƒ‡ãƒ¼ã‚¿ãŒæŒ‡æ•°è¡¨è¨˜ã«ãªã‚‹å•é¡Œã‚’SQLå´ã§å¯¾å‡¦æ¸ˆã¿ï¼ˆé€£æºç¢ºèªï¼‰
"""

from __future__ import annotations

import json
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st
from pandas.api.types import is_numeric_dtype

from google.cloud import bigquery
from google.oauth2 import service_account
from google.api_core.exceptions import BadRequest, GoogleAPICallError


# -----------------------------
# 1. Configuration & Constants
# -----------------------------
APP_TITLE = "SFAï½œæˆ¦ç•¥ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"
DEFAULT_LOCATION = "asia-northeast1"
CACHE_TTL_SEC = 300

# â˜…QRã‚³ãƒ¼ãƒ‰ã®é£›ã³å…ˆ
APP_URL = "https://sfa-premium-app-2.streamlit.app/"

PROJECT_DEFAULT = "salesdb-479915"
DATASET_DEFAULT = "sales_data"

# BigQuery Views (FQN)
VIEW_ROLE = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_dim_staff_role_dedup"
VIEW_FYTD_ORG = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_admin_org_fytd_summary_scoped"
VIEW_WORST_RANK = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_admin_product_yoy_worst_ranking"
VIEW_BEST_RANK = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_admin_product_yoy_best_ranking"
VIEW_FYTD_ME = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_staff_fytd_summary_scoped"
VIEW_YOY_TOP = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_top_current_month_named"
VIEW_YOY_BOTTOM = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_bottom_current_month_named"
VIEW_YOY_UNCOMP = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_uncomparable_current_month_named"
VIEW_RECOMMEND = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_recommendation_engine"
VIEW_FACT_DAILY = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_login_jan_daily"


# -----------------------------
# 2. Display Mappings
# -----------------------------
JP_COLS_FYTD = {
    "viewer_email": "é–²è¦§è€…ãƒ¡ãƒ¼ãƒ«",
    "login_email": "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«",
    "display_name": "æ‹…å½“è€…å",
    "role_tier": "ãƒ­ãƒ¼ãƒ«",
    "area_name": "ã‚¨ãƒªã‚¢",
    "current_month": "åŸºæº–æ—¥",
    "fy_start": "å¹´åº¦é–‹å§‹",
    "sales_amount_fytd": "å£²ä¸Šï¼ˆFYTDï¼‰",
    "gross_profit_fytd": "ç²—åˆ©ï¼ˆFYTDï¼‰",
    "gross_profit_rate_fytd": "ç²—åˆ©ç‡ï¼ˆFYTDï¼‰",
    "sales_amount_py_fytd": "å£²ä¸Šï¼ˆå‰å¹´FYTDï¼‰",
    "gross_profit_py_fytd": "ç²—åˆ©ï¼ˆå‰å¹´FYTDï¼‰",
    "sales_diff_fytd": "å‰å¹´å·®ï¼ˆå£²ä¸Šï¼‰",
    "gp_diff_fytd": "å‰å¹´å·®ï¼ˆç²—åˆ©ï¼‰",
    "sales_forecast_total": "å£²ä¸Šç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰",
    "pacing_rate": "å£²ä¸Šå¯¾å‰å¹´ãƒšãƒ¼ã‚¹",
    "sales_amount_py_total": "å‰å¹´å£²ä¸Šå®Ÿç¸¾ï¼ˆå¹´ï¼‰",
    "gp_forecast_total": "ç²—åˆ©ç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰",
    "gp_pacing_rate": "ç²—åˆ©å¯¾å‰å¹´ãƒšãƒ¼ã‚¹",
    "gross_profit_py_total": "å‰å¹´ç²—åˆ©å®Ÿç¸¾ï¼ˆå¹´ï¼‰",
}

JP_COLS_YOY = {
    "login_email": "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«",
    "display_name": "æ‹…å½“è€…å",
    "month": "å¯¾è±¡æœˆï¼ˆæœˆåˆï¼‰",
    "customer_code": "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰",
    "customer_name": "å¾—æ„å…ˆå",
    "sales_amount": "å£²ä¸Šï¼ˆå½“æœˆï¼‰",
    "gross_profit": "ç²—åˆ©ï¼ˆå½“æœˆï¼‰",
    "gross_profit_rate": "ç²—åˆ©ç‡ï¼ˆå½“æœˆï¼‰",
    "sales_amount_py": "å£²ä¸Šï¼ˆå‰å¹´åŒæœˆï¼‰",
    "gross_profit_py": "ç²—åˆ©ï¼ˆå‰å¹´åŒæœˆï¼‰",
    "gross_profit_rate_py": "ç²—åˆ©ç‡ï¼ˆå‰å¹´åŒæœˆï¼‰",
    "sales_diff_yoy": "å‰å¹´å·®ï¼ˆå£²ä¸Šï¼‰",
    "gp_diff_yoy": "å‰å¹´å·®ï¼ˆç²—åˆ©ï¼‰",
    "sales_yoy_rate": "å‰å¹´åŒæœˆæ¯”ï¼ˆå£²ä¸Šï¼‰",
    "gp_yoy_rate": "å‰å¹´åŒæœˆæ¯”ï¼ˆç²—åˆ©ï¼‰",
}


# -----------------------------
# 3. Helper Functions
# -----------------------------
def set_page():
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)
    st.caption("OS v1.8.1ï½œæˆ¦ç•¥ææ¡ˆï½œãƒ¯ãƒ¼ã‚¹ãƒˆãƒ»ãƒˆãƒƒãƒ—åˆ†æï½œç€åœ°äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

def get_qr_code_url(url: str) -> str:
    return f"https://api.qrserver.com/v1/create-qr-code/?size=150x150&data={url}"

def rename_columns_for_display(df: pd.DataFrame, mapping: Dict[str, str]) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    cols = {c: mapping.get(c, c) for c in df.columns}
    return df.rename(columns=cols)

def append_total_row(df: pd.DataFrame, label_col: str = None) -> pd.DataFrame:
    if df.empty: return df
    num_cols = df.select_dtypes(include=['number']).columns
    total_data = {}
    for col in df.columns:
        if col in num_cols:
            if any(k in col for k in ["ç‡", "æ¯”", "ãƒšãƒ¼ã‚¹", "rate", "pace"]):
                total_data[col] = None
            else:
                total_data[col] = df[col].sum()
        else:
            total_data[col] = ""
    target_label = label_col if label_col and label_col in df.columns else df.columns[0]
    total_data[target_label] = "=== åˆè¨ˆ ==="
    return pd.concat([df, pd.DataFrame([total_data])], ignore_index=True)

def create_default_column_config(df: pd.DataFrame) -> Dict[str, st.column_config.Column]:
    config = {}
    for col in df.columns:
        if any(k in col for k in ["å£²ä¸Š", "ç²—åˆ©", "é‡‘é¡", "å·®", "å®Ÿç¸¾", "äºˆæ¸¬", "GAP", "amount", "profit", "diff", "cur", "prev"]):
            config[col] = st.column_config.NumberColumn(col, format="Â¥%d")
        elif any(k in col for k in ["ç‡", "æ¯”", "ãƒšãƒ¼ã‚¹", "rate", "pace"]):
            config[col] = st.column_config.NumberColumn(col, format="%.1f%%")
        elif is_numeric_dtype(df[col]):
            config[col] = st.column_config.NumberColumn(col, format="%d")
        else:
            config[col] = st.column_config.TextColumn(col)
    return config


# -----------------------------
# 4. Role & Auth
# -----------------------------
@dataclass(frozen=True)
class RoleInfo:
    login_email: str
    role_key: str = "SALES"
    role_admin_view: bool = False
    role_admin_edit: bool = False
    role_sales_view: bool = True
    area_name: str = "æœªè¨­å®š"

def normalize_role_key(role_key: str) -> str:
    rk = (role_key or "").strip().upper()
    if rk in ("HQ_ADMIN", "AREA_MANAGER", "SALES"):
        return rk
    return "SALES"

def _secrets_has_bigquery() -> bool:
    if "bigquery" not in st.secrets: return False
    bq = st.secrets.get("bigquery", {})
    return bool(bq.get("project_id")) and bool(bq.get("service_account"))

def _get_bq_from_secrets() -> Tuple[str, str, Dict[str, Any]]:
    bq = st.secrets["bigquery"]
    return str(bq.get("project_id")), str(bq.get("location") or DEFAULT_LOCATION), dict(bq.get("service_account"))

def setup_bigquery_client() -> Tuple[bigquery.Client, str, str, str]:
    if not _secrets_has_bigquery():
        st.error("âŒ Secretsè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()
    project_id, location, sa = _get_bq_from_secrets()
    sa_json = json.dumps(sa)
    creds = service_account.Credentials.from_service_account_info(sa)
    client = bigquery.Client(project=project_id, credentials=creds, location=location)
    return client, project_id, location, sa_json


# -----------------------------
# 5. Query Execution
# -----------------------------
def _build_query_parameters(params: Optional[Dict[str, Any]]) -> List[bigquery.ScalarQueryParameter]:
    qparams = []
    if not params: return qparams
    for k, v in params.items():
        if isinstance(v, bool): qparams.append(bigquery.ScalarQueryParameter(k, "BOOL", v))
        elif isinstance(v, int): qparams.append(bigquery.ScalarQueryParameter(k, "INT64", v))
        elif isinstance(v, float): qparams.append(bigquery.ScalarQueryParameter(k, "FLOAT64", v))
        elif v is None: qparams.append(bigquery.ScalarQueryParameter(k, "STRING", ""))
        else: qparams.append(bigquery.ScalarQueryParameter(k, "STRING", str(v)))
    return qparams

@st.cache_data(show_spinner=False, ttl=CACHE_TTL_SEC)
def cached_query_df(project_id: str, location: str, sa_json: str, sql: str, params_json: str, use_bqstorage: bool, timeout_sec: int) -> pd.DataFrame:
    sa = json.loads(sa_json)
    creds = service_account.Credentials.from_service_account_info(sa)
    client = bigquery.Client(project=project_id, credentials=creds, location=location)
    params = json.loads(params_json) if params_json else {}
    job_config = bigquery.QueryJobConfig()
    qparams = _build_query_parameters(params)
    if qparams: job_config.query_parameters = qparams
    job = client.query(sql, job_config=job_config)
    job.result(timeout=timeout_sec)
    return job.to_dataframe(create_bqstorage_client=use_bqstorage)

def query_df_safe(client: bigquery.Client, sql: str, params: Optional[Dict[str, Any]] = None, label: str = "", use_bqstorage: bool = True, timeout_sec: int = 60, cache_key: Optional[Tuple[str, str, str]] = None) -> pd.DataFrame:
    params_json = json.dumps(params or {}, ensure_ascii=False, sort_keys=True)
    try:
        if cache_key:
            project_id, location, sa_json = cache_key
            return cached_query_df(project_id, location, sa_json, sql, params_json, use_bqstorage, timeout_sec)
        else:
            job_config = bigquery.QueryJobConfig()
            qparams = _build_query_parameters(params or {})
            if qparams: job_config.query_parameters = qparams
            job = client.query(sql, job_config=job_config)
            job.result(timeout=timeout_sec)
            return job.to_dataframe(create_bqstorage_client=use_bqstorage)
    except Exception as e:
        st.error(f"Query Failed: {label}\n{e}")
        return pd.DataFrame()

def resolve_role(client, cache_key, login_email, opts) -> RoleInfo:
    sql = f"SELECT login_email, role_tier, role_admin_view, area_name FROM `{VIEW_ROLE}` WHERE login_email = @login_email LIMIT 1"
    df = query_df_safe(client, sql, {"login_email": login_email}, "Role Check", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    if df.empty: return RoleInfo(login_email=login_email)
    r = df.iloc[0]
    return RoleInfo(login_email=login_email, role_key=normalize_role_key(str(r.get("role_tier"))), role_admin_view=bool(r.get("role_admin_view")), area_name=str(r.get("area_name", "æœªè¨­å®š")))

def run_scoped_query(client, cache_key, sql_template, scope_col, login_email, opts, allow_fallback=False):
    sql = sql_template.replace("__WHERE__", f"WHERE {scope_col} = @login_email")
    if opts["show_sql"]: st.code(sql, language="sql")
    df = query_df_safe(client, sql, {"login_email": login_email}, "Scoped Query", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    if not df.empty: return df
    if allow_fallback:
        sql_all = sql_template.replace("__WHERE__", f'WHERE {scope_col} = "all" OR {scope_col} IS NULL')
        if opts["show_sql"]: st.code(sql_all, language="sql")
        return query_df_safe(client, sql_all, None, "Fallback Query", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    return pd.DataFrame()


# -----------------------------
# 6. Sidebar
# -----------------------------
def sidebar_controls() -> Dict[str, Any]:
    qr_url = get_qr_code_url(APP_URL)
    st.sidebar.image(qr_url, caption="ğŸ“±ã‚¹ãƒãƒ›ã§ã‚¢ã‚¯ã‚»ã‚¹", width=150)
    st.sidebar.divider()
    st.sidebar.header("System Settings")
    use_bqstorage = st.sidebar.toggle("Use Storage API (Fast)", value=True)
    timeout_sec = st.sidebar.slider("Query Timeout (sec)", 10, 300, 60, 10)
    show_sql = st.sidebar.toggle("Show SQL (Debug)", value=False)
    if st.sidebar.button("Clear Cache"):
        st.cache_data.clear()
        st.sidebar.success("Cache Cleared.")
    return {"use_bqstorage": use_bqstorage, "timeout_sec": timeout_sec, "show_sql": show_sql}

def get_login_email_ui() -> str:
    st.sidebar.header("Login Simulation")
    default_email = st.secrets.get("default_login_email", "") if "default_login_email" in st.secrets else ""
    login_email = st.sidebar.text_input("Login Email", value=default_email).strip()
    if not login_email: st.stop()
    return login_email


# -----------------------------
# 7. Render Functions
# -----------------------------

def render_fytd_org_section(client, cache_key, login_email, opts):
    st.subheader("ğŸ¢ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå…¨ç¤¾")
    
    if st.button("å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_org_load", use_container_width=True):
        st.session_state.org_data_loaded = True
    
    if st.session_state.org_data_loaded:
        sql_kpi = f"SELECT * FROM `{VIEW_FYTD_ORG}` __WHERE__ LIMIT 100"
        df_org = run_scoped_query(client, cache_key, sql_kpi, "viewer_email", login_email, opts, allow_fallback=True)
        
        if not df_org.empty:
            row = df_org.iloc[0]
            s_cur, s_py = float(row.get('sales_amount_fytd', 0)), float(row.get('sales_amount_py_total', 0))
            s_fc = float(row.get('sales_forecast_total', 0))
            gp_cur, gp_py = float(row.get('gross_profit_fytd', 0)), float(row.get('gross_profit_py_total', 0))
            gp_fc = float(row.get('gp_forecast_total', 0))

            st.markdown("##### â–  å£²ä¸Š (Sales)")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("â‘  ç¾çŠ¶ (FYTD)", f"Â¥{s_cur:,.0f}")
            c2.metric("â‘¡ æ˜¨å¹´åº¦å®Ÿç¸¾", f"Â¥{s_py:,.0f}")
            c3.metric("â‘¢ ç€åœ°äºˆæ¸¬", f"Â¥{s_fc:,.0f}", delta_color="normal")
            c4.metric("â‘£ GAP", f"Â¥{s_fc - s_py:,.0f}", delta=None, delta_color="off")

            st.markdown("##### â–  ç²—åˆ© (Gross Profit)")
            c5, c6, c7, c8 = st.columns(4)
            c5.metric("â‘  ç¾çŠ¶ (FYTD)", f"Â¥{gp_cur:,.0f}")
            c6.metric("â‘¡ æ˜¨å¹´åº¦å®Ÿç¸¾", f"Â¥{gp_py:,.0f}")
            c7.metric("â‘¢ ç€åœ°äºˆæ¸¬", f"Â¥{gp_fc:,.0f}", delta_color="normal")
            c8.metric("â‘£ GAP", f"Â¥{gp_fc - gp_py:,.0f}", delta=None, delta_color="off")
            
            # â˜…ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´: ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç©ºã‘ã‚‹
            st.divider()
            st.write("") 

        # --- Interactive Ranking ---
        st.subheader("ğŸ“Š å¢—æ¸›è¦å› åˆ†æ (ãƒ©ãƒ³ã‚­ãƒ³ã‚°)")
        
        # 1. è»¸ã®é¸æŠ
        c_mode, c_axis, c_val = st.columns(3)
        with c_mode:
            rank_type = st.radio("é †ä½ (Type):", ["ğŸ“‰ ãƒ¯ãƒ¼ã‚¹ãƒˆ (Worst)", "ğŸ“ˆ ãƒˆãƒƒãƒ— (Best)"])
            is_worst = "ãƒ¯ãƒ¼ã‚¹ãƒˆ" in rank_type
        with c_axis:
            axis_mode = st.radio("é›†è¨ˆè»¸ (Axis):", ["ğŸ“¦ å•†å“è»¸", "ğŸ¥ å¾—æ„å…ˆè»¸"])
            is_product_mode = "å•†å“" in axis_mode
        with c_val:
            value_mode = st.radio("è©•ä¾¡æŒ‡æ¨™ (Value):", ["ğŸ’° å£²ä¸Šé‡‘é¡", "ğŸ’¹ ç²—åˆ©é‡‘é¡"])
            is_sales_mode = "å£²ä¸Š" in value_mode

        # 2. Viewã®åˆ‡ã‚Šæ›¿ãˆ
        target_view = VIEW_WORST_RANK if is_worst else VIEW_BEST_RANK
        
        # 3. ãƒ‡ãƒ¼ã‚¿å–å¾—
        sql_rank = f"SELECT * FROM `{target_view}` LIMIT 3000"
        df_raw = query_df_safe(client, sql_rank, None, "Ranking Raw", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
        
        if df_raw.empty:
            st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        # 4. ã‚«ãƒ©ãƒ è¨­å®š
        if is_sales_mode:
            col_target, col_cur, col_prev = "sales_diff", "sales_cur", "sales_prev"
            label_diff, label_cur, label_prev = "å£²ä¸Šå¢—æ¸›é¡", "ä»Šå¹´å£²ä¸Š", "å‰å¹´å£²ä¸Š"
        else:
            col_target, col_cur, col_prev = "gp_diff", "gp_cur", "gp_prev"
            label_diff, label_cur, label_prev = "ç²—åˆ©å¢—æ¸›é¡", "ä»Šå¹´ç²—åˆ©", "å‰å¹´ç²—åˆ©"

        # 5. ç”»é¢æç”»
        if st.session_state.worst_view_mode == 'ranking':
            target_key = "product_name" if is_product_mode else "customer_name"
            target_label = "å•†å“å" if is_product_mode else "å¾—æ„å…ˆå"
            
            # â˜…ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´: ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç©ºã‘ã‚‹
            st.write("")
            st.markdown(f"**{rank_type} ãƒ©ãƒ³ã‚­ãƒ³ã‚° ({label_diff}é †)**")
            st.caption("ğŸ‘‡ è¡Œã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨è©³ç´°åˆ†æã¸ç§»å‹•ã—ã¾ã™")
            
            df_group = df_raw.groupby(target_key)[[col_target, col_cur, col_prev]].sum().reset_index()
            # ã‚½ãƒ¼ãƒˆ
            df_group = df_group.sort_values(col_target, ascending=not is_worst)
            
            # åˆè¨ˆè¡Œ
            df_display = append_total_row(df_group, label_col=target_key)
            
            # Click Event
            selection = st.dataframe(
                df_display[[target_key, col_target, col_cur, col_prev]], 
                column_config={
                    target_key: st.column_config.TextColumn(target_label, width="medium"),
                    col_target: st.column_config.NumberColumn(label_diff, format="Â¥%d"),
                    col_cur: st.column_config.NumberColumn(label_cur, format="Â¥%d"),
                    col_prev: st.column_config.NumberColumn(label_prev, format="Â¥%d")
                },
                use_container_width=True, 
                hide_index=True, 
                height=400,
                on_select="rerun",
                selection_mode="single-row"
            )
            
            if len(selection.selection.rows) > 0:
                selected_idx = selection.selection.rows[0]
                selected_name = df_display.iloc[selected_idx][target_key]
                if selected_name != "=== åˆè¨ˆ ===":
                    st.session_state.worst_selected_name = selected_name
                    st.session_state.worst_view_mode = 'detail'
                    st.rerun()

        elif st.session_state.worst_view_mode == 'detail':
            target_name = st.session_state.worst_selected_name
            if st.button("â¬… ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«æˆ»ã‚‹"):
                st.session_state.worst_view_mode = 'ranking'
                st.session_state.worst_selected_name = None
                st.rerun()

            st.title(f"ğŸ” è©³ç´°åˆ†æ: {target_name}")
            st.caption(f"æŒ‡æ¨™: {label_diff}")
            
            if is_product_mode:
                df_detail = df_raw[df_raw["product_name"] == target_name].copy()
                main_col, col_label = "customer_name", "å¾—æ„å…ˆå"
            else:
                df_detail = df_raw[df_raw["customer_name"] == target_name].copy()
                main_col, col_label = "product_name", "å•†å“å"
            
            df_detail = df_detail.sort_values(col_target, ascending=not is_worst)
            df_display = append_total_row(df_detail, label_col=main_col)

            st.dataframe(
                df_display[[main_col, col_target, col_cur, col_prev]],
                column_config={
                    main_col: st.column_config.TextColumn(col_label),
                    col_target: st.column_config.NumberColumn(label_diff, format="Â¥%d"),
                    col_cur: st.column_config.NumberColumn(label_cur, format="Â¥%d"),
                    col_prev: st.column_config.NumberColumn(label_prev, format="Â¥%d")
                },
                use_container_width=True, hide_index=True
            )
    else:
        st.info("ğŸ‘† ä¸Šã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")

def render_fytd_me_section(client, cache_key, login_email, opts):
    st.subheader("ğŸ‘¤ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œè‡ªåˆ†")
    if st.button("è‡ªåˆ†ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_me", use_container_width=True):
        sql = f"SELECT * FROM `{VIEW_FYTD_ME}` __WHERE__ LIMIT 100"
        df_me = run_scoped_query(client, cache_key, sql, "login_email", login_email, opts)
        if df_me.empty:
            st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        row = df_me.iloc[0]
        s_cur = float(row.get('sales_amount_fytd', 0))
        s_fc = float(row.get('sales_forecast_total', 0))
        s_py = float(row.get('sales_amount_py_total', 0))
        gp_cur = float(row.get('gross_profit_fytd', 0))
        gp_fc = float(row.get('gp_forecast_total', 0))
        gp_py = float(row.get('gross_profit_py_total', 0))

        st.markdown("##### â–  å£²ä¸Š (Sales)")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("â‘  ç¾çŠ¶", f"Â¥{s_cur:,.0f}")
        c2.metric("â‘¡ æ˜¨å¹´", f"Â¥{s_py:,.0f}")
        c3.metric("â‘¢ äºˆæ¸¬", f"Â¥{s_fc:,.0f}")
        c4.metric("â‘£ GAP", f"Â¥{s_fc - s_py:,.0f}", delta_color="off")

        st.markdown("##### â–  ç²—åˆ© (Gross Profit)")
        c5, c6, c7, c8 = st.columns(4)
        c5.metric("â‘  ç¾çŠ¶", f"Â¥{gp_cur:,.0f}")
        c6.metric("â‘¡ æ˜¨å¹´", f"Â¥{gp_py:,.0f}")
        c7.metric("â‘¢ äºˆæ¸¬", f"Â¥{gp_fc:,.0f}")
        c8.metric("â‘£ GAP", f"Â¥{gp_fc - gp_py:,.0f}", delta_color="off")
        st.divider()
        
        df_disp = rename_columns_for_display(df_me, JP_COLS_FYTD)
        cols = list(df_disp.columns)
        if "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«" in cols: cols.remove("ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«")
        if "é–²è¦§è€…ãƒ¡ãƒ¼ãƒ«" in cols: cols.remove("é–²è¦§è€…ãƒ¡ãƒ¼ãƒ«")
        if "æ‹…å½“è€…å" in cols:
            cols.remove("æ‹…å½“è€…å")
            cols.insert(0, "æ‹…å½“è€…å")
        
        col_cfg = create_default_column_config(df_disp[cols])
        st.dataframe(df_disp[cols], use_container_width=True, hide_index=True, column_config=col_cfg)

def render_yoy_section(client, cache_key, login_email, allow_fallback, opts):
    st.subheader("ğŸ“Š å½“æœˆYoYï¼ˆå¾—æ„å…ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰")
    c1, c2, c3 = st.columns(3)
    
    def _show_table(title, view_name, key):
        if st.button(title, key=key, use_container_width=True):
            sql = f"SELECT * FROM `{view_name}` __WHERE__ LIMIT 200"
            df = run_scoped_query(client, cache_key, sql, "login_email", login_email, opts, allow_fallback)
            if not df.empty:
                df_disp = rename_columns_for_display(df, JP_COLS_YOY)
                cols = list(df_disp.columns)
                if "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«" in cols: cols.remove("ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«")
                if "æ‹…å½“è€…å" in cols:
                    cols.remove("æ‹…å½“è€…å")
                    cols.insert(0, "æ‹…å½“è€…å")
                
                df_final = append_total_row(df_disp[cols], label_col="æ‹…å½“è€…å")
                col_cfg = create_default_column_config(df_final)
                st.dataframe(df_final, use_container_width=True, hide_index=True, column_config=col_cfg)
            else:
                st.info("0ä»¶ã§ã™ã€‚")

    with c1: _show_table("YoY Top (ä¼¸ã³)", VIEW_YOY_TOP, "btn_top")
    with c2: _show_table("YoY Bottom (è½ã¡)", VIEW_YOY_BOTTOM, "btn_btm")
    with c3: _show_table("æ–°è¦/æ¯”è¼ƒä¸èƒ½", VIEW_YOY_UNCOMP, "btn_unc")

def render_customer_drilldown(client, cache_key, login_email, opts):
    st.subheader("ğŸ¯ å¾—æ„å…ˆåˆ¥ãƒ»æˆ¦ç•¥ææ¡ˆï¼ˆAI Gap Analysisï¼‰")
    
    sql_cust = f"SELECT DISTINCT customer_code, customer_name FROM `{VIEW_FACT_DAILY}` WHERE login_email = @login_email ORDER BY customer_code"
    df_cust = query_df_safe(client, sql_cust, {"login_email": login_email}, "Cust List", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    
    if df_cust.empty:
        st.info("æ‹…å½“å¾—æ„å…ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆã¾ãŸã¯ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«ä¸ä¸€è‡´ï¼‰ã€‚")
        return

    cust_options = {row["customer_code"]: f"{row['customer_code']} : {row['customer_name']}" for _, row in df_cust.iterrows()}
    selected_code = st.selectbox("åˆ†æã™ã‚‹å¾—æ„å…ˆã‚’é¸æŠã—ã¦ãã ã•ã„", options=cust_options.keys(), format_func=lambda x: cust_options[x])
    if not selected_code: return

    st.divider()
    sql_rec = f"SELECT * FROM `{VIEW_RECOMMEND}` WHERE customer_code = @cust_code ORDER BY priority_rank ASC"
    df_rec = query_df_safe(client, sql_rec, {"cust_code": selected_code}, "Recommendation", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    
    c1, c2 = st.columns([1, 2])
    with c1:
        st.markdown("#### ğŸ¥ å¾—æ„å…ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«")
        if not df_rec.empty:
            strong_cat = df_rec.iloc[0].get("strong_category", "-")
            st.info(f"ã“ã®å¾—æ„å…ˆã®ä¸»åŠ›é ˜åŸŸ(ãƒ¡ãƒ¼ã‚«ãƒ¼): **{strong_cat}**")
            st.caption("â€»è³¼å…¥å®Ÿç¸¾ã‚·ã‚§ã‚¢No.1ã®ãƒ¡ãƒ¼ã‚«ãƒ¼")
        else:
            st.warning("ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆã¾ãŸã¯ä¸»è¦å“å®Œç´æ¸ˆã¿ï¼‰")
            strong_cat = "(ä¸æ˜)"

    with c2:
        st.markdown("#### ğŸ’¡ AIææ¡ˆãƒªã‚¹ãƒˆï¼ˆæœªæ¡ç”¨ã®ãƒãƒ£ãƒ³ã‚¹å•†å“ï¼‰")
        st.caption(f"å…¨ç¤¾ã® **{strong_cat}** å£²ä¸ŠTOP10ã®ã†ã¡ã€**æœªæ¡ç”¨**ã®å•†å“")
        
        if df_rec.empty:
            st.success("ğŸ‰ ã“ã®é ˜åŸŸã®ä¸»è¦å•†å“ã¯ã™ã¹ã¦æ¡ç”¨æ¸ˆã¿ã§ã™ã€‚")
        else:
            disp_df = df_rec[["priority_rank", "recommend_product", "manufacturer", "market_scale"]].rename(columns={"priority_rank": "å„ªå…ˆé †ä½", "recommend_product": "æ¨å¥¨å•†å“å", "manufacturer": "ãƒ¡ãƒ¼ã‚«ãƒ¼", "market_scale": "å…¨ç¤¾å£²ä¸Šè¦æ¨¡"})
            col_cfg = create_default_column_config(disp_df)
            st.dataframe(disp_df, use_container_width=True, hide_index=True, column_config=col_cfg)
            
    with st.expander("å‚è€ƒ: ç¾åœ¨ã®æ¡ç”¨å“ãƒªã‚¹ãƒˆã‚’è¦‹ã‚‹"):
        sql_adopted = f"""
        SELECT 
            m.product_name, 
            SUM(t.sales_amount) as sales_fytd,
            SUM(t.gross_profit) as gp_fytd
        FROM `{VIEW_FACT_DAILY}` t
        LEFT JOIN `{PROJECT_DEFAULT}.{DATASET_DEFAULT}.vw_item_master_norm` m 
            ON CAST(t.jan AS STRING) = CAST(m.jan_code AS STRING)
        WHERE t.customer_code = @cust_code AND t.fiscal_year = 2025
        GROUP BY 1 ORDER BY 2 DESC LIMIT 100
        """
        df_adopted = query_df_safe(client, sql_adopted, {"cust_code": selected_code}, "Adopted List", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
        
        renamed_df = df_adopted.rename(columns={"product_name": "å•†å“å", "sales_fytd": "å£²ä¸Š(FYTD)", "gp_fytd": "ç²—åˆ©(FYTD)"})
        col_cfg = create_default_column_config(renamed_df)
        st.dataframe(renamed_df, use_container_width=True, column_config=col_cfg)


# -----------------------------
# 8. Main
# -----------------------------
def main():
    if 'worst_view_mode' not in st.session_state: st.session_state.worst_view_mode = 'ranking'
    if 'worst_selected_name' not in st.session_state: st.session_state.worst_selected_name = None
    if 'org_data_loaded' not in st.session_state: st.session_state.org_data_loaded = False

    set_page()
    
    client, project_id, location, sa_json = setup_bigquery_client()
    cache_key = (project_id, location, sa_json)
    
    opts = sidebar_controls()
    login_email = get_login_email_ui()
    st.divider()

    role = resolve_role(client, cache_key, login_email, opts)
    st.write(f"**Login:** {role.login_email} / **Role:** {role.role_key} ({role.area_name})")
    is_admin = role.role_key in ("HQ_ADMIN", "AREA_MANAGER")
    st.divider()
    
    if is_admin:
        t1, t2, t3 = st.tabs(["ğŸ¢ å…¨ç¤¾çŠ¶æ³", "ğŸ‘¤ ã‚¨ãƒªã‚¢/å€‹äºº", "ğŸ¯ æˆ¦ç•¥ææ¡ˆ(Beta)"])
        with t1: render_fytd_org_section(client, cache_key, login_email, opts)
        with t2:
            render_fytd_me_section(client, cache_key, login_email, opts)
            st.divider()
            render_yoy_section(client, cache_key, login_email, is_admin, opts)
        with t3: render_customer_drilldown(client, cache_key, login_email, opts)
    else:
        t1, t2, t3 = st.tabs(["ğŸ‘¤ ä»Šå¹´ã®æˆç¸¾", "ğŸ“Š å¾—æ„å…ˆåˆ†æ", "ğŸ¯ ææ¡ˆã‚’ä½œã‚‹"])
        with t1: render_fytd_me_section(client, cache_key, login_email, opts)
        with t2: render_yoy_section(client, cache_key, login_email, is_admin, opts)
        with t3: render_customer_drilldown(client, cache_key, login_email, opts)

    st.caption("Updated: v1.8.1 (Layout Fixed)")

if __name__ == "__main__":
    main()
