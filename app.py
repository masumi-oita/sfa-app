# app.py
# -*- coding: utf-8 -*-
"""
SFAï½œå…¥å£é«˜é€Ÿç‰ˆï¼ˆåˆ¤æ–­å°‚ç”¨ï¼‰ - OS v1.6.3 (Enhanced UI/UX)

ã€ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆå®šç¾©ã€‘
- Backend: Google BigQuery (asia-northeast1)
- Frontend: Streamlit (Compatible with v1.31.0+)
- Logic:
    1. Role Separation: HQ_ADMIN (å…¨ç¤¾) vs SALES (å€‹äºº)
    2. Forecasting: Pacing Method (Sales & Gross Profit)
    3. Analysis: Worst Impact Ranking (Stateful Drill-down) â˜…Updated
    4. Recommendation: Gap Analysis (JAN Based)

ã€æ›´æ–°å±¥æ­´ v1.6.3ã€‘
- ãƒ¯ãƒ¼ã‚¹ãƒˆåˆ†æã®ãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³æ™‚ã«ç”»é¢ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹å•é¡Œã‚’ä¿®æ­£ï¼ˆSession Stateå°å…¥ï¼‰
- æ•°å€¤è¡¨ç¤ºã‚’3æ¡ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼ˆÂ¥1,234,567ï¼‰ã«å¤‰æ›´ã—è¦–èªæ€§ã‚’å‘ä¸Š
"""

from __future__ import annotations

import json
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st

from google.cloud import bigquery
from google.oauth2 import service_account
from google.api_core.exceptions import BadRequest, GoogleAPICallError


# -----------------------------
# Configuration & Constants
# -----------------------------
APP_TITLE = "SFAï½œå…¥å£é«˜é€Ÿç‰ˆï¼ˆåˆ¤æ–­å°‚ç”¨ï¼‰"
DEFAULT_LOCATION = "asia-northeast1"
CACHE_TTL_SEC = 300

PROJECT_DEFAULT = "salesdb-479915"
DATASET_DEFAULT = "sales_data"

# BigQuery Views (FQN)
VIEW_ROLE = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_dim_staff_role_dedup"
VIEW_FYTD_ORG = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_admin_org_fytd_summary_scoped"
VIEW_WORST_RANK = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_admin_product_yoy_worst_ranking"
VIEW_FYTD_ME = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_staff_fytd_summary_scoped"
VIEW_YOY_TOP = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_top_current_month_named"
VIEW_YOY_BOTTOM = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_bottom_current_month_named"
VIEW_YOY_UNCOMP = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_customer_yoy_uncomparable_current_month_named"
VIEW_RECOMMEND = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_recommendation_engine"
VIEW_FACT_DAILY = f"{PROJECT_DEFAULT}.{DATASET_DEFAULT}.v_sales_fact_login_jan_daily"


# -----------------------------
# Display Mappings (Japanese)
# -----------------------------
JP_COLS_FYTD = {
    "viewer_email": "é–²è¦§è€…ãƒ¡ãƒ¼ãƒ«",
    "login_email": "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«",
    "display_name": "æ‹…å½“è€…å",
    "role_tier": "ãƒ­ãƒ¼ãƒ«",
    "area_name": "ã‚¨ãƒªã‚¢",
    "current_month": "åŸºæº–æ—¥",
    "fy_start": "å¹´åº¦é–‹å§‹",
    "sales_amount_fytd": "å£²ä¸Šï¼ˆFYTDï¼‰",
    "gross_profit_fytd": "ç²—åˆ©ï¼ˆFYTDï¼‰",
    "gross_profit_rate_fytd": "ç²—åˆ©ç‡ï¼ˆFYTDï¼‰",
    "sales_amount_py_fytd": "å£²ä¸Šï¼ˆå‰å¹´FYTDï¼‰",
    "gross_profit_py_fytd": "ç²—åˆ©ï¼ˆå‰å¹´FYTDï¼‰",
    "sales_diff_fytd": "å‰å¹´å·®ï¼ˆå£²ä¸Šï¼‰",
    "gp_diff_fytd": "å‰å¹´å·®ï¼ˆç²—åˆ©ï¼‰",
    "sales_forecast_total": "å£²ä¸Šç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰",
    "pacing_rate": "å£²ä¸Šå¯¾å‰å¹´ãƒšãƒ¼ã‚¹",
    "sales_amount_py_total": "å‰å¹´å£²ä¸Šå®Ÿç¸¾ï¼ˆå¹´ï¼‰",
    "gp_forecast_total": "ç²—åˆ©ç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰",
    "gp_pacing_rate": "ç²—åˆ©å¯¾å‰å¹´ãƒšãƒ¼ã‚¹",
    "gross_profit_py_total": "å‰å¹´ç²—åˆ©å®Ÿç¸¾ï¼ˆå¹´ï¼‰",
}

JP_COLS_YOY = {
    "login_email": "ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«",
    "display_name": "æ‹…å½“è€…å",
    "month": "å¯¾è±¡æœˆï¼ˆæœˆåˆï¼‰",
    "customer_code": "å¾—æ„å…ˆã‚³ãƒ¼ãƒ‰",
    "customer_name": "å¾—æ„å…ˆå",
    "sales_amount": "å£²ä¸Šï¼ˆå½“æœˆï¼‰",
    "gross_profit": "ç²—åˆ©ï¼ˆå½“æœˆï¼‰",
    "gross_profit_rate": "ç²—åˆ©ç‡ï¼ˆå½“æœˆï¼‰",
    "sales_amount_py": "å£²ä¸Šï¼ˆå‰å¹´åŒæœˆï¼‰",
    "gross_profit_py": "ç²—åˆ©ï¼ˆå‰å¹´åŒæœˆï¼‰",
    "gross_profit_rate_py": "ç²—åˆ©ç‡ï¼ˆå‰å¹´åŒæœˆï¼‰",
    "sales_diff_yoy": "å‰å¹´å·®ï¼ˆå£²ä¸Šï¼‰",
    "gp_diff_yoy": "å‰å¹´å·®ï¼ˆç²—åˆ©ï¼‰",
    "sales_yoy_rate": "å‰å¹´åŒæœˆæ¯”ï¼ˆå£²ä¸Šï¼‰",
    "gp_yoy_rate": "å‰å¹´åŒæœˆæ¯”ï¼ˆç²—åˆ©ï¼‰",
}


# -----------------------------
# Utility Functions
# -----------------------------
def rename_columns_for_display(df: pd.DataFrame, mapping: Dict[str, str]) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    cols = {c: mapping.get(c, c) for c in df.columns}
    return df.rename(columns=cols)


# -----------------------------
# Role Management
# -----------------------------
@dataclass(frozen=True)
class RoleInfo:
    login_email: str
    role_key: str = "SALES"
    role_admin_view: bool = False
    role_admin_edit: bool = False
    role_sales_view: bool = True
    area_name: str = "æœªè¨­å®š"

def normalize_role_key(role_key: str) -> str:
    rk = (role_key or "").strip().upper()
    if rk in ("HQ_ADMIN", "AREA_MANAGER", "SALES"):
        return rk
    return "SALES"


# -----------------------------
# BigQuery Client & Auth
# -----------------------------
def _secrets_has_bigquery() -> bool:
    if "bigquery" not in st.secrets:
        return False
    bq = st.secrets.get("bigquery", {})
    return bool(bq.get("project_id")) and bool(bq.get("service_account"))

def _get_bq_from_secrets() -> Tuple[str, str, Dict[str, Any]]:
    bq = st.secrets["bigquery"]
    project_id = str(bq.get("project_id"))
    location = str(bq.get("location") or DEFAULT_LOCATION)
    sa = dict(bq.get("service_account"))
    return project_id, location, sa

def _parse_service_account_json(text: str) -> Dict[str, Any]:
    obj = json.loads(text)
    if not isinstance(obj, dict):
        raise ValueError("JSON format invalid.")
    for k in ["type", "project_id", "private_key", "client_email"]:
        if k not in obj:
            raise ValueError(f"Service Account JSON missing key: {k}")
    return obj

def ensure_credentials_ui() -> Tuple[str, str, Dict[str, Any]]:
    st.sidebar.header("æ¥ç¶šè¨­å®š")
    if _secrets_has_bigquery():
        project_id, location, sa = _get_bq_from_secrets()
        # st.sidebar.success("Secrets: OK") # UIç°¡æ˜“åŒ–ã®ãŸã‚éè¡¨ç¤º
        return project_id, location, sa
    
    st.sidebar.warning("Secrets æœªè¨­å®šã€‚JSONè²¼ã‚Šä»˜ã‘ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™ã€‚")
    project_id = st.sidebar.text_input("project_id (Temporary)", value=PROJECT_DEFAULT)
    location = st.sidebar.text_input("location (Temporary)", value=DEFAULT_LOCATION)
    sa_text = st.sidebar.text_area("Service Account JSON", height=100)
    if not sa_text.strip():
        st.info("SA JSONã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    try:
        sa = _parse_service_account_json(sa_text.strip())
    except Exception as e:
        st.error(f"JSON Parse Error: {e}")
        st.stop()
    sa["project_id"] = project_id.strip() or sa.get("project_id")
    return str(project_id), str(location), sa

@st.cache_resource(show_spinner=False)
def get_bq_client(project_id: str, location: str, sa: Dict[str, Any]) -> bigquery.Client:
    creds = service_account.Credentials.from_service_account_info(sa)
    return bigquery.Client(project=project_id, credentials=creds, location=location)


# -----------------------------
# Query Execution Helpers
# -----------------------------
def _build_query_parameters(params: Optional[Dict[str, Any]]) -> List[bigquery.ScalarQueryParameter]:
    qparams = []
    if not params:
        return qparams
    for k, v in params.items():
        if isinstance(v, bool):
            qparams.append(bigquery.ScalarQueryParameter(k, "BOOL", v))
        elif isinstance(v, int):
            qparams.append(bigquery.ScalarQueryParameter(k, "INT64", v))
        elif isinstance(v, float):
            qparams.append(bigquery.ScalarQueryParameter(k, "FLOAT64", v))
        elif v is None:
            qparams.append(bigquery.ScalarQueryParameter(k, "STRING", ""))
        else:
            qparams.append(bigquery.ScalarQueryParameter(k, "STRING", str(v)))
    return qparams

def _show_bq_error_context(title: str, sql: str, exc: Exception):
    st.error(f"Query Failed: {title}")
    st.write(f"Exception: {exc}")

@st.cache_data(show_spinner=False, ttl=CACHE_TTL_SEC)
def cached_query_df(
    project_id: str, location: str, sa_json: str, sql: str, params_json: str,
    use_bqstorage: bool, timeout_sec: int
) -> pd.DataFrame:
    sa = json.loads(sa_json)
    client = get_bq_client(project_id, location, sa)
    params = json.loads(params_json) if params_json else {}
    job_config = bigquery.QueryJobConfig()
    qparams = _build_query_parameters(params)
    if qparams:
        job_config.query_parameters = qparams
    job = client.query(sql, job_config=job_config)
    job.result(timeout=timeout_sec)
    return job.to_dataframe(create_bqstorage_client=use_bqstorage)

def query_df_safe(
    client: bigquery.Client, sql: str, params: Optional[Dict[str, Any]] = None,
    label: str = "", use_bqstorage: bool = True, timeout_sec: int = 60,
    cache_key: Optional[Tuple[str, str, str]] = None
) -> pd.DataFrame:
    params_json = json.dumps(params or {}, ensure_ascii=False, sort_keys=True)
    try:
        if cache_key:
            project_id, location, sa_json = cache_key
            return cached_query_df(
                project_id, location, sa_json, sql, params_json, use_bqstorage, timeout_sec
            )
        else:
            job_config = bigquery.QueryJobConfig()
            qparams = _build_query_parameters(params or {})
            if qparams:
                job_config.query_parameters = qparams
            job = client.query(sql, job_config=job_config)
            job.result(timeout=timeout_sec)
            return job.to_dataframe(create_bqstorage_client=use_bqstorage)
    except (BadRequest, GoogleAPICallError, Exception) as e:
        _show_bq_error_context(label, sql, e)
        return pd.DataFrame()


# -----------------------------
# Component: User Interface
# -----------------------------
def set_page():
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)
    st.caption("OS v1.6.3ï½œæˆ¦ç•¥ææ¡ˆï½œãƒ¯ãƒ¼ã‚¹ãƒˆåˆ†æï¼ˆãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³æ”¹å–„ï¼‰ï½œç€åœ°äºˆæ¸¬")

def sidebar_controls() -> Dict[str, Any]:
    st.sidebar.header("System Settings")
    use_bqstorage = st.sidebar.toggle("Use Storage API (Fast)", value=True)
    timeout_sec = st.sidebar.slider("Query Timeout (sec)", 10, 300, 60, 10)
    show_sql = st.sidebar.toggle("Show SQL (Debug)", value=False)
    if st.sidebar.button("Clear Cache"):
        st.cache_data.clear()
        st.sidebar.success("Cache Cleared.")
    return {"use_bqstorage": use_bqstorage, "timeout_sec": timeout_sec, "show_sql": show_sql}

def get_login_email_ui() -> str:
    st.sidebar.header("Login Simulation")
    default_email = st.secrets.get("default_login_email", "") if "default_login_email" in st.secrets else ""
    login_email = st.sidebar.text_input("Login Email", value=default_email).strip()
    if not login_email:
        st.info("Please enter login email.")
        st.stop()
    return login_email

def resolve_role(client, cache_key, login_email, opts) -> RoleInfo:
    sql = f"""
    SELECT login_email, role_tier, role_admin_view, area_name
    FROM `{VIEW_ROLE}` WHERE login_email = @login_email LIMIT 1
    """
    df = query_df_safe(client, sql, {"login_email": login_email}, "Role Check",
                       opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    if df.empty:
        return RoleInfo(login_email=login_email)
    
    r = df.iloc[0]
    return RoleInfo(
        login_email=login_email,
        role_key=normalize_role_key(str(r.get("role_tier"))),
        role_admin_view=bool(r.get("role_admin_view")),
        area_name=str(r.get("area_name", "æœªè¨­å®š"))
    )

def run_scoped_query(client, cache_key, sql_template, scope_col, login_email, opts, allow_fallback=False):
    sql = sql_template.replace("__WHERE__", f"WHERE {scope_col} = @login_email")
    if opts["show_sql"]: st.code(sql, language="sql")
    df = query_df_safe(client, sql, {"login_email": login_email}, "Scoped Query",
                       opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    if not df.empty: return df

    if allow_fallback:
        sql_all = sql_template.replace("__WHERE__", f'WHERE {scope_col} = "all" OR {scope_col} IS NULL')
        if opts["show_sql"]: st.code(sql_all, language="sql")
        df_all = query_df_safe(client, sql_all, None, "Fallback Query",
                               opts["use_bqstorage"], opts["timeout_sec"], cache_key)
        return df_all
        
    return pd.DataFrame()


# -----------------------------
# Component: Render Sections
# -----------------------------

def render_fytd_org_section(client, cache_key, login_email, opts):
    """
    å…¨ç¤¾KPI + ãƒ¯ãƒ¼ã‚¹ãƒˆãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æ
    v1.6.3: ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã«ã‚ˆã‚‹ç”»é¢ç¶­æŒã€3æ¡ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šè¡¨ç¤ºã‚’é©ç”¨
    """
    st.subheader("ğŸ¢ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œå…¨ç¤¾")
    
    # å…¨ç¤¾KPIã®èª­ã¿è¾¼ã¿
    if st.button("å…¨ç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_org", use_container_width=True):
        # KPI Card
        sql_kpi = f"SELECT * FROM `{VIEW_FYTD_ORG}` __WHERE__ LIMIT 100"
        df_org = run_scoped_query(client, cache_key, sql_kpi, "viewer_email", login_email, opts, allow_fallback=True)
        
        if not df_org.empty:
            row = df_org.iloc[0]
            st.markdown("##### â–  å£²ä¸Šäºˆæ¸¬")
            c1, c2, c3 = st.columns(3)
            with c1: st.metric("å£²ä¸Š ç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰", f"Â¥{float(row.get('sales_forecast_total', 0)):,.0f}")
            with c2: 
                pace = float(row.get('pacing_rate', 0))
                st.metric("å¯¾å‰å¹´ãƒšãƒ¼ã‚¹", f"{pace*100:.1f}%", f"{(pace-1.0)*100:+.1f}%")
            with c3: st.metric("æ˜¨å¹´åº¦å®Ÿç¸¾ï¼ˆå¹´ï¼‰", f"Â¥{float(row.get('sales_amount_py_total', 0)):,.0f}")

            st.markdown("##### â–  ç²—åˆ©äºˆæ¸¬")
            c4, c5, c6 = st.columns(3)
            with c4: st.metric("ç²—åˆ© ç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰", f"Â¥{float(row.get('gp_forecast_total', 0)):,.0f}")
            with c5:
                pace_gp = float(row.get('gp_pacing_rate', 0))
                st.metric("å¯¾å‰å¹´ãƒšãƒ¼ã‚¹", f"{pace_gp*100:.1f}%", f"{(pace_gp-1.0)*100:+.1f}%")
            with c6: st.metric("æ˜¨å¹´åº¦å®Ÿç¸¾ï¼ˆå¹´ï¼‰", f"Â¥{float(row.get('gross_profit_py_total', 0)):,.0f}")
            st.divider()

        # --- Interactive Worst Ranking (Stateful) ---
        st.subheader("ğŸ“‰ å£²ä¸Šæ¸›å°‘è¦å› ï¼ˆãƒ¯ãƒ¼ã‚¹ãƒˆåˆ†æï¼‰")
        
        # 1. ãƒ‡ãƒ¼ã‚¿å–å¾—
        sql_rank = f"SELECT * FROM `{VIEW_WORST_RANK}` LIMIT 3000"
        df_raw = query_df_safe(client, sql_rank, None, "Worst Raw", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
        
        if df_raw.empty:
            st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        # 2. åˆ†æè»¸ã®é¸æŠï¼ˆãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ï¼‰
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çŠ¶æ…‹ã«å¿œã˜ã¦è¡¨ç¤ºã‚’åˆ¶å¾¡
        axis_mode = st.radio("åˆ†æè»¸:", ["ğŸ“¦ å•†å“è»¸ã§è¦‹ã‚‹", "ğŸ¥ å¾—æ„å…ˆè»¸ã§è¦‹ã‚‹"], horizontal=True, key="worst_axis_radio")
        is_product_mode = "å•†å“" in axis_mode

        # 3. ç”»é¢åˆ†å²: ã€Œä¸€è¦§ã€ã‹ã€Œè©³ç´°ã€ã‹
        if st.session_state.worst_view_mode == 'ranking':
            # === ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä¸€è¦§ç”»é¢ ===
            
            if is_product_mode:
                # å•†å“ã”ã¨ã®é›†è¨ˆ
                st.markdown("**â‘  å•†å“ãƒ¯ãƒ¼ã‚¹ãƒˆãƒ©ãƒ³ã‚­ãƒ³ã‚°**")
                df_group = df_raw.groupby("product_name")[["sales_diff", "sales_cur", "sales_prev"]].sum().reset_index()
                df_group = df_group.sort_values("sales_diff", ascending=True) # æ¸›å°‘é¡ãŒå¤§ãã„é †ï¼ˆãƒã‚¤ãƒŠã‚¹ï¼‰
                
                # è¡¨ç¤ºç”¨è¨­å®š
                col_cfg = {
                    "product_name": st.column_config.TextColumn("å•†å“å", width="medium"),
                    "sales_diff": st.column_config.NumberColumn("æ¸›å°‘é¡", format="Â¥%d"),
                    "sales_cur": st.column_config.NumberColumn("ä»Šå¹´", format="Â¥%d"),
                    "sales_prev": st.column_config.NumberColumn("å‰å¹´", format="Â¥%d")
                }
                disp_cols = ["product_name", "sales_diff", "sales_cur", "sales_prev"]
                target_key = "product_name"
                
            else:
                # å¾—æ„å…ˆã”ã¨ã®é›†è¨ˆ
                st.markdown("**â‘  å¾—æ„å…ˆãƒ¯ãƒ¼ã‚¹ãƒˆãƒ©ãƒ³ã‚­ãƒ³ã‚°**")
                df_group = df_raw.groupby("customer_name")[["sales_diff", "sales_cur", "sales_prev"]].sum().reset_index()
                df_group = df_group.sort_values("sales_diff", ascending=True)

                col_cfg = {
                    "customer_name": st.column_config.TextColumn("å¾—æ„å…ˆå", width="medium"),
                    "sales_diff": st.column_config.NumberColumn("æ¸›å°‘é¡", format="Â¥%d"),
                    "sales_cur": st.column_config.NumberColumn("ä»Šå¹´", format="Â¥%d"),
                    "sales_prev": st.column_config.NumberColumn("å‰å¹´", format="Â¥%d")
                }
                disp_cols = ["customer_name", "sales_diff", "sales_cur", "sales_prev"]
                target_key = "customer_name"

            # ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º
            st.dataframe(
                df_group[disp_cols],
                column_config=col_cfg,
                use_container_width=True,
                hide_index=True,
                height=400
            )

            # ãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³é¸æŠUI
            st.divider()
            st.info("ğŸ‘‡ è©³ç´°ã‚’è¦‹ãŸã„é …ç›®ã‚’é¸ã‚“ã§ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„")
            
            # é¸æŠè‚¢ãƒªã‚¹ãƒˆ
            options_list = df_group[target_key].tolist()
            selected_item = st.selectbox(
                f"åˆ†æå¯¾è±¡ã‚’é¸æŠ:", 
                options_list, 
                key="worst_selectbox"
            )

            if st.button("è©³ç´°åˆ†æã¸ç§»å‹• â¡", type="primary"):
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ã—ã¦ãƒªãƒ­ãƒ¼ãƒ‰
                st.session_state.worst_selected_name = selected_item
                st.session_state.worst_view_mode = 'detail'
                st.rerun()

        elif st.session_state.worst_view_mode == 'detail':
            # === è©³ç´°åˆ†æç”»é¢ ===
            target_name = st.session_state.worst_selected_name
            
            # æˆ»ã‚‹ãƒœã‚¿ãƒ³
            if st.button("â¬… ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«æˆ»ã‚‹"):
                st.session_state.worst_view_mode = 'ranking'
                st.session_state.worst_selected_name = None
                st.rerun()

            st.title(f"ğŸ” è©³ç´°åˆ†æ: {target_name}")
            
            if is_product_mode:
                # å•†å“ãŒé¸ã°ã‚ŒãŸ -> å¾—æ„å…ˆåˆ¥ã®å†…è¨³ã‚’è¡¨ç¤º
                df_detail = df_raw[df_raw["product_name"] == target_name].copy()
                st.markdown("##### å¾—æ„å…ˆåˆ¥ æ¸›å°‘å†…è¨³")
                main_col = "customer_name"
                col_label = "å¾—æ„å…ˆå"
            else:
                # å¾—æ„å…ˆãŒé¸ã°ã‚ŒãŸ -> å•†å“åˆ¥ã®å†…è¨³ã‚’è¡¨ç¤º
                df_detail = df_raw[df_raw["customer_name"] == target_name].copy()
                st.markdown("##### å•†å“åˆ¥ æ¸›å°‘å†…è¨³")
                main_col = "product_name"
                col_label = "å•†å“å"
            
            df_detail = df_detail.sort_values("sales_diff", ascending=True)

            # è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)
            st.dataframe(
                df_detail[[main_col, "sales_diff", "sales_cur", "sales_prev", "sales_rate"]],
                column_config={
                    main_col: st.column_config.TextColumn(col_label),
                    "sales_diff": st.column_config.NumberColumn("æ¸›å°‘é¡", format="Â¥%d"),
                    "sales_cur": st.column_config.NumberColumn("ä»Šå¹´", format="Â¥%d"),
                    "sales_prev": st.column_config.NumberColumn("å‰å¹´", format="Â¥%d"),
                    "sales_rate": st.column_config.NumberColumn("å‰å¹´æ¯”", format="%.2f")
                },
                use_container_width=True,
                hide_index=True
            )

def render_fytd_me_section(client, cache_key, login_email, opts):
    st.subheader("ğŸ‘¤ å¹´åº¦ç´¯è¨ˆï¼ˆFYTDï¼‰ï½œè‡ªåˆ†")
    if st.button("è‡ªåˆ†ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="btn_me", use_container_width=True):
        sql = f"SELECT * FROM `{VIEW_FYTD_ME}` __WHERE__ LIMIT 100"
        df_me = run_scoped_query(client, cache_key, sql, "login_email", login_email, opts)
        
        if df_me.empty:
            st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        row = df_me.iloc[0]
        c1, c2, c3 = st.columns(3)
        with c1: st.metric("ç€åœ°äºˆæ¸¬ï¼ˆå¹´ï¼‰", f"Â¥{float(row.get('sales_forecast_total', 0)):,.0f}")
        with c2: 
            pace = float(row.get('pacing_rate', 0))
            st.metric("å¯¾å‰å¹´ãƒšãƒ¼ã‚¹", f"{pace*100:.1f}%", f"{(pace-1.0)*100:+.1f}%")
        with c3: st.metric("å‰å¹´å®Ÿç¸¾ï¼ˆå¹´ï¼‰", f"Â¥{float(row.get('sales_amount_py_total', 0)):,.0f}")
        
        st.divider()
        # Dataframe with simple renaming
        st.dataframe(rename_columns_for_display(df_me, JP_COLS_FYTD), use_container_width=True)

def render_yoy_section(client, cache_key, login_email, allow_fallback, opts):
    st.subheader("ğŸ“Š å½“æœˆYoYï¼ˆå¾—æ„å…ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰")
    c1, c2, c3 = st.columns(3)
    
    def _show_table(title, view_name, key):
        if st.button(title, key=key, use_container_width=True):
            sql = f"SELECT * FROM `{view_name}` __WHERE__ LIMIT 200"
            df = run_scoped_query(client, cache_key, sql, "login_email", login_email, opts, allow_fallback)
            if not df.empty:
                # ç°¡æ˜“è¡¨ç¤ºã®ãŸã‚ã€å…¨ã‚«ãƒ©ãƒ ã‚’ã‚«ãƒ©ãƒ ã‚³ãƒ³ãƒ•ã‚£ã‚°ã™ã‚‹ã®ã¯çœç•¥ã—ã€
                # ä¸»è¦ã‚«ãƒ©ãƒ ã ã‘è¦‹ã‚„ã™ãã™ã‚‹ï¼ˆã“ã“ã§ã¯æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¸è¥²ï¼‰
                st.dataframe(rename_columns_for_display(df, JP_COLS_YOY), use_container_width=True)
            else:
                st.info("0ä»¶ã§ã™ã€‚")

    with c1: _show_table("YoY Top (ä¼¸ã³)", VIEW_YOY_TOP, "btn_top")
    with c2: _show_table("YoY Bottom (è½ã¡)", VIEW_YOY_BOTTOM, "btn_btm")
    with c3: _show_table("æ–°è¦/æ¯”è¼ƒä¸èƒ½", VIEW_YOY_UNCOMP, "btn_unc")

def render_customer_drilldown(client, cache_key, login_email, opts):
    """
    v1.6.0 New Feature: Customer Gap Analysis & Recommendation (JAN Based)
    """
    st.subheader("ğŸ¯ å¾—æ„å…ˆåˆ¥ãƒ»æˆ¦ç•¥ææ¡ˆï¼ˆAI Gap Analysisï¼‰")
    
    # 1. Get Customer List
    sql_cust = f"""
    SELECT DISTINCT customer_code, customer_name
    FROM `{VIEW_FACT_DAILY}`
    WHERE login_email = @login_email
    ORDER BY customer_code
    """
    df_cust = query_df_safe(client, sql_cust, {"login_email": login_email}, "Cust List", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    
    if df_cust.empty:
        st.info("æ‹…å½“å¾—æ„å…ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆã¾ãŸã¯ãƒ­ã‚°ã‚¤ãƒ³ãƒ¡ãƒ¼ãƒ«ä¸ä¸€è‡´ï¼‰ã€‚")
        return

    # 2. Select Customer
    cust_options = {row["customer_code"]: f"{row['customer_code']} : {row['customer_name']}" for _, row in df_cust.iterrows()}
    selected_code = st.selectbox("åˆ†æã™ã‚‹å¾—æ„å…ˆã‚’é¸æŠã—ã¦ãã ã•ã„", options=cust_options.keys(), format_func=lambda x: cust_options[x])
    
    if not selected_code:
        return

    st.divider()
    
    # 3. Get Recommendation
    sql_rec = f"""
    SELECT * FROM `{VIEW_RECOMMEND}`
    WHERE customer_code = @cust_code
    ORDER BY priority_rank ASC
    """
    df_rec = query_df_safe(client, sql_rec, {"cust_code": selected_code}, "Recommendation", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
    
    # 4. Display Logic
    c1, c2 = st.columns([1, 2])
    
    with c1:
        st.markdown("#### ğŸ¥ å¾—æ„å…ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«")
        if not df_rec.empty:
            strong_cat = df_rec.iloc[0].get("strong_category", "-")
            st.info(f"ã“ã®å¾—æ„å…ˆã®ä¸»åŠ›é ˜åŸŸ(ãƒ¡ãƒ¼ã‚«ãƒ¼): **{strong_cat}**")
            st.caption("â€»è³¼å…¥å®Ÿç¸¾ã‚·ã‚§ã‚¢No.1ã®ãƒ¡ãƒ¼ã‚«ãƒ¼")
        else:
            st.warning("ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆã¾ãŸã¯ä¸»è¦å“å®Œç´æ¸ˆã¿ï¼‰")
            strong_cat = "(ä¸æ˜)"

    with c2:
        st.markdown("#### ğŸ’¡ AIææ¡ˆãƒªã‚¹ãƒˆï¼ˆæœªæ¡ç”¨ã®ãƒãƒ£ãƒ³ã‚¹å•†å“ï¼‰")
        st.caption(f"å…¨ç¤¾ã® **{strong_cat}** å£²ä¸ŠTOP10ã®ã†ã¡ã€**æœªæ¡ç”¨**ã®å•†å“")
        
        if df_rec.empty:
            st.success("ğŸ‰ ã“ã®é ˜åŸŸã®ä¸»è¦å•†å“ã¯ã™ã¹ã¦æ¡ç”¨æ¸ˆã¿ã§ã™ã€‚")
        else:
            disp_df = df_rec[[
                "priority_rank", "recommend_product", "manufacturer", "market_scale"
            ]].rename(columns={
                "priority_rank": "å„ªå…ˆé †ä½",
                "recommend_product": "æ¨å¥¨å•†å“å",
                "manufacturer": "ãƒ¡ãƒ¼ã‚«ãƒ¼",
                "market_scale": "å…¨ç¤¾å£²ä¸Šè¦æ¨¡"
            })
            
            st.dataframe(
                disp_df,
                column_config={
                    "å…¨ç¤¾å£²ä¸Šè¦æ¨¡": st.column_config.NumberColumn(format="Â¥%d")
                },
                use_container_width=True,
                hide_index=True
            )
            
    # 5. Reference: Adopted List
    with st.expander("å‚è€ƒ: ç¾åœ¨ã®æ¡ç”¨å“ãƒªã‚¹ãƒˆã‚’è¦‹ã‚‹"):
        sql_adopted = f"""
        SELECT 
            m.product_name, 
            SUM(t.sales_amount) as sales_fytd
        FROM `{VIEW_FACT_DAILY}` t
        LEFT JOIN `{PROJECT_DEFAULT}.{DATASET_DEFAULT}.vw_item_master_norm` m 
            ON CAST(t.jan AS STRING) = CAST(m.jan_code AS STRING)
        WHERE t.customer_code = @cust_code
          AND t.fiscal_year = 2025
        GROUP BY 1
        ORDER BY 2 DESC
        LIMIT 100
        """
        df_adopted = query_df_safe(client, sql_adopted, {"cust_code": selected_code}, "Adopted List", opts["use_bqstorage"], opts["timeout_sec"], cache_key)
        
        st.dataframe(
            df_adopted.rename(columns={"product_name": "å•†å“å", "sales_fytd": "å£²ä¸Š(FYTD)"}),
            use_container_width=True,
            column_config={
                "å£²ä¸Š(FYTD)": st.column_config.NumberColumn(format="Â¥%d")
            }
        )


# -----------------------------
# Main Execution
# -----------------------------
def main():
    # 0. Session State Initialization (Critical for Drill-down)
    # ç”»é¢é·ç§»ã‚„ãƒªãƒ­ãƒ¼ãƒ‰ã§ã‚‚çŠ¶æ…‹ã‚’ä¿æŒã™ã‚‹ãŸã‚ã«åˆæœŸåŒ–
    if 'worst_view_mode' not in st.session_state:
        st.session_state.worst_view_mode = 'ranking' # 'ranking' or 'detail'
    if 'worst_selected_name' not in st.session_state:
        st.session_state.worst_selected_name = None

    set_page()
    
    # 1. Connection
    project_id, location, sa = ensure_credentials_ui()
    sa_json = json.dumps(sa)
    cache_key = (project_id, location, sa_json)
    client = get_bq_client(project_id, location, sa)
    
    # 2. Controls
    opts = sidebar_controls()
    login_email = get_login_email_ui()
    
    st.divider()

    # 3. Role Check
    role = resolve_role(client, cache_key, login_email, opts)
    st.write(f"**Login:** {role.login_email} / **Role:** {role.role_key} ({role.area_name})")
    
    is_admin = role.role_key in ("HQ_ADMIN", "AREA_MANAGER")
    
    st.divider()
    
    # 4. Routing with Tabs
    if is_admin:
        t1, t2, t3 = st.tabs(["ğŸ¢ å…¨ç¤¾çŠ¶æ³", "ğŸ‘¤ ã‚¨ãƒªã‚¢/å€‹äºº", "ğŸ¯ æˆ¦ç•¥ææ¡ˆ(Beta)"])
        with t1: render_fytd_org_section(client, cache_key, login_email, opts)
        with t2:
            render_fytd_me_section(client, cache_key, login_email, opts)
            st.divider()
            render_yoy_section(client, cache_key, login_email, is_admin, opts)
        with t3:
            render_customer_drilldown(client, cache_key, login_email, opts)

    else:
        # Sales Role
        t1, t2, t3 = st.tabs(["ğŸ‘¤ ä»Šå¹´ã®æˆç¸¾", "ğŸ“Š å¾—æ„å…ˆåˆ†æ", "ğŸ¯ ææ¡ˆã‚’ä½œã‚‹"])
        with t1: render_fytd_me_section(client, cache_key, login_email, opts)
        with t2: render_yoy_section(client, cache_key, login_email, is_admin, opts)
        with t3: render_customer_drilldown(client, cache_key, login_email, opts)

    st.caption("Updated: v1.6.3 (Safe Mode + Enhanced UI)")

if __name__ == "__main__":
    main()
